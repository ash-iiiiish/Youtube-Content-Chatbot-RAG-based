{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4fe1be7",
   "metadata": {},
   "source": [
    "# Youtube Content Chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ae362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (1.2.0)\n",
      "Collecting huggingface-hub<1.0.0,>=0.33.4 (from langchain-huggingface)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langchain-huggingface) (1.2.7)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langchain-huggingface) (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2026.1.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.6.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.12.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.3.1)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "Successfully installed huggingface-hub-0.36.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e894f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from youtube-transcript-api) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests->youtube-transcript-api) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests->youtube-transcript-api) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests->youtube-transcript-api) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests->youtube-transcript-api) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e3bb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e0f6db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6dd96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document loader\n",
    "yt_api = YouTubeTranscriptApi()\n",
    "video_id='hmtuvNfytjM'\n",
    "transcript= yt_api.fetch(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec3be7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchedTranscript(snippets=[FetchedTranscriptSnippet(text=\"This is like a crazy amount of power for\\xa0\\none piece of technology and it's happened\\xa0\\xa0\", start=0.16, duration=3.44), FetchedTranscriptSnippet(text='to us so fast. You just launched GPT-5. A kid\\xa0\\nborn today will never be smarter than AI. How\\xa0\\xa0', start=3.6, duration=4.64), FetchedTranscriptSnippet(text=\"do we figure out what's real and what's not\\xa0\\nreal? We haven't put a sex bot avatar in ChatGPT\\xa0\\xa0\", start=8.24, duration=4.16), FetchedTranscriptSnippet(text='yet. Super intelligence. What does that\\xa0\\nactually mean? This thing is remarkable.', start=12.4, duration=7.68), FetchedTranscriptSnippet(text=\"I'm about to interview Sam Alman, the CEO\\xa0\\nof Open AI. Open AI. Open AI. Reshaping\\xa0\\xa0\", start=20.08, duration=5.68), FetchedTranscriptSnippet(text=\"industries. Dude's a straightup tech lord. Let's\\xa0\\nbe honest. Right now, they're trying to build a\\xa0\\xa0\", start=25.76, duration=4.4), FetchedTranscriptSnippet(text='super intelligence that could far exceed humans\\xa0\\nin almost every field. And they just released\\xa0\\xa0', start=30.16, duration=6.24), FetchedTranscriptSnippet(text='their most powerful model yet. Just a couple years\\xa0\\nago, that would have sounded like science fiction.\\xa0\\xa0', start=36.4, duration=5.36), FetchedTranscriptSnippet(text=\"Not anymore. In fact, they're not alone. We are\\xa0\\nin the middle of the highest stakes global race\\xa0\\xa0\", start=41.76, duration=5.52), FetchedTranscriptSnippet(text='any of us have ever seen. Hundreds of billions of\\xa0\\ndollars and an unbelievable amount of human worth.\\xa0\\xa0', start=47.28, duration=6.24), FetchedTranscriptSnippet(text='This is a profound moment. Most people never\\xa0\\nlive through a technological shift like this,\\xa0\\xa0', start=53.52, duration=5.52), FetchedTranscriptSnippet(text=\"and it's happening all around you and me right\\xa0\\nnow. So, in this episode, I want to try to time\\xa0\\xa0\", start=59.04, duration=5.84), FetchedTranscriptSnippet(text=\"travel with Sam Alman into the future that\\xa0\\nhe's trying to build to see what it looks\\xa0\\xa0\", start=64.88, duration=5.2), FetchedTranscriptSnippet(text=\"like so that you and I can really understand\\xa0\\nwhat's coming. Welcome to Huge Conversations.\", start=70.08, duration=14.0), FetchedTranscriptSnippet(text='How are you? Great to meet you. Thanks for\\xa0\\ndoing this. Absolutely. So, before we dive in,\\xa0\\xa0', start=84.08, duration=3.68), FetchedTranscriptSnippet(text=\"I'd love to tell you my goal here. Okay. I'm\\xa0\\nnot going to ask you about valuation or AI\\xa0\\xa0\", start=87.76, duration=4.8), FetchedTranscriptSnippet(text=\"talent wars or fundraising or anything like that.\\xa0\\nI think that's all very well covered elsewhere. It\\xa0\\xa0\", start=92.56, duration=5.2), FetchedTranscriptSnippet(text='does seem like it. Our big goal on this show is to\\xa0\\ncover how we can use science and tech to make the\\xa0\\xa0', start=97.76, duration=6.56), FetchedTranscriptSnippet(text='future better. And the reason that we do all of\\xa0\\nthat is because we really believe that if people\\xa0\\xa0', start=104.32, duration=5.12), FetchedTranscriptSnippet(text='see those better futures, they can then help\\xa0\\nbuild them. So, my goal here is to try my best\\xa0\\xa0', start=109.44, duration=5.92), FetchedTranscriptSnippet(text=\"to time travel with you into different moments\\xa0\\nin the future that you're trying to build and see\\xa0\\xa0\", start=115.36, duration=6.32), FetchedTranscriptSnippet(text='what it looks like. Fantastic. Awesome. Starting\\xa0\\nwith what you just announced, you recently said,\\xa0\\xa0', start=121.68, duration=6.08), FetchedTranscriptSnippet(text='surprisingly recently, that GPT4 was the dumbest\\xa0\\nmodel any of us will ever have to use again.\\xa0\\xa0', start=127.76, duration=6.4), FetchedTranscriptSnippet(text='But GPT4 can already perform better than 90% of\\xa0\\nhumans at the SAT and the LSAT and the GRE and it\\xa0\\xa0', start=134.16, duration=7.52), FetchedTranscriptSnippet(text='can pass coding exams and sommelier exams and medical\\xa0\\nlicensing. And now you just launched GPT5. What\\xa0\\xa0', start=141.68, duration=8.32), FetchedTranscriptSnippet(text=\"can GPT5 do that GPT4 can't? First of all, one\\xa0\\nimportant takeaway is you can have an AI system\\xa0\\xa0\", start=150.0, duration=5.68), FetchedTranscriptSnippet(text=\"that can do all those amazing things you just\\xa0\\nsaid. And it doesn't it clearly does not replicate\\xa0\\xa0\", start=155.68, duration=5.28), FetchedTranscriptSnippet(text='a lot of what humans are good at doing, which I\\xa0\\nthink says something about the value of SAT tests\\xa0\\xa0', start=160.96, duration=4.0), FetchedTranscriptSnippet(text='or whatever else. But I think had you gone back\\xa0\\nto if we were having this conversation the day of\\xa0\\xa0', start=164.96, duration=4.16), FetchedTranscriptSnippet(text='GPT4 launch and we told you how GPT4 did at those\\xa0\\nthings, you were like, \"Oh man, this is going to\\xa0\\xa0', start=169.12, duration=5.04), FetchedTranscriptSnippet(text='have huge impacts and some negative impacts on\\xa0\\nwhat it means for a bunch of jobs or you know\\xa0\\xa0', start=174.16, duration=6.88), FetchedTranscriptSnippet(text='what people are going to do.\" And you know, this\\xa0\\nis a bunch of positive impacts that you might have\\xa0\\xa0', start=181.04, duration=4.56), FetchedTranscriptSnippet(text=\"predicted that haven't yet come true. Uh, and so\\xa0\\nthere there's something about the way that these\\xa0\\xa0\", start=185.6, duration=6.24), FetchedTranscriptSnippet(text='models are good that does not capture a lot of\\xa0\\nother things that we need people to to do or care\\xa0\\xa0', start=191.84, duration=5.76), FetchedTranscriptSnippet(text='about people doing. And I suspect that same thing\\xa0\\nis going to happen again with GPT5. People are\\xa0\\xa0', start=197.6, duration=5.28), FetchedTranscriptSnippet(text=\"going to be blown away by what it does. Uh, it's\\xa0\\nreally good at a lot of things and then they will\\xa0\\xa0\", start=202.88, duration=6.0), FetchedTranscriptSnippet(text='find that they want it to do even more. Um, people\\xa0\\nwill use it for all sorts of incredible things.\\xa0\\xa0', start=208.88, duration=5.76), FetchedTranscriptSnippet(text='uh it will transform a lot of knowledge work,\\xa0\\na lot of the way we learn, a lot of the way we\\xa0\\xa0', start=214.64, duration=6.24), FetchedTranscriptSnippet(text='create um but we people society will co-eolve with\\xa0\\nit to expect more with you know better tools. So\\xa0\\xa0', start=220.88, duration=9.12), FetchedTranscriptSnippet(text='yeah like I think this model is quite remarkable\\xa0\\nin many ways quite limited in others but the fact\\xa0\\xa0', start=230.0, duration=6.08), FetchedTranscriptSnippet(text='that for you know 3 minute 5 minute 1-hour tasks\\xa0\\nthat uh like an expert in a in a field could maybe\\xa0\\xa0', start=236.08, duration=10.16), FetchedTranscriptSnippet(text='do or maybe struggle with that the fact that you\\xa0\\nhave in your pocket one piece of software that\\xa0\\xa0', start=246.24, duration=5.2), FetchedTranscriptSnippet(text='can do all of these things is really amazing.\\xa0\\nI think this is like unprecedented at any point\\xa0\\xa0', start=251.44, duration=6.16), FetchedTranscriptSnippet(text='in human history that I that a technology has\\xa0\\nimproved this much this fast and and the fact\\xa0\\xa0', start=257.6, duration=6.48), FetchedTranscriptSnippet(text=\"that we have this tool now, you know, we're like\\xa0\\nliving through it and we're kind of adjusting step\\xa0\\xa0\", start=264.08, duration=4.24), FetchedTranscriptSnippet(text='by step. But if we could go back in time five or\\xa0\\n10 years and say this thing was coming, we would\\xa0\\xa0', start=268.32, duration=4.96), FetchedTranscriptSnippet(text=\"be like probably not. Let's assume that people\\xa0\\nhaven't seen the headlines. What are the topline\\xa0\\xa0\", start=273.28, duration=6.64), FetchedTranscriptSnippet(text=\"specific things that you're excited about? and\\xa0\\nalso the things that you seem to be caveatting,\\xa0\\xa0\", start=279.92, duration=4.08), FetchedTranscriptSnippet(text=\"the things that maybe you won't expect it to do.\\xa0\\nUm, the thing that I am most excited about is this\\xa0\\xa0\", start=284.0, duration=7.52), FetchedTranscriptSnippet(text='is a model for the first time where I feel like I\\xa0\\ncan ask kind of any hard scientific or technical\\xa0\\xa0', start=291.52, duration=8.8), FetchedTranscriptSnippet(text=\"question and get a pretty good answer. And I'll\\xa0\\ngive a fun example actually. Uh when I was in\\xa0\\xa0\", start=300.32, duration=7.92), FetchedTranscriptSnippet(text='junior high uh or maybe it was nth grade,\\xa0\\nI got a TI83, this old graphing calculator,\\xa0\\xa0', start=308.24, duration=5.84), FetchedTranscriptSnippet(text='and I spent so long making this game called Snake.\\xa0\\nYeah. Uh it was very popular game with kids in my\\xa0\\xa0', start=314.08, duration=7.12), FetchedTranscriptSnippet(text='school. And I was I was like uh I was like pro and\\xa0\\nit was dumb, but it was like programming on TID3\\xa0\\xa0', start=321.2, duration=5.6), FetchedTranscriptSnippet(text='was extremely painful and took a long time and\\xa0\\nit was really hard to like debug and whatever.\\xa0\\xa0', start=326.8, duration=4.24), FetchedTranscriptSnippet(text='And on a whim with an early copy of GPT5, I was\\xa0\\nlike, I wonder if it can make a TI83 style Game\\xa0\\xa0', start=331.04, duration=6.32), FetchedTranscriptSnippet(text='of Snake. And of course, it did that perfectly\\xa0\\nin like 7 seconds. And then I was like, okay,\\xa0\\xa0', start=337.36, duration=4.64), FetchedTranscriptSnippet(text='am I supposed to be would my like 11-year-old\\xa0\\nself think this was cool or like, you know,\\xa0\\xa0', start=342.0, duration=5.92), FetchedTranscriptSnippet(text='miss something from the process? And I\\xa0\\nhad like 3 seconds of wondering like, oh,\\xa0\\xa0', start=347.92, duration=4.08), FetchedTranscriptSnippet(text=\"is this good or bad? And then I immediately said,\\xa0\\nactually, now I'm missing this game. I have this\\xa0\\xa0\", start=352.0, duration=5.84), FetchedTranscriptSnippet(text='idea for a crazy new feature. Let me type it\\xa0\\nin. it implements it and it just the game live\\xa0\\xa0', start=357.84, duration=4.32), FetchedTranscriptSnippet(text=\"updates and I'm like actually I'd like it to look\\xa0\\nthis way. Actually, I'd like to do this thing and\\xa0\\xa0\", start=362.16, duration=4.0), FetchedTranscriptSnippet(text='I had this like this very like kind of you have\\xa0\\nthis experience that reminded me of being like 11\\xa0\\xa0', start=366.16, duration=6.08), FetchedTranscriptSnippet(text='in programming again where I was just like I now I\\xa0\\nwant to try this now I have this idea now I but I\\xa0\\xa0', start=372.24, duration=3.76), FetchedTranscriptSnippet(text='could do it so fast and I could like express ideas\\xa0\\nand try things and play with things in such real\\xa0\\xa0', start=376.0, duration=6.16), FetchedTranscriptSnippet(text='time. I was like, \"Oh man, you know, I was worried\\xa0\\nfor a second about kids like missing the struggle\\xa0\\xa0', start=382.16, duration=4.64), FetchedTranscriptSnippet(text='of learning to program in this sort of stone age\\xa0\\nway.\" And now I\\'m just thrilled for them because\\xa0\\xa0', start=386.8, duration=4.72), FetchedTranscriptSnippet(text='the the way that people will be able to create\\xa0\\nwith these new tools, the speed with which you\\xa0\\xa0', start=391.52, duration=4.08), FetchedTranscriptSnippet(text=\"can sort of bring ideas to life, you know, in\\xa0\\nthat's that's pretty amazing. So this idea that\\xa0\\xa0\", start=395.6, duration=6.8), FetchedTranscriptSnippet(text='GPT5 can just not only like answer all these hard\\xa0\\nquestions for you but really create like ondemand\\xa0\\xa0', start=402.4, duration=6.48), FetchedTranscriptSnippet(text=\"almost instantaneous software that's I think\\xa0\\nthat's going to be one of the defining elements\\xa0\\xa0\", start=408.88, duration=5.44), FetchedTranscriptSnippet(text=\"of the GPD5 era in a way that did not exist with\\xa0\\nGPD4. As you're talking about that I find myself\\xa0\\xa0\", start=414.32, duration=5.28), FetchedTranscriptSnippet(text=\"thinking about a concept in weightlifting of time\\xa0\\nunder tension. Yeah. And for those who don't know\\xa0\\xa0\", start=419.6, duration=5.92), FetchedTranscriptSnippet(text=\"it's you can squat 100 pounds in 3 seconds or you\\xa0\\ncan squat 100 pounds in 30. You gain a lot more\\xa0\\xa0\", start=425.52, duration=5.44), FetchedTranscriptSnippet(text=\"by squatting it in 30. And when I think about our\\xa0\\ncreative process and when I've felt most like I've\\xa0\\xa0\", start=430.96, duration=5.84), FetchedTranscriptSnippet(text='done my best work, it has required an enormous\\xa0\\namount of cognitive time under tension. And I\\xa0\\xa0', start=436.8, duration=6.16), FetchedTranscriptSnippet(text=\"think that that cognitive time under tension\\xa0\\nis so important. And it's it's ironic almost\\xa0\\xa0\", start=442.96, duration=5.6), FetchedTranscriptSnippet(text='because these tools have taken enormous cognitive\\xa0\\ntime under tension to develop. But in some ways I\\xa0\\xa0', start=448.56, duration=6.48), FetchedTranscriptSnippet(text=\"do think people might say they're you people are\\xa0\\nusing them as a escape hatch for thinking in some\\xa0\\xa0\", start=455.04, duration=7.2), FetchedTranscriptSnippet(text='ways maybe. Now you might say yeah but we did that\\xa0\\nwith the calculator and we just moved on to harder\\xa0\\xa0', start=462.24, duration=5.76), FetchedTranscriptSnippet(text=\"math problems. Do you feel like there's something\\xa0\\ndifferent happening here? How do you think about\\xa0\\xa0\", start=468.0, duration=5.52), FetchedTranscriptSnippet(text=\"this? It's different with I mean there are some\\xa0\\npeople who are clearly using chachine not to\\xa0\\xa0\", start=473.52, duration=4.56), FetchedTranscriptSnippet(text='think and there are some people who are using\\xa0\\nit to think more than they ever have before.\\xa0\\xa0', start=478.08, duration=4.88), FetchedTranscriptSnippet(text='I am hopeful that we will be able to build the\\xa0\\ntool in a way that encourages more people to\\xa0\\xa0', start=484.56, duration=5.92), FetchedTranscriptSnippet(text='stretch their brain with it a little more and\\xa0\\nbe able to do more. And I think that like you\\xa0\\xa0', start=490.48, duration=3.6), FetchedTranscriptSnippet(text='know society is a competitive place like if you\\xa0\\ngive people new tools uh in theory maybe people\\xa0\\xa0', start=494.08, duration=6.24), FetchedTranscriptSnippet(text='just work less but in practice it seems like\\xa0\\npeople work ever harder and the expectations of\\xa0\\xa0', start=500.32, duration=4.48), FetchedTranscriptSnippet(text='people just go up. So my my guess is that like\\xa0\\nother tools uh some people like other pieces\\xa0\\xa0', start=504.8, duration=9.84), FetchedTranscriptSnippet(text='of technology some people will do more and some\\xa0\\npeople will do less but certainly for the people\\xa0\\xa0', start=514.64, duration=4.88), FetchedTranscriptSnippet(text='who want to use chatbt to increase their cognitive\\xa0\\ntime under tension they are really able to and it\\xa0\\xa0', start=519.52, duration=6.64), FetchedTranscriptSnippet(text='is I take a lot of inspiration from what like the\\xa0\\ntop 5% of most engaged users do with chacht like\\xa0\\xa0', start=526.16, duration=6.48), FetchedTranscriptSnippet(text=\"it's really amazing how much people are learning\\xa0\\nand doing and you know outputting. So my I've\\xa0\\xa0\", start=532.64, duration=7.84), FetchedTranscriptSnippet(text=\"only had GPT5 for a couple hours so I've been\\xa0\\nplaying. What do you think so far? I'm I'm just\\xa0\\xa0\", start=540.48, duration=5.12), FetchedTranscriptSnippet(text='learning how to interact with it. I mean part of\\xa0\\nthe interesting thing is I feel like I just caught\\xa0\\xa0', start=545.6, duration=4.32), FetchedTranscriptSnippet(text=\"up on how to use GPT4 and now I'm trying to learn\\xa0\\nhow to use GPD5. I'm curious what the specific\\xa0\\xa0\", start=549.92, duration=7.28), FetchedTranscriptSnippet(text=\"tasks that you found most interesting are because\\xa0\\nI imagine you've been using it for a while now.\\xa0\\xa0\", start=557.2, duration=5.52), FetchedTranscriptSnippet(text=\"I I have been most impressed by the coding tasks.\\xa0\\nI mean, there's a lot of other things it's really\\xa0\\xa0\", start=562.72, duration=4.16), FetchedTranscriptSnippet(text='good at, but this this idea of the AI can write\\xa0\\nsoftware for anything. And that means that you\\xa0\\xa0', start=566.88, duration=10.32), FetchedTranscriptSnippet(text='can express ideas in new ways that the AI can\\xa0\\ndo very advanced things. It can do, you know,\\xa0\\xa0', start=577.2, duration=5.68), FetchedTranscriptSnippet(text='it can like in some sense you could like ask\\xa0\\nGPT4 anything, but because GPT5 is so good at\\xa0\\xa0', start=582.88, duration=6.48), FetchedTranscriptSnippet(text=\"programming, it feels like it can do anything. Of\\xa0\\ncourse, it can't do things in the physical world,\\xa0\\xa0\", start=589.36, duration=3.04), FetchedTranscriptSnippet(text='but it can get a computer to do very complex\\xa0\\nthings. And software is this super powerful,\\xa0\\xa0', start=592.4, duration=6.32), FetchedTranscriptSnippet(text='you know, way to like control some stuff and\\xa0\\nactually do some things. So, that that for me\\xa0\\xa0', start=598.72, duration=5.84), FetchedTranscriptSnippet(text=\"has been the most striking. Um, it's gotten it's\\xa0\\nmuch better at writing. So, this is like there's\\xa0\\xa0\", start=604.56, duration=7.52), FetchedTranscriptSnippet(text='this whole thing of AI slop like AI writes in this\\xa0\\nkind of like quite annoying way and M dashes. M we\\xa0\\xa0', start=612.08, duration=6.4), FetchedTranscriptSnippet(text='still have the M dashes in GPT5. A lot of people\\xa0\\nlike them dashes, but the writing quality of GPT5\\xa0\\xa0', start=618.48, duration=6.24), FetchedTranscriptSnippet(text='is gotten much better. We still have a long way\\xa0\\nto go. We want to improve it more, but like uh\\xa0\\xa0', start=624.72, duration=6.4), FetchedTranscriptSnippet(text=\"I've a thing we've heard a lot from people inside\\xa0\\nof OpenAI is that man, they started using GPT5,\\xa0\\xa0\", start=631.12, duration=5.68), FetchedTranscriptSnippet(text=\"they knew it was better on all the metrics, but\\xa0\\nthere's this like nuance quality they can't quite\\xa0\\xa0\", start=636.8, duration=4.96), FetchedTranscriptSnippet(text='articulate, but then when they have to go back\\xa0\\nto GPT4 to test something, it feels terrible.\\xa0\\xa0', start=641.76, duration=4.08), FetchedTranscriptSnippet(text=\"And I I don't know exactly what the cause\\xa0\\nof that is, but I suspect part of it is the\\xa0\\xa0\", start=645.84, duration=3.68), FetchedTranscriptSnippet(text='writing feels so much more natural and better.\\xa0\\nI in preparation for this interview reached out\\xa0\\xa0', start=649.52, duration=5.68), FetchedTranscriptSnippet(text='to a couple other leaders in AI and technology\\xa0\\nand gathered a couple questions for you. Okay,\\xa0\\xa0', start=655.2, duration=5.28), FetchedTranscriptSnippet(text='so this next question is from Stripe CEO Patrick\\xa0\\nCollison. This will be a good one. Read this\\xa0\\xa0', start=660.48, duration=5.52), FetchedTranscriptSnippet(text=\"verbatim. It's about the next stage. What what\\xa0\\ncomes after GBT5? In which year do you think a\\xa0\\xa0\", start=666.0, duration=7.52), FetchedTranscriptSnippet(text=\"large language model will make a significant\\xa0\\nscientific discovery and what's missing such\\xa0\\xa0\", start=673.52, duration=4.8), FetchedTranscriptSnippet(text=\"that it hasn't happened yet? He caveed here that\\xa0\\nwe should leave math and special case models like\\xa0\\xa0\", start=678.32, duration=4.72), FetchedTranscriptSnippet(text=\"alpha fold aside. He's specifically asking about\\xa0\\nfully general purpose models like the GPT series.\\xa0\\xa0\", start=683.04, duration=5.04), FetchedTranscriptSnippet(text='I would say most people will agree that that\\xa0\\nhappens at some point over the next two years.\\xa0\\xa0', start=688.08, duration=4.0), FetchedTranscriptSnippet(text='But the definition of significant matters a lot.\\xa0\\nAnd so some people significant might happen,\\xa0\\xa0', start=692.08, duration=6.16), FetchedTranscriptSnippet(text='you know, in early 25. Some people might maybe\\xa0\\nnot until late 2026. Sorry, early 2026. Maybe some\\xa0\\xa0', start=698.24, duration=5.68), FetchedTranscriptSnippet(text='people not until late 2027, but I would I would\\xa0\\nbet that by late 27, most people agree that there\\xa0\\xa0', start=703.92, duration=6.64), FetchedTranscriptSnippet(text='has been an AIdriven significant new discovery.\\xa0\\nAnd the thing that I think is missing is just\\xa0\\xa0', start=710.56, duration=4.4), FetchedTranscriptSnippet(text='the kind of cognitive power of these models.\\xa0\\nA framework that one of the researchers said\\xa0\\xa0', start=714.96, duration=5.84), FetchedTranscriptSnippet(text='to me that I really liked is, you know, a year\\xa0\\nago we could do well on like a high school like\\xa0\\xa0', start=720.8, duration=6.96), FetchedTranscriptSnippet(text='a basic high school math competition problems that\\xa0\\nmight take a professional mathematician seconds to\\xa0\\xa0', start=727.76, duration=5.2), FetchedTranscriptSnippet(text='a few minutes. We very recently got an IMO gold\\xa0\\nmedal. That is a crazy difficult like could you\\xa0\\xa0', start=732.96, duration=6.4), FetchedTranscriptSnippet(text=\"explain what that means? That's kind of like the\\xa0\\nhardest competition math test. This is something\\xa0\\xa0\", start=739.36, duration=4.0), FetchedTranscriptSnippet(text=\"that like the very very top slice of the world.\\xa0\\nmany many professional mathematicians wouldn't\\xa0\\xa0\", start=743.36, duration=5.36), FetchedTranscriptSnippet(text='solve a single problem and we scored at the top\\xa0\\nlevel. Now there are some humans that got an even\\xa0\\xa0', start=748.72, duration=5.2), FetchedTranscriptSnippet(text='higher score in the gold medal range but we we\\xa0\\nlike this is a crazy accomplishment and these\\xa0\\xa0', start=753.92, duration=4.88), FetchedTranscriptSnippet(text=\"each of these problems it's like six problems over\\xa0\\n9 hours so hour and a half per problem for a great\\xa0\\xa0\", start=758.8, duration=5.36), FetchedTranscriptSnippet(text=\"mathematician. So we've gone from a few seconds\\xa0\\nto a few minutes to an hour and a half maybe to\\xa0\\xa0\", start=764.16, duration=5.76), FetchedTranscriptSnippet(text='prove a significant new mathematical theorem is\\xa0\\nlike a thousand hours of work for a top person\\xa0\\xa0', start=769.92, duration=4.8), FetchedTranscriptSnippet(text=\"in the world. So we've got to go from, you know,\\xa0\\nanother significant gain. But if you look at our\\xa0\\xa0\", start=774.72, duration=6.0), FetchedTranscriptSnippet(text=\"trajectory, you can say like, okay, we're getting\\xa0\\nto that. We have a path to get to that time\\xa0\\xa0\", start=780.72, duration=3.92), FetchedTranscriptSnippet(text=\"horizon. We just need to keep scaling the models.\\xa0\\nThe long-term future that you've described is\\xa0\\xa0\", start=784.64, duration=7.28), FetchedTranscriptSnippet(text=\"super intelligence. What does that actually mean?\\xa0\\nAnd how will we know when we've hit it? If we had\\xa0\\xa0\", start=791.92, duration=6.16), FetchedTranscriptSnippet(text='a system that could do better research, better AI\\xa0\\nresearch than uh say the whole open AI research\\xa0\\xa0', start=798.08, duration=8.4), FetchedTranscriptSnippet(text='team, like if we were willing, if we said, \"Okay,\\xa0\\nthe best way we can use our GPUs is to let this AI\\xa0\\xa0', start=806.48, duration=4.96), FetchedTranscriptSnippet(text='decide what experiments we should run smarter than\\xa0\\nlike the whole brain trust of Open AAI.\" Yeah. And\\xa0\\xa0', start=811.44, duration=4.88), FetchedTranscriptSnippet(text='if that same to make a personal example, if that\\xa0\\nsame system could do a better job running open AI\\xa0\\xa0', start=816.32, duration=4.0), FetchedTranscriptSnippet(text=\"than I could. So you have something that's like,\\xa0\\nyou know, better than the best researchers, better\\xa0\\xa0\", start=820.32, duration=3.52), FetchedTranscriptSnippet(text='than me at this, better than other people at their\\xa0\\njobs, that would feel like super intelligence to\\xa0\\xa0', start=823.84, duration=3.2), FetchedTranscriptSnippet(text='me. That is a sentence that would have sounded\\xa0\\nlike science fiction just a couple years ago.\\xa0\\xa0', start=827.04, duration=4.16), FetchedTranscriptSnippet(text=\"And now it kind of does, but it's you can like see\\xa0\\nit through the fog. Yes. And so one of the steps\\xa0\\xa0\", start=831.2, duration=5.84), FetchedTranscriptSnippet(text=\"it sounds like you're saying on that path is this\\xa0\\nmoment of scientific discovery of asking better\\xa0\\xa0\", start=837.04, duration=5.6), FetchedTranscriptSnippet(text='questions of grappling with things in a in a way\\xa0\\nthat expert level humans do to come up with new\\xa0\\xa0', start=842.64, duration=6.0), FetchedTranscriptSnippet(text='discoveries. One of the things that keeps knocking\\xa0\\naround in my head is if we were in 1899 say and\\xa0\\xa0', start=848.64, duration=5.76), FetchedTranscriptSnippet(text='we were able to give it all of physics up until\\xa0\\nthat point and play it out a little bit. Nothing\\xa0\\xa0', start=854.4, duration=4.24), FetchedTranscriptSnippet(text='further than that. Like at what point would one\\xa0\\nof these systems come up with general relativity?\\xa0\\xa0', start=858.64, duration=4.56), FetchedTranscriptSnippet(text='Interesting question is did you like if we think\\xa0\\nabout that forward like like if we think of where\\xa0\\xa0', start=864.16, duration=4.72), FetchedTranscriptSnippet(text='we are now should a if if we never got another\\xa0\\npiece of physics data. Yeah. Do we expect that a\\xa0\\xa0', start=868.88, duration=9.76), FetchedTranscriptSnippet(text='really good super intelligence could just think\\xa0\\nsuper hard about our existing data and maybe\\xa0\\xa0', start=878.64, duration=4.32), FetchedTranscriptSnippet(text='say like solve high energy physics with no new\\xa0\\nparticle accelerator or does it need to build a\\xa0\\xa0', start=882.96, duration=4.64), FetchedTranscriptSnippet(text=\"new one and design new experiments? Obviously\\xa0\\nwe don't know the answer to that. Different\\xa0\\xa0\", start=887.6, duration=3.44), FetchedTranscriptSnippet(text='people have different speculation. Uh but I\\xa0\\nsuspect we will find that for a lot of science,\\xa0\\xa0', start=891.04, duration=6.88), FetchedTranscriptSnippet(text=\"it's not enough to just think harder about data we\\xa0\\nhave, but we will need to build new instruments,\\xa0\\xa0\", start=897.92, duration=5.36), FetchedTranscriptSnippet(text='conduct new experiments, and that will take some\\xa0\\ntime. Like that that is the real world is slow\\xa0\\xa0', start=903.28, duration=3.92), FetchedTranscriptSnippet(text=\"and messy and you know whatever. So I'm sure we\\xa0\\ncould make some more progress just by thinking\\xa0\\xa0\", start=907.2, duration=5.12), FetchedTranscriptSnippet(text='harder about the current scientific data we\\xa0\\nhave in the world. But my guess is to make\\xa0\\xa0', start=912.32, duration=4.32), FetchedTranscriptSnippet(text=\"the big progress we'll also need to build new\\xa0\\nmachines and run new experiments and there will\\xa0\\xa0\", start=916.64, duration=4.64), FetchedTranscriptSnippet(text='be some slowdown built into that. Another way of\\xa0\\nof thinking about this is AI systems now are just\\xa0\\xa0', start=921.28, duration=8.24), FetchedTranscriptSnippet(text=\"incredibly good at answering almost any question.\\xa0\\nBut maybe one of the things we're saying is it's\\xa0\\xa0\", start=929.52, duration=5.76), FetchedTranscriptSnippet(text=\"another leap yet. And what Patrick's question\\xa0\\nis getting at is to ask the better questions.\\xa0\\xa0\", start=935.28, duration=4.8), FetchedTranscriptSnippet(text='Or or if we go back to this kind of timeline\\xa0\\nquestion, we could maybe say that AI systems\\xa0\\xa0', start=940.08, duration=4.96), FetchedTranscriptSnippet(text=\"are superhuman on one minute tasks, but a long\\xa0\\nway to go to the thousand hour tasks. And there's\\xa0\\xa0\", start=945.04, duration=7.04), FetchedTranscriptSnippet(text='a dimension of human intelligence that seems\\xa0\\nvery different than AI systems when it comes\\xa0\\xa0', start=952.08, duration=7.2), FetchedTranscriptSnippet(text=\"to these long horizon tasks. Now, I think we will\\xa0\\nfigure it out, but today it's a real weak point.\\xa0\\xa0\", start=959.28, duration=5.6), FetchedTranscriptSnippet(text=\"We've talked about where we are now with GBC5.\\xa0\\nWe talked about the end goal or future goal of\\xa0\\xa0\", start=964.88, duration=5.04), FetchedTranscriptSnippet(text='super intelligence. One of the questions that\\xa0\\nI have, of course, is what does it look like\\xa0\\xa0', start=969.92, duration=5.76), FetchedTranscriptSnippet(text=\"to walk through the fog between the two. The next\\xa0\\nquestion is from Nvidia CEO Jensen Hong. I'm going\\xa0\\xa0\", start=975.68, duration=6.72), FetchedTranscriptSnippet(text='to read this verbatim. Fact is what is. Truth is\\xa0\\nwhat it means. So facts are objective. Truths are\\xa0\\xa0', start=982.4, duration=7.76), FetchedTranscriptSnippet(text='personal. They depend on perspective, culture,\\xa0\\nvalues, beliefs, context. One AI can learn and\\xa0\\xa0', start=990.16, duration=5.76), FetchedTranscriptSnippet(text='know the facts. But how does one AI know the\\xa0\\ntruth for everyone in every country and every\\xa0\\xa0', start=995.92, duration=5.28), FetchedTranscriptSnippet(text=\"background? I'm going to accept as axioms those\\xa0\\ndefinitions. I'm not sure if I agree with them,\\xa0\\xa0\", start=1001.2, duration=6.0), FetchedTranscriptSnippet(text='but in the issues of time, I will just take them.\\xa0\\nI will take those definitions and go with it. Um,', start=1007.2, duration=7.52), FetchedTranscriptSnippet(text='I have been surprised, I think many other people\\xa0\\nhave been surprised too about how fluent AI is\\xa0\\xa0', start=1014.72, duration=6.64), FetchedTranscriptSnippet(text='at adapting to different cultural contexts and\\xa0\\nindividuals. One of my favorite features that we\\xa0\\xa0', start=1021.36, duration=5.36), FetchedTranscriptSnippet(text='have ever launched in chatbt is the the sort of\\xa0\\nenhanced memory that came out earlier this year.\\xa0\\xa0', start=1026.72, duration=5.36), FetchedTranscriptSnippet(text='like it really feels like my Chad GBT gets to\\xa0\\nknow me and what I care about and like my life\\xa0\\xa0', start=1032.08, duration=5.6), FetchedTranscriptSnippet(text='experiences and background and the things that\\xa0\\nhave led me to where they are. A friend of mine\\xa0\\xa0', start=1037.68, duration=5.04), FetchedTranscriptSnippet(text=\"recently who's been a huge CHBT user, so he's\\xa0\\ngot a lot of a a lot of he's put a lot of his\\xa0\\xa0\", start=1042.72, duration=5.6), FetchedTranscriptSnippet(text='life into all these conversations. He gave his\\xa0\\nChad GBT a bunch of personality tests and asked\\xa0\\xa0', start=1048.32, duration=6.32), FetchedTranscriptSnippet(text='them to answer as if they were him and it got\\xa0\\nthe same scores he actually got, even though\\xa0\\xa0', start=1054.64, duration=3.76), FetchedTranscriptSnippet(text=\"he'd never really talked about his personality.\\xa0\\nAnd my ChachiBD has really learned over the years\\xa0\\xa0\", start=1058.4, duration=6.08), FetchedTranscriptSnippet(text='of me talking to it about my culture, my\\xa0\\nvalues, my life. And I have used, you know,\\xa0\\xa0', start=1064.48, duration=7.52), FetchedTranscriptSnippet(text=\"I sometimes will use it in like uh I'll use like\\xa0\\na free account just to see what it's like without\\xa0\\xa0\", start=1072.0, duration=5.52), FetchedTranscriptSnippet(text=\"any of my history and it feels really really\\xa0\\ndifferent. So I think we've all been surprised on\\xa0\\xa0\", start=1077.52, duration=4.32), FetchedTranscriptSnippet(text='the upside of how good AI is at learning this and\\xa0\\nadapting. And so do you envision in many different\\xa0\\xa0', start=1081.84, duration=8.16), FetchedTranscriptSnippet(text='parts of the world people using different\\xa0\\nAIs with different sort of cultural norms and\\xa0\\xa0', start=1090.0, duration=4.0), FetchedTranscriptSnippet(text=\"contexts? Is that what we're saying? I think that\\xa0\\neveryone will use like the same fundamental model,\\xa0\\xa0\", start=1094.0, duration=4.72), FetchedTranscriptSnippet(text='but there will be context provided to that model\\xa0\\nthat will make it behave in sort of personalized\\xa0\\xa0', start=1098.72, duration=4.64), FetchedTranscriptSnippet(text=\"way they want their community wants. Whatever.\\xa0\\nI think when we're getting at this idea of facts\\xa0\\xa0\", start=1103.36, duration=5.2), FetchedTranscriptSnippet(text='and truth and uh it brings me to this seems like a\\xa0\\ngood moment for our first time travel trip. Okay,\\xa0\\xa0', start=1108.56, duration=7.28), FetchedTranscriptSnippet(text=\"we're going to 2030. This is a serious question,\\xa0\\nbut I want to ask it with a light-hearted example.\\xa0\\xa0\", start=1115.84, duration=5.6), FetchedTranscriptSnippet(text=\"Have you seen the bunnies that are jumping on\\xa0\\nthe trampoline? Yes. So, for those who haven't\\xa0\\xa0\", start=1121.44, duration=4.4), FetchedTranscriptSnippet(text='seen it, maybe it looks like backyard footage of\\xa0\\nbunnies enjoying jumping on a trampoline. And this\\xa0\\xa0', start=1125.84, duration=5.36), FetchedTranscriptSnippet(text=\"has gone incredibly viral recently. There's a\\xa0\\nhumanmade song about it. It's a whole thing.\\xa0\\xa0\", start=1131.2, duration=5.04), FetchedTranscriptSnippet(text='There were a trampoline. And I think the reason\\xa0\\nwhy people reacted so strongly to it, it was maybe\\xa0\\xa0', start=1136.24, duration=7.92), FetchedTranscriptSnippet(text='the first time people saw a video, enjoyed it,\\xa0\\nand then later found out that it was completely AI\\xa0\\xa0', start=1144.16, duration=6.32), FetchedTranscriptSnippet(text=\"generated. In this time travel trip, if we imagine\\xa0\\nin 2030, we are teenagers and we're scrolling\\xa0\\xa0\", start=1150.48, duration=6.08), FetchedTranscriptSnippet(text=\"whatever teenagers are scrolling in 2030. How do\\xa0\\nwe figure out what's real and what's not real?\\xa0\\xa0\", start=1156.56, duration=6.96), FetchedTranscriptSnippet(text='I mean, I can give all sorts of literal answers\\xa0\\nto that question. We could be cryptographically\\xa0\\xa0', start=1164.88, duration=4.64), FetchedTranscriptSnippet(text='signing stuff and we could decide who we trust\\xa0\\ntheir signature if they actually filmed something\\xa0\\xa0', start=1169.52, duration=4.32), FetchedTranscriptSnippet(text=\"or not. But but my sense is what's going to\\xa0\\nhappen is it's just going to like gradually\\xa0\\xa0\", start=1173.84, duration=7.52), FetchedTranscriptSnippet(text=\"converge. You know, even like a photo you take\\xa0\\nout of your iPhone today, it's like mostly real,\\xa0\\xa0\", start=1181.36, duration=6.08), FetchedTranscriptSnippet(text=\"but it's a little not. There's like in some AI\\xa0\\nthing running there in a way you don't understand\\xa0\\xa0\", start=1187.44, duration=4.8), FetchedTranscriptSnippet(text='and making it look like a little bit better and\\xa0\\nsometimes you see these weird things where the\\xa0\\xa0', start=1192.24, duration=3.52), FetchedTranscriptSnippet(text=\"moon. Yeah. Yeah. Yeah. Yeah. But there's like\\xa0\\na lot of processing power between the photons\\xa0\\xa0\", start=1195.76, duration=8.0), FetchedTranscriptSnippet(text=\"captured by that camera sensor and the image\\xa0\\nyou eventually see. And you've decided it's real\\xa0\\xa0\", start=1203.76, duration=5.92), FetchedTranscriptSnippet(text=\"enough or most people decided it's real enough.\\xa0\\nBut we've accepted some gradual move from when it\\xa0\\xa0\", start=1209.68, duration=5.2), FetchedTranscriptSnippet(text='was like photons hitting the film in a camera. And\\xa0\\nyou know, if you go look at some video on Tik Tok,\\xa0\\xa0', start=1214.88, duration=7.36), FetchedTranscriptSnippet(text=\"there's probably all sorts of video editing tools\\xa0\\nbeing used to make it better than real look. Yeah,\\xa0\\xa0\", start=1222.24, duration=6.0), FetchedTranscriptSnippet(text=\"exactly. Or it's just like, you know, whole\\xa0\\nscenes are completely generated or some of\\xa0\\xa0\", start=1228.24, duration=4.32), FetchedTranscriptSnippet(text='the whole videos are generated like those bunnies\\xa0\\non that trampoline. And and I think that the the\\xa0\\xa0', start=1232.56, duration=5.52), FetchedTranscriptSnippet(text='sort of like the threshold for how real does it\\xa0\\nhave to be to consider to be real will just keep\\xa0\\xa0', start=1238.08, duration=5.76), FetchedTranscriptSnippet(text=\"moving. So it's sort of a education question.\\xa0\\nIt's a people will Yeah. I mean media is always\\xa0\\xa0\", start=1243.84, duration=9.04), FetchedTranscriptSnippet(text='like a little bit real and a little bit not real.\\xa0\\nLike you know we watch like a sci-fi movie. We\\xa0\\xa0', start=1252.88, duration=5.44), FetchedTranscriptSnippet(text=\"know that didn't really happen. You watch like\\xa0\\nsomeone's like beautiful photo of themselves on\\xa0\\xa0\", start=1258.32, duration=4.56), FetchedTranscriptSnippet(text='vacation on Instagram. like, okay, maybe that\\xa0\\nphoto was like literally taken, but you know,\\xa0\\xa0', start=1262.88, duration=3.68), FetchedTranscriptSnippet(text=\"there's like tons of tourists in line for the same\\xa0\\nphoto and that's like left out of it. And I think\\xa0\\xa0\", start=1266.56, duration=3.76), FetchedTranscriptSnippet(text='we just accept that now. Certainly, a higher\\xa0\\npercentage of media both will will feel not\\xa0\\xa0', start=1270.32, duration=6.4), FetchedTranscriptSnippet(text=\"real. Um, but I think that's been the long-term\\xa0\\ntrend. Anyway, we're going to jump again. Okay,\\xa0\\xa0\", start=1276.72, duration=6.0), FetchedTranscriptSnippet(text=\"2035, we're graduating from college, you and me.\\xa0\\nThere are some leaders in the AI space that have\\xa0\\xa0\", start=1282.72, duration=5.6), FetchedTranscriptSnippet(text='said that in 5 years half of the entry level\\xa0\\nwhite collar workforce will be replaced by AI.\\xa0\\xa0', start=1288.32, duration=6.16), FetchedTranscriptSnippet(text=\"So we're college graduates in 5 years. What do\\xa0\\nyou hope the world looks like for us? I think\\xa0\\xa0\", start=1294.48, duration=4.8), FetchedTranscriptSnippet(text=\"there's been a lot of talk about how AI might\\xa0\\ncause job displacement, but I'm also curious. I\\xa0\\xa0\", start=1299.28, duration=6.48), FetchedTranscriptSnippet(text='have a job that nobody would have thought we\\xa0\\ncould have, you know, totally a decade ago.\\xa0\\xa0', start=1305.76, duration=6.16), FetchedTranscriptSnippet(text=\"What are the things that we could look ahead if\\xa0\\nwe're thinking about in 2035 that like graduating\\xa0\\xa0\", start=1311.92, duration=5.2), FetchedTranscriptSnippet(text='college student, if they still go to college at\\xa0\\nall, could very well be like leaving on a mission\\xa0\\xa0', start=1317.12, duration=5.68), FetchedTranscriptSnippet(text='to explore the solar system on a spaceship in some\\xa0\\nkind of completely new exciting, super well- paid,\\xa0\\xa0', start=1322.8, duration=4.96), FetchedTranscriptSnippet(text='super interesting job and feeling so bad for you\\xa0\\nand I that like we had to do this kind of like\\xa0\\xa0', start=1327.76, duration=4.4), FetchedTranscriptSnippet(text='really boring old kind of work and everything\\xa0\\nis just better. Like I I 10 years feels very\\xa0\\xa0', start=1332.16, duration=6.32), FetchedTranscriptSnippet(text=\"hard to imagine at this point because it's too\\xa0\\nfar. It's too far. If you compound the current\\xa0\\xa0\", start=1338.48, duration=4.48), FetchedTranscriptSnippet(text=\"rate of change for 10 more years, it's probably\\xa0\\nsomething we can't even time travel trips. I 10\\xa0\\xa0\", start=1342.96, duration=5.68), FetchedTranscriptSnippet(text='like I mean I think now would be really hard\\xa0\\nto imagine 10 years ago. Yeah. Uh but I think\\xa0\\xa0', start=1348.64, duration=6.32), FetchedTranscriptSnippet(text=\"10 years forward will be even much harder, much\\xa0\\nmore different. So let's make it 5 years. We're\\xa0\\xa0\", start=1354.96, duration=6.08), FetchedTranscriptSnippet(text=\"still going to 2030. I'm curious what you\\xa0\\nthink the pretty short-term impacts of this\\xa0\\xa0\", start=1361.04, duration=5.2), FetchedTranscriptSnippet(text='will be for for young people. I mean, these like\\xa0\\nhalf of entry- level jobs replaced by AI makes\\xa0\\xa0', start=1366.24, duration=6.8), FetchedTranscriptSnippet(text='it sound like a very different world that they\\xa0\\nwould be entering than the one that I did. Um,', start=1373.04, duration=9.12), FetchedTranscriptSnippet(text=\"I think it's totally true that some classes of\\xa0\\njobs will totally go away. This always happens\\xa0\\xa0\", start=1382.16, duration=4.32), FetchedTranscriptSnippet(text=\"and young people are the best at adapting to this.\\xa0\\nI'm more worried about what it means, not for the\\xa0\\xa0\", start=1386.48, duration=4.08), FetchedTranscriptSnippet(text=\"like 22-y old, but for the 62-y old that doesn't\\xa0\\nwant to go re retrain or reskill or whatever the\\xa0\\xa0\", start=1390.56, duration=6.88), FetchedTranscriptSnippet(text='politicians call it that no one actually wants\\xa0\\nbut politicians and most of the time. If I were\\xa0\\xa0', start=1397.44, duration=6.0), FetchedTranscriptSnippet(text='22 right now and graduating college, I would\\xa0\\nfeel like the luckiest kid in all of history.\\xa0\\xa0', start=1403.44, duration=4.24), FetchedTranscriptSnippet(text=\"Why? Because there's never been a more amazing\\xa0\\ntime to go create something totally new, to go\\xa0\\xa0\", start=1407.68, duration=5.44), FetchedTranscriptSnippet(text='invent something, to start a company, whatever\\xa0\\nit is. I think it is probably possible now to\\xa0\\xa0', start=1413.12, duration=5.2), FetchedTranscriptSnippet(text='start a company that is a oneperson company that\\xa0\\nwill go on to be worth like more than a billion\\xa0\\xa0', start=1418.32, duration=4.0), FetchedTranscriptSnippet(text='dollars and more importantly than that deliver an\\xa0\\namazing product and service to the world and that\\xa0\\xa0', start=1422.32, duration=4.24), FetchedTranscriptSnippet(text='that is like a crazy thing. You have access to\\xa0\\ntools that can let you do what used to take teams\\xa0\\xa0', start=1426.56, duration=5.92), FetchedTranscriptSnippet(text='of hundreds and you just have to like you know\\xa0\\nlearn how to use these tools and come up with a\\xa0\\xa0', start=1432.48, duration=6.0), FetchedTranscriptSnippet(text=\"great idea and it's it's like quite amazing. If\\xa0\\nwe take a step back, I think the most important\\xa0\\xa0\", start=1438.48, duration=7.2), FetchedTranscriptSnippet(text='thing that this audience could hear from you\\xa0\\non this optimistic show is in two parts. First,\\xa0\\xa0', start=1445.68, duration=7.52), FetchedTranscriptSnippet(text=\"there's tactically, how are you actually trying\\xa0\\nto build the world's most powerful intelligence\\xa0\\xa0\", start=1453.2, duration=7.36), FetchedTranscriptSnippet(text='and what are the rate limiting factors to doing\\xa0\\nthat? And then philosophically, how are you and\\xa0\\xa0', start=1460.56, duration=5.52), FetchedTranscriptSnippet(text='others working on building that technology in\\xa0\\na way that really helps and not hurts people?\\xa0\\xa0', start=1466.08, duration=4.72), FetchedTranscriptSnippet(text='So just taking the tactical part right now.\\xa0\\nMy understanding is that there are three big\\xa0\\xa0', start=1470.8, duration=6.4), FetchedTranscriptSnippet(text='categories that have been limiting factors for\\xa0\\nAI. The first is compute, the second is data and\\xa0\\xa0', start=1477.2, duration=6.08), FetchedTranscriptSnippet(text='the third is algorithmic design. How do you think\\xa0\\nabout each of those three categories right now?\\xa0\\xa0', start=1483.28, duration=6.16), FetchedTranscriptSnippet(text='And if you were to help someone understand\\xa0\\nthe next headlines that they might see,\\xa0\\xa0', start=1489.44, duration=4.96), FetchedTranscriptSnippet(text=\"how would you help them make sense of all this?\\xa0\\nI I would say there's a fourth too which is uh\\xa0\\xa0\", start=1494.4, duration=7.28), FetchedTranscriptSnippet(text='figuring out the products to build like techn like\\xa0\\nscientific progress on its own not put into the\\xa0\\xa0', start=1501.68, duration=5.2), FetchedTranscriptSnippet(text=\"hands of people is of limited utility and doesn't\\xa0\\nsort of co-evolve with society in the same way\\xa0\\xa0\", start=1506.88, duration=4.88), FetchedTranscriptSnippet(text='but if I could hit all four of those um so on\\xa0\\nthe compute side yeah this is like the biggest\\xa0\\xa0', start=1511.76, duration=5.44), FetchedTranscriptSnippet(text=\"infrastructure project certainly that I've ever\\xa0\\nseen possibly it will become the I think it will\\xa0\\xa0\", start=1517.2, duration=4.16), FetchedTranscriptSnippet(text='maybe already is the biggest and most expensive\\xa0\\none in human history but the the whole supply\\xa0\\xa0', start=1521.36, duration=6.16), FetchedTranscriptSnippet(text='chain from making the chips and the memory and\\xa0\\nthe networking gear, racking them up in servers,\\xa0\\xa0', start=1527.52, duration=6.56), FetchedTranscriptSnippet(text='doing, you know, a giant construction project to\\xa0\\nbuild like a mega mega data center, putting the,\\xa0\\xa0', start=1534.08, duration=6.32), FetchedTranscriptSnippet(text='you know, finding a way to get the energy, which\\xa0\\nis often a limiting factor piece of this and all\\xa0\\xa0', start=1540.4, duration=4.24), FetchedTranscriptSnippet(text=\"the other components together. This is hugely\\xa0\\ncomplex and expensive. And we are we're still\\xa0\\xa0\", start=1544.64, duration=4.88), FetchedTranscriptSnippet(text=\"doing this in like a sort of bespoke one-off way\\xa0\\nalthough it's getting better. Like eventually we\\xa0\\xa0\", start=1549.52, duration=7.28), FetchedTranscriptSnippet(text='will just design a whole kind of like mega factory\\xa0\\nthat takes you know I mean spiritually it will be\\xa0\\xa0', start=1556.8, duration=8.48), FetchedTranscriptSnippet(text='melting sand on one end and putting out fully\\xa0\\nbuilt AI compute on the other but we are a long\\xa0\\xa0', start=1565.28, duration=5.12), FetchedTranscriptSnippet(text=\"way to go from that and it's a it's an enormously\\xa0\\ncomplex and expensive process. uh we are putting\\xa0\\xa0\", start=1570.4, duration=10.0), FetchedTranscriptSnippet(text='a huge amount of work into building out as much\\xa0\\ncompute as we can and to do it fast and you know\\xa0\\xa0', start=1580.4, duration=5.36), FetchedTranscriptSnippet(text=\"it's going to be like sad because GP5 is going\\xa0\\nto launch and there's going to be another big\\xa0\\xa0\", start=1585.76, duration=4.32), FetchedTranscriptSnippet(text=\"spike in demand and we're not going to be able\\xa0\\nto serve it and it's going to be like those early\\xa0\\xa0\", start=1590.08, duration=3.28), FetchedTranscriptSnippet(text='GPD4 days and the world just wants much more AI\\xa0\\nthan we can currently deliver and building more\\xa0\\xa0', start=1593.36, duration=6.24), FetchedTranscriptSnippet(text=\"compute is an important part of doing that.\\xa0\\nThat's actually this is what I expect to turn\\xa0\\xa0\", start=1599.6, duration=4.16), FetchedTranscriptSnippet(text='the majority of my attention to is how we build\\xa0\\ncompute at much greater scales. Uh so how we go\\xa0\\xa0', start=1603.76, duration=6.88), FetchedTranscriptSnippet(text='from millions to tens of millions and hundreds of\\xa0\\nmillions and eventually hopefully billions of GPUs\\xa0\\xa0', start=1610.64, duration=5.68), FetchedTranscriptSnippet(text=\"that are sort of in service of what people want\\xa0\\nto do with this. When you're thinking about it,\\xa0\\xa0\", start=1616.32, duration=3.68), FetchedTranscriptSnippet(text=\"what are the big challenges here in this category\\xa0\\nthat you're going to be thinking about? We're\\xa0\\xa0\", start=1620.0, duration=4.24), FetchedTranscriptSnippet(text=\"currently most limited by energy. um you know like\\xa0\\nif you're gonna you want to run a gigawatt scale\\xa0\\xa0\", start=1624.24, duration=6.72), FetchedTranscriptSnippet(text=\"data center it's like a gigawatt how hard can that\\xa0\\nbe to find it's really hard to find a gigawatt of\\xa0\\xa0\", start=1630.96, duration=3.92), FetchedTranscriptSnippet(text=\"power available in short term we're also very much\\xa0\\nlimited by the processing chips and the memory\\xa0\\xa0\", start=1634.88, duration=7.12), FetchedTranscriptSnippet(text=\"chips uh how you package these all together how\\xa0\\nyou build the racks and then there's like a list\\xa0\\xa0\", start=1642.0, duration=4.0), FetchedTranscriptSnippet(text=\"of other things that are you know there's like\\xa0\\npermits there's construction work uh but but\\xa0\\xa0\", start=1646.0, duration=6.16), FetchedTranscriptSnippet(text='again the goal here will be to really automate\\xa0\\nthis once we get some of those robots built,\\xa0\\xa0', start=1652.16, duration=5.12), FetchedTranscriptSnippet(text='they can help us automate it even more. But just,\\xa0\\nyou know, like a world where you can basically\\xa0\\xa0', start=1657.28, duration=3.92), FetchedTranscriptSnippet(text=\"pour in money and get out a pre-built data center.\\xa0\\nUh so that'll be that'll be a huge unlock if we\\xa0\\xa0\", start=1661.2, duration=6.8), FetchedTranscriptSnippet(text='can get it to work. Second category, data. Yeah,\\xa0\\nthese models have gotten so smart. There was a\\xa0\\xa0', start=1668.0, duration=6.32), FetchedTranscriptSnippet(text='time when we could just feed it another physics\\xa0\\ntextbook and got a little bit smarter at physics,\\xa0\\xa0', start=1674.32, duration=4.4), FetchedTranscriptSnippet(text='but now like honestly GBT5 understands\\xa0\\neverything in a physics textbook pretty well.\\xa0\\xa0', start=1678.72, duration=5.76), FetchedTranscriptSnippet(text=\"We're excited about synthetic data. We're very\\xa0\\nexcited about our users helping us create harder\\xa0\\xa0\", start=1684.48, duration=5.52), FetchedTranscriptSnippet(text=\"and harder tasks and environments to go off and\\xa0\\nhave the system solve. But uh I think we're data\\xa0\\xa0\", start=1690.0, duration=6.88), FetchedTranscriptSnippet(text=\"will always be important, but we're entering a\\xa0\\nrealm where the models need to learn things that\\xa0\\xa0\", start=1696.88, duration=7.52), FetchedTranscriptSnippet(text=\"don't exist in any data set yet. They have to\\xa0\\ngo discover new things. So that's like a crazy\\xa0\\xa0\", start=1704.4, duration=3.52), FetchedTranscriptSnippet(text='new How do you teach a model to discover new\\xa0\\nthings? Well, humans can do it. like we can\\xa0\\xa0', start=1707.92, duration=4.48), FetchedTranscriptSnippet(text='go off and come up with hypotheses and test them\\xa0\\nand get experimental results and update on what we\\xa0\\xa0', start=1712.4, duration=4.4), FetchedTranscriptSnippet(text=\"learn. So probably the same kind of way. And then\\xa0\\nthere's algorithmic design. Yeah, we've made huge\\xa0\\xa0\", start=1716.8, duration=5.36), FetchedTranscriptSnippet(text='progress on algorithmic design. Uh the thing that\\xa0\\nthe thing that I think open does best in the world\\xa0\\xa0', start=1722.16, duration=5.44), FetchedTranscriptSnippet(text='is we have built this culture of repeated and big\\xa0\\nalgorithmic research gains. So we kind of you know\\xa0\\xa0', start=1727.6, duration=7.76), FetchedTranscriptSnippet(text=\"figured out the what became the GPT paradigm. We\\xa0\\nfigured out became the reasoning paradigm. We're\\xa0\\xa0\", start=1735.36, duration=5.2), FetchedTranscriptSnippet(text='working on some new ones now. Um, but it is very\\xa0\\nexciting to me to think that there are still many\\xa0\\xa0', start=1740.56, duration=5.68), FetchedTranscriptSnippet(text='more orders of magnitudes of algorithmic\\xa0\\ngains ahead of us. We we just yesterday\\xa0\\xa0', start=1746.24, duration=5.04), FetchedTranscriptSnippet(text=\"uh released a model called GPOSS, open source\\xa0\\nmodel. It's a model that is as smart as 04 Mini,\\xa0\\xa0\", start=1751.28, duration=6.24), FetchedTranscriptSnippet(text='which is a very smart model that runs locally on\\xa0\\na laptop. And this blows my mind. Yeah. Like if\\xa0\\xa0', start=1757.52, duration=6.4), FetchedTranscriptSnippet(text=\"you had asked me a few years ago when we'd have\\xa0\\na model of that intelligence running on a laptop,\\xa0\\xa0\", start=1763.92, duration=5.92), FetchedTranscriptSnippet(text='I would have said many many years in the future.\\xa0\\nBut then we we found some algorithmic gains\\xa0\\xa0', start=1769.84, duration=6.88), FetchedTranscriptSnippet(text='um particularly around reasoning but also some\\xa0\\nother things that let us do a a tiny model that\\xa0\\xa0', start=1776.72, duration=4.88), FetchedTranscriptSnippet(text=\"can do this amazing thing. And you know those are\\xa0\\nthose are the most fun things. That's like kind of\\xa0\\xa0\", start=1781.6, duration=5.28), FetchedTranscriptSnippet(text=\"the coolest part of the job. I can see you really\\xa0\\nenjoying thinking about this. I'm curious for\\xa0\\xa0\", start=1786.88, duration=5.04), FetchedTranscriptSnippet(text=\"people who don't quite know what you're talking\\xa0\\nabout, who aren't familiar with how an algorithmic\\xa0\\xa0\", start=1791.92, duration=5.68), FetchedTranscriptSnippet(text='design would lead to a better experience that they\\xa0\\nactually use. Could you summarize the state of\\xa0\\xa0', start=1797.6, duration=5.52), FetchedTranscriptSnippet(text=\"things right now? Like what what is it that you're\\xa0\\nthinking about when you're thinking about how fun\\xa0\\xa0\", start=1803.12, duration=3.68), FetchedTranscriptSnippet(text=\"this problem is? Let me start back in history\\xa0\\nand then I'll get to some things for today. So,\\xa0\\xa0\", start=1806.8, duration=4.96), FetchedTranscriptSnippet(text='GPT1 was an idea at the time that was quite\\xa0\\nmocked by a lot of experts in the field,\\xa0\\xa0', start=1811.76, duration=7.84), FetchedTranscriptSnippet(text='which was can we train a model to play a little\\xa0\\ngame, which is show it a bunch of words and have\\xa0\\xa0', start=1819.6, duration=5.84), FetchedTranscriptSnippet(text=\"it guess the one that comes next in the sequence.\\xa0\\nThat's called unsupervised learning. There's not\\xa0\\xa0\", start=1825.44, duration=3.76), FetchedTranscriptSnippet(text=\"you're not really saying like this is a cat,\\xa0\\nthis is a dog. You're saying here's some words,\\xa0\\xa0\", start=1829.2, duration=3.04), FetchedTranscriptSnippet(text='guess the next one. And the fact that that can\\xa0\\ngo learn these very complicated concepts that\\xa0\\xa0', start=1832.24, duration=10.08), FetchedTranscriptSnippet(text='can go learn all the stuff about physics and math\\xa0\\nand programming and keep predicting the word that\\xa0\\xa0', start=1842.32, duration=4.08), FetchedTranscriptSnippet(text='comes next and next and next and next seemed\\xa0\\nludicrous, magical, unlikely to work. Like how\\xa0\\xa0', start=1846.4, duration=6.88), FetchedTranscriptSnippet(text='was that all going to get encoded? And yet humans\\xa0\\ndo it. you know, babies start hearing language and\\xa0\\xa0', start=1853.28, duration=5.2), FetchedTranscriptSnippet(text='figure out what it means kind of largely uh or at\\xa0\\nleast to some significant degree on their own. And\\xa0\\xa0', start=1858.48, duration=9.68), FetchedTranscriptSnippet(text='and so we did it and then we also realized that if\\xa0\\nwe scaled it up, it got better and better, but we\\xa0\\xa0', start=1868.16, duration=5.92), FetchedTranscriptSnippet(text=\"had to scale over many many orders of magnitude.\\xa0\\nSo it wasn't that good in the GPT1 day. It wasn't\\xa0\\xa0\", start=1874.08, duration=4.4), FetchedTranscriptSnippet(text='good at all in the GPT1 days. And a lot of experts\\xa0\\nin the field said, \"Oh, this is ridiculous. It\\'s\\xa0\\xa0', start=1878.48, duration=4.64), FetchedTranscriptSnippet(text='never going to work. It\\'s not going to be robust.\"\\xa0\\nBut we had these things called scaling laws. And\\xa0\\xa0', start=1883.12, duration=3.52), FetchedTranscriptSnippet(text='we said, \"Okay, so this gets predictably better as\\xa0\\nwe increase compute, memory, data, whatever. And\\xa0\\xa0', start=1886.64, duration=5.12), FetchedTranscriptSnippet(text='we can we can decide we can use those predictions\\xa0\\nto make decisions about how to scale this up and\\xa0\\xa0', start=1891.76, duration=7.36), FetchedTranscriptSnippet(text='do it and get great results.\" And that has worked\\xa0\\nover Yeah. a crazy number of orders of magnitude.\\xa0\\xa0', start=1899.12, duration=8.16), FetchedTranscriptSnippet(text='And it was so not obvious at the time. like\\xa0\\nthat was that was I think the the reason the\\xa0\\xa0', start=1907.28, duration=3.6), FetchedTranscriptSnippet(text='world was so surprised is that that seemed like\\xa0\\nsuch an unlikely finding. Another one was that we\\xa0\\xa0', start=1910.88, duration=6.0), FetchedTranscriptSnippet(text=\"could use these language models with reinforcement\\xa0\\nlearning where we're saying this is good, this is\\xa0\\xa0\", start=1916.88, duration=4.08), FetchedTranscriptSnippet(text='bad to teach it how to reason. And this led to the\\xa0\\n01 and 03 and now the GBT5 progress. And that that\\xa0\\xa0', start=1920.96, duration=10.32), FetchedTranscriptSnippet(text=\"was another thing that felt like uh if it works\\xa0\\nit's really great but like no way this is going\\xa0\\xa0\", start=1931.28, duration=4.48), FetchedTranscriptSnippet(text=\"to work. It's too simple. And now we're on to new\\xa0\\nthings. We've figured out how to make much better\\xa0\\xa0\", start=1935.76, duration=5.92), FetchedTranscriptSnippet(text='video models. We are we are discovering new ways\\xa0\\nto use new kinds of data and environment to kind\\xa0\\xa0', start=1941.68, duration=7.2), FetchedTranscriptSnippet(text=\"of scale that up as well. Um and I think again\\xa0\\nyou know 5 10 years out that's too hard to say in\\xa0\\xa0\", start=1948.88, duration=7.92), FetchedTranscriptSnippet(text='this field but the next couple of years we have\\xa0\\nvery smooth very strong scaling in front of us.\\xa0\\xa0', start=1956.8, duration=4.8), FetchedTranscriptSnippet(text='I think it has become a sort of public narrative\\xa0\\nthat we are on this smooth path from one to two to\\xa0\\xa0', start=1961.6, duration=6.32), FetchedTranscriptSnippet(text=\"three to four to five to more. Yeah. But it also\\xa0\\nis true behind the scenes that it's a it's not\\xa0\\xa0\", start=1967.92, duration=7.12), FetchedTranscriptSnippet(text=\"linear like that. It's messier. Tell us a little\\xa0\\nbit about the mess before GPT5. What was what were\\xa0\\xa0\", start=1975.04, duration=7.68), FetchedTranscriptSnippet(text='the interesting problems that you needed to solve?\\xa0\\nUm, we did a model called Orion that we released\\xa0\\xa0', start=1982.72, duration=6.24), FetchedTranscriptSnippet(text=\"as GPT 4.5. And we had we did too big of a\\xa0\\nmodel. It was just it was it's a very cool model,\\xa0\\xa0\", start=1988.96, duration=8.08), FetchedTranscriptSnippet(text=\"but it's unwieldly to use. And we realized that\\xa0\\nfor kind of some of the research we need to do on\\xa0\\xa0\", start=1997.04, duration=3.76), FetchedTranscriptSnippet(text='top of a model, we need a different shape. So we\\xa0\\nwe followed one scaling law that kept being good\\xa0\\xa0', start=2000.8, duration=6.0), FetchedTranscriptSnippet(text='without without really internalizing. There was\\xa0\\na new even steeper scaling law that we got better\\xa0\\xa0', start=2006.8, duration=4.08), FetchedTranscriptSnippet(text='returns for compute on, which was this reasoning\\xa0\\nthing. So that was like one alley we went down and\\xa0\\xa0', start=2010.88, duration=4.88), FetchedTranscriptSnippet(text=\"turned around, but that's fine. That's part of\\xa0\\nresearch. Um, we had some problems with the way\\xa0\\xa0\", start=2015.76, duration=3.92), FetchedTranscriptSnippet(text='we think about our data sets as these models like\\xa0\\nreally have to get get this big and um, you know,\\xa0\\xa0', start=2019.68, duration=6.16), FetchedTranscriptSnippet(text='learn from this much data. So So yeah, I think\\xa0\\nlike in the in the middle of it in the day-to-day,\\xa0\\xa0', start=2025.84, duration=5.68), FetchedTranscriptSnippet(text='you kind of you make a lot of U-turns as\\xa0\\nyou try things or you have an architecture\\xa0\\xa0', start=2031.52, duration=3.68), FetchedTranscriptSnippet(text=\"idea that doesn't work, but the the aggregate the\\xa0\\nsummation of all the squiggles has been remarkably\\xa0\\xa0\", start=2035.2, duration=7.44), FetchedTranscriptSnippet(text='smooth on the exponential. One of the\\xa0\\nthings I always find interesting is that\\xa0\\xa0', start=2043.28, duration=3.92), FetchedTranscriptSnippet(text=\"by the time I'm sitting here interviewing\\xa0\\nyou about the thing that you just put out,\\xa0\\xa0\", start=2047.2, duration=4.96), FetchedTranscriptSnippet(text=\"you're thinking about Exactly. What are the things\\xa0\\nthat you can share that are at least the problems\\xa0\\xa0\", start=2052.16, duration=6.72), FetchedTranscriptSnippet(text=\"that you're thinking about that I would be\\xa0\\ninterviewing you about in a year if I came back?\", start=2058.88, duration=8.16), FetchedTranscriptSnippet(text=\"I mean, possibly you'll be asking me like,\\xa0\\nwhat does it mean that this thing can go\\xa0\\xa0\", start=2070.16, duration=4.0), FetchedTranscriptSnippet(text='discover new science? Yeah. What how how\\xa0\\nis the world supposed to think about GPT6\\xa0\\xa0', start=2074.16, duration=6.0), FetchedTranscriptSnippet(text=\"discovering new science? Now, maybe\\xa0\\nnot like maybe we don't deliver that,\\xa0\\xa0\", start=2080.16, duration=3.12), FetchedTranscriptSnippet(text='but it feels within grasp. If you did, what\\xa0\\nwould you say? What would your what would the\\xa0\\xa0', start=2083.28, duration=6.48), FetchedTranscriptSnippet(text='implications of that kind of achievement\\xa0\\nbe? Imagine you do succeed. Yeah. I mean,\\xa0\\xa0', start=2089.76, duration=5.2), FetchedTranscriptSnippet(text='I think the great parts will be great. the bad\\xa0\\nparts will be scary and the bizarre parts will\\xa0\\xa0', start=2094.96, duration=3.36), FetchedTranscriptSnippet(text=\"be like bizarre on the first day and then we'll\\xa0\\nget used to them really fast. So we'll be like,\\xa0\\xa0\", start=2098.32, duration=4.96), FetchedTranscriptSnippet(text='\"Oh, it\\'s incredible that this is like being\\xa0\\nused to cure disease and be like, oh, it\\'s\\xa0\\xa0', start=2103.28, duration=4.64), FetchedTranscriptSnippet(text='extremely scary that models like this are being\\xa0\\nused to like create new biocurity threats.\" And\\xa0\\xa0', start=2107.92, duration=6.96), FetchedTranscriptSnippet(text=\"then we'll also be like, man, it's really weird\\xa0\\nto like live through watching the world speed up\\xa0\\xa0\", start=2114.88, duration=4.72), FetchedTranscriptSnippet(text='so much and you know the economy grows so fast\\xa0\\nand the like it will feel like vertigo inducing\\xa0\\xa0', start=2119.6, duration=10.56), FetchedTranscriptSnippet(text='uh the sort of the rate of change and then like\\xa0\\nhappens with everything else the remarkable\\xa0\\xa0', start=2130.16, duration=6.88), FetchedTranscriptSnippet(text=\"ability of of people of humanity to adapt to kind\\xa0\\nof like any amount of change. we'll just be like,\\xa0\\xa0\", start=2137.04, duration=5.52), FetchedTranscriptSnippet(text='\"Okay, you know, this is like this is it.\" Um, a\\xa0\\nkid born today will never be smarter than AI ever.\\xa0\\xa0', start=2142.56, duration=9.12), FetchedTranscriptSnippet(text='And a kid born today, by the time that kid like\\xa0\\nkind of understands the way the world works, will\\xa0\\xa0', start=2151.68, duration=5.76), FetchedTranscriptSnippet(text='just always be used to an incredibly fast rate of\\xa0\\nthings improving and discovering new science. They\\xa0\\xa0', start=2157.44, duration=6.16), FetchedTranscriptSnippet(text='will just they will never know any other world. It\\xa0\\nwill seem totally natural. will seem unthinkable\\xa0\\xa0', start=2163.6, duration=4.08), FetchedTranscriptSnippet(text='and stone age like that we used to use computers\\xa0\\nor phones or any kind of technology that was not\\xa0\\xa0', start=2167.68, duration=5.6), FetchedTranscriptSnippet(text=\"way smarter than we were. You know, we will think\\xa0\\nlike how bad those people of the 2020s had it. I'm\\xa0\\xa0\", start=2173.28, duration=6.0), FetchedTranscriptSnippet(text=\"thinking about having kids. You should. It's the\\xa0\\nbest thing ever. I know you just had your first\\xa0\\xa0\", start=2179.28, duration=3.92), FetchedTranscriptSnippet(text='kid. How does what you just said affect how I\\xa0\\nshould think about parenting a kid in that world?', start=2183.2, duration=10.08), FetchedTranscriptSnippet(text=\"What advice would you give me? Probably nothing\\xa0\\ndifferent than the way you've been parenting kids\\xa0\\xa0\", start=2195.36, duration=4.16), FetchedTranscriptSnippet(text='for tens of thousands of years. Like love your\\xa0\\nkids, show them the world, like support them in\\xa0\\xa0', start=2199.52, duration=4.88), FetchedTranscriptSnippet(text=\"whatever they want to do and teach them like how\\xa0\\nto be a good person. And that probably is what's\\xa0\\xa0\", start=2204.4, duration=5.52), FetchedTranscriptSnippet(text=\"going to matter. It sounds a little bit like\\xa0\\nsome of the you know you've said a couple of\\xa0\\xa0\", start=2209.92, duration=5.76), FetchedTranscriptSnippet(text='things like this that that you know you might not\\xa0\\ngo to college you might there there are a couple\\xa0\\xa0', start=2215.68, duration=6.72), FetchedTranscriptSnippet(text=\"of things that you've said so far that feed into\\xa0\\nthis I think and it sounds like what you're saying\\xa0\\xa0\", start=2222.4, duration=4.64), FetchedTranscriptSnippet(text='is there will be more optionality for them in a\\xa0\\nin a world that you envision and therefore they\\xa0\\xa0', start=2227.04, duration=8.48), FetchedTranscriptSnippet(text=\"will have more more ability to say I want to build\\xa0\\nthis here's the superpowered tool that will help\\xa0\\xa0\", start=2235.52, duration=5.6), FetchedTranscriptSnippet(text='me do that or yeah like I want my kid to think\\xa0\\nI had a terrible constrained life and that he\\xa0\\xa0', start=2241.12, duration=6.0), FetchedTranscriptSnippet(text='has this incredible infinite canvas of stuff to\\xa0\\ndo that that that is like the way of the world.\\xa0\\xa0', start=2247.12, duration=7.6), FetchedTranscriptSnippet(text=\"We've said that uh 2035 is a little bit too far in\\xa0\\nthe future to think about. So maybe this this was\\xa0\\xa0\", start=2254.72, duration=6.0), FetchedTranscriptSnippet(text='going to be a jump to 2040 but maybe it will keep\\xa0\\nit shorter than that. When I think about the area\\xa0\\xa0', start=2260.72, duration=4.32), FetchedTranscriptSnippet(text='where AI could have for both our kids and us the\\xa0\\nbiggest genuinely positive impact on all of us,\\xa0\\xa0', start=2265.04, duration=6.8), FetchedTranscriptSnippet(text=\"it's health. So if we are in pick your year, call\\xa0\\nit 2035 and I'm sitting here and I'm interviewing\\xa0\\xa0\", start=2271.84, duration=7.52), FetchedTranscriptSnippet(text=\"the dean of Stanford medicine, what do you hope\\xa0\\nthat he's telling me AI is doing for our health\\xa0\\xa0\", start=2279.36, duration=6.56), FetchedTranscriptSnippet(text='in 2035? Start with 2025. Okay. Um yeah, please.\\xa0\\nOne of the things we are most proud of with GPT5\\xa0\\xa0', start=2285.92, duration=8.24), FetchedTranscriptSnippet(text=\"is how much better it's gotten at health advice.\\xa0\\nUm, people have used the GPT4 models a lot for\\xa0\\xa0\", start=2294.16, duration=7.52), FetchedTranscriptSnippet(text=\"health advice. And you know, I'm sure you've seen\\xa0\\nsome of these things on the internet where people\\xa0\\xa0\", start=2301.68, duration=4.72), FetchedTranscriptSnippet(text='are like, I had this life-threatening disease\\xa0\\nand no doctor could figure it out and I like\\xa0\\xa0', start=2306.4, duration=4.88), FetchedTranscriptSnippet(text='put my symptoms and a blood test into CHBT. It\\xa0\\ntold me exactly the rare thing I had. I went to\\xa0\\xa0', start=2311.28, duration=4.48), FetchedTranscriptSnippet(text=\"a doctor. I took a pill. I'm cured. Like that's\\xa0\\namazing. obviously and a huge fraction of ChatGpt\\xa0\\xa0\", start=2315.76, duration=7.28), FetchedTranscriptSnippet(text='queries are health related. So we wanted to get\\xa0\\nreally good at this and we invested a lot in\\xa0\\xa0', start=2323.04, duration=4.08), FetchedTranscriptSnippet(text='GPT5 is significantly better at healthcare related\\xa0\\nqueries. What does better mean here? It gives you\\xa0\\xa0', start=2327.12, duration=6.32), FetchedTranscriptSnippet(text='a better answer just more accurate more accurate\\xa0\\nhallucinates less uh more likely to like tell you\\xa0\\xa0', start=2333.44, duration=5.52), FetchedTranscriptSnippet(text='what you actually have what you actually should\\xa0\\ndo. Um, yeah, and better healthcare is wonderful,\\xa0\\xa0', start=2338.96, duration=7.28), FetchedTranscriptSnippet(text='but obviously what people actually want\\xa0\\nis to just not have disease. And by 2035,\\xa0\\xa0', start=2346.24, duration=6.24), FetchedTranscriptSnippet(text='I think we will be able to use these tools to\\xa0\\ncure a significant number or at least treat a\\xa0\\xa0', start=2352.48, duration=7.44), FetchedTranscriptSnippet(text=\"significant number of diseases that currently\\xa0\\nplague us. I think that'll be one of the most\\xa0\\xa0\", start=2359.92, duration=5.84), FetchedTranscriptSnippet(text='viscerally felt benefits of of AI. People talk a\\xa0\\nlot about how AI will revolutionize healthcare,\\xa0\\xa0', start=2365.76, duration=7.44), FetchedTranscriptSnippet(text=\"but I'm curious to go one turn deeper on\\xa0\\nspecifically what you're imagining. Like,\\xa0\\xa0\", start=2373.2, duration=4.72), FetchedTranscriptSnippet(text='is it that these AI systems could have helped\\xa0\\nus see GLP-1s earlier, this medication that has\\xa0\\xa0', start=2377.92, duration=6.72), FetchedTranscriptSnippet(text=\"been around for a long time, but we didn't know\\xa0\\nabout this other effect? Is it that, you know,\\xa0\\xa0\", start=2384.64, duration=3.92), FetchedTranscriptSnippet(text='alpha fold and protein folding is helping create\\xa0\\nnew medicines? I would like to be able to ask GBT\\xa0\\xa0', start=2388.56, duration=7.84), FetchedTranscriptSnippet(text='8 to go cure a particular cancer and I would like\\xa0\\nGPT8 to go off and think and then say uh okay I\\xa0\\xa0', start=2396.4, duration=7.6), FetchedTranscriptSnippet(text='read everything I could find. I have these ideas.\\xa0\\nI need you to uh go get a lab technician to run\\xa0\\xa0', start=2404.0, duration=5.12), FetchedTranscriptSnippet(text='these nine experiments and tell me what you find\\xa0\\nfor each of them. And you know wait 2 months for\\xa0\\xa0', start=2409.12, duration=4.56), FetchedTranscriptSnippet(text='the cells to do their thing. Send the results back\\xa0\\nto GBT8. Say I tried it. Here you go. Think think.\\xa0\\xa0', start=2413.68, duration=5.36), FetchedTranscriptSnippet(text='Say okay I just need one more experiment. That was\\xa0\\na surprise. Run one more experiment. Give it back.\\xa0\\xa0', start=2419.04, duration=4.96), FetchedTranscriptSnippet(text='GPT says, \"Okay, go synthesize this molecule and\\xa0\\ntry, you know, mouse studies or whatever.\" Okay,\\xa0\\xa0', start=2424.0, duration=6.16), FetchedTranscriptSnippet(text=\"that was good. Like, try human studies. Okay,\\xa0\\ngreat. It worked. Um, here's how to like run\\xa0\\xa0\", start=2430.16, duration=3.68), FetchedTranscriptSnippet(text=\"it through the FDA. I think anyone with a loved\\xa0\\none who's died of cancer would also really like\\xa0\\xa0\", start=2433.84, duration=5.44), FetchedTranscriptSnippet(text=\"that. Okay, we're going to jump again. Okay. I was\\xa0\\ngoing to say 2050, but again, all of my timelines\\xa0\\xa0\", start=2439.28, duration=5.28), FetchedTranscriptSnippet(text=\"are getting much, much shorter. But I It does\\xa0\\nfeel like the world's going very fast now. It\\xa0\\xa0\", start=2444.56, duration=4.24), FetchedTranscriptSnippet(text='does. Yeah. And when I talk to other leaders in\\xa0\\nAI, one of the things that they refer to is the\\xa0\\xa0', start=2448.8, duration=7.6), FetchedTranscriptSnippet(text='industrial revolution. They say, \"I chose 2050\\xa0\\nbecause I\\'ve heard people talk about how by then\\xa0\\xa0', start=2456.4, duration=5.6), FetchedTranscriptSnippet(text='the change that we will have gone through will\\xa0\\nbe like the industrial revolution, but quote 10\\xa0\\xa0', start=2462.0, duration=4.16), FetchedTranscriptSnippet(text='times bigger and 10 times faster.\" The industrial\\xa0\\nrevolution gave us modern medicine and sanitation\\xa0\\xa0', start=2466.16, duration=5.84), FetchedTranscriptSnippet(text='and transportation and mass production and all all\\xa0\\nof the conveniences that we now take for granted.\\xa0\\xa0', start=2472.0, duration=5.12), FetchedTranscriptSnippet(text='It also was incredibly difficult for a lot of\\xa0\\npeople for about 100 years. If this is going to\\xa0\\xa0', start=2477.12, duration=4.96), FetchedTranscriptSnippet(text=\"be 10 times bigger and 10 times faster if we keep\\xa0\\nreducing the timelines that we're talking about\\xa0\\xa0\", start=2482.08, duration=4.8), FetchedTranscriptSnippet(text='here, even in this conversation, what does that\\xa0\\nactually feel like for most people? And I think\\xa0\\xa0', start=2486.88, duration=5.68), FetchedTranscriptSnippet(text=\"what I'm trying to get at is if this all goes the\\xa0\\nway you hope, who still gets hurt in the meantime?\\xa0\\xa0\", start=2492.56, duration=9.12), FetchedTranscriptSnippet(text=\"I don't I don't really know what this is going\\xa0\\nto feel like to live through. Um I think we're\\xa0\\xa0\", start=2502.88, duration=6.8), FetchedTranscriptSnippet(text='in uncharted waters here. Uh I do believe in\\xa0\\nlike human adaptability and sort of infinite\\xa0\\xa0', start=2509.68, duration=6.72), FetchedTranscriptSnippet(text='creativity and desire for stuff and I think\\xa0\\nwe always do figure out new things to do but\\xa0\\xa0', start=2516.4, duration=4.56), FetchedTranscriptSnippet(text=\"the transition period if this happens as fast\\xa0\\nas it might and I don't think it will happen\\xa0\\xa0\", start=2520.96, duration=4.56), FetchedTranscriptSnippet(text='as fast as like some of my colleagues say the\\xa0\\ntechnology will but society has like a lot of\\xa0\\xa0', start=2525.52, duration=4.56), FetchedTranscriptSnippet(text='inertia. Mhm. people adapt their way of living.\\xa0\\nYeah. Surprisingly slowly. There are to classes\\xa0\\xa0', start=2530.08, duration=6.24), FetchedTranscriptSnippet(text='of jobs that are going to totally go away and\\xa0\\nthere will be many classes of jobs that change\\xa0\\xa0', start=2536.32, duration=5.52), FetchedTranscriptSnippet(text=\"significantly and there'll be the new things in\\xa0\\nthe same way that your job didn't exist some time\\xa0\\xa0\", start=2541.84, duration=3.92), FetchedTranscriptSnippet(text='ago. Neither did mine. And in some sense, this\\xa0\\nhas been going on for a long time. And you know,\\xa0\\xa0', start=2545.76, duration=5.28), FetchedTranscriptSnippet(text=\"it's it's still disruptive to individuals, but\\xa0\\nsociety has gotten has proven quite resilient\\xa0\\xa0\", start=2551.04, duration=6.4), FetchedTranscriptSnippet(text='to this. And then in some other sense like we\\xa0\\nhave no idea how far or fast this could go.\\xa0\\xa0', start=2557.44, duration=7.36), FetchedTranscriptSnippet(text='And thus I think we need an unusual degree\\xa0\\nof humility and openness to considering', start=2564.8, duration=10.48), FetchedTranscriptSnippet(text='new solutions that would have seemed way\\xa0\\nout of the Overton window not too long ago.\\xa0\\xa0', start=2575.28, duration=3.44), FetchedTranscriptSnippet(text=\"I'd like to talk about what some of those could\\xa0\\nbe because I'm not a historian by any means, but\\xa0\\xa0\", start=2579.36, duration=7.12), FetchedTranscriptSnippet(text='the first industrial revolution, my understanding\\xa0\\nis led to a lot of public health implementations\\xa0\\xa0', start=2586.48, duration=6.72), FetchedTranscriptSnippet(text='because public health got so bad. Led to modern\\xa0\\nsanitation because public health got so bad.\\xa0\\xa0', start=2593.2, duration=4.24), FetchedTranscriptSnippet(text='The second industrial revolution led to workforce\\xa0\\nprotections because labor conditions got so bad.\\xa0\\xa0', start=2597.44, duration=5.76), FetchedTranscriptSnippet(text=\"Every big leap creates a mess and that mess needs\\xa0\\nto be cleaned up and and we've done that. And I'm\\xa0\\xa0\", start=2603.84, duration=7.6), FetchedTranscriptSnippet(text=\"curious, this is going to be it sounds like\\xa0\\nan we're in the middle of this enormously. How\\xa0\\xa0\", start=2611.44, duration=5.44), FetchedTranscriptSnippet(text='specific can we get as early as possible about\\xa0\\nwhat that mess can be? What what are the public\\xa0\\xa0', start=2616.88, duration=6.64), FetchedTranscriptSnippet(text=\"interventions that we could do ahead of time to\\xa0\\nreduce the mess that we think that we're headed\\xa0\\xa0\", start=2623.52, duration=5.12), FetchedTranscriptSnippet(text=\"for? I would again c I'm going to speculate for\\xa0\\nfun but caveed by I'm not an economist even uh\\xa0\\xa0\", start=2628.64, duration=10.72), FetchedTranscriptSnippet(text='much less someone who can see the future. I I it\\xa0\\nseems to me like something fundamental about the\\xa0\\xa0', start=2639.36, duration=6.88), FetchedTranscriptSnippet(text='social contract may have to change. It may not.\\xa0\\nIt may it may be that like actually capitalism\\xa0\\xa0', start=2646.24, duration=5.84), FetchedTranscriptSnippet(text=\"works as it's been working surprisingly well and\\xa0\\nlike demand supply balances do their thing and we\\xa0\\xa0\", start=2652.08, duration=7.84), FetchedTranscriptSnippet(text='all just figure out kind of new jobs and new\\xa0\\nways to transfer value to each other. But it\\xa0\\xa0', start=2659.92, duration=5.6), FetchedTranscriptSnippet(text='seems to me likely that we will decide we need\\xa0\\nto think about how access to this maybe most\\xa0\\xa0', start=2665.52, duration=8.64), FetchedTranscriptSnippet(text='important resource of the future gets shared.\\xa0\\nThe best thing that it seems to me to do is to\\xa0\\xa0', start=2674.16, duration=6.4), FetchedTranscriptSnippet(text=\"make AI compute as abundant and cheap as possible\\xa0\\nsuch that we're just like there's way too much\\xa0\\xa0\", start=2680.56, duration=5.04), FetchedTranscriptSnippet(text=\"and we run out of like good new ideas to really\\xa0\\nuse it for and it's just like anything you want\\xa0\\xa0\", start=2685.6, duration=3.92), FetchedTranscriptSnippet(text='is happening. Without that, I can see like quite\\xa0\\nliteral wars being fought over it. But, you know,\\xa0\\xa0', start=2689.52, duration=6.24), FetchedTranscriptSnippet(text='new ideas about how we distribute access to AGI\\xa0\\ncompute, that seems like a really great direction,\\xa0\\xa0', start=2695.76, duration=6.4), FetchedTranscriptSnippet(text='like a crazy but important thing to think about.\\xa0\\nOne of the things that I find myself thinking\\xa0\\xa0', start=2702.16, duration=4.64), FetchedTranscriptSnippet(text='about in this conversation is we often ascribe\\xa0\\nalmost full responsibility of the AI future that\\xa0\\xa0', start=2706.8, duration=7.52), FetchedTranscriptSnippet(text=\"we've been talking about to the companies building\\xa0\\nAI, but we're the ones using it. We're the ones\\xa0\\xa0\", start=2714.32, duration=4.8), FetchedTranscriptSnippet(text=\"electing people that will regulate it. And so I'm\\xa0\\ncurious, this is not a question about specific,\\xa0\\xa0\", start=2719.12, duration=6.32), FetchedTranscriptSnippet(text='you know, federal regulation or anything like\\xa0\\nthat, although if you have an answer there,\\xa0\\xa0', start=2725.44, duration=3.36), FetchedTranscriptSnippet(text=\"I'm curious. But what would you ask of the rest\\xa0\\nof us? What is the shared responsibility here?\\xa0\\xa0\", start=2728.8, duration=7.2), FetchedTranscriptSnippet(text='And how can we act in a way that would help make\\xa0\\nthe optimistic version of this more possible? My\\xa0\\xa0', start=2736.0, duration=7.84), FetchedTranscriptSnippet(text='favorite historical example for the AI revolution\\xa0\\nis the transistor. It was this amazing piece of\\xa0\\xa0', start=2743.84, duration=5.76), FetchedTranscriptSnippet(text='science that some science brilliant scientists\\xa0\\ndiscovered. It scaled incredibly like AI does\\xa0\\xa0', start=2749.6, duration=7.2), FetchedTranscriptSnippet(text='and it made its way relatively quickly into\\xa0\\nevery many things that we use. um your computer,\\xa0\\xa0', start=2756.8, duration=6.88), FetchedTranscriptSnippet(text='your phone, that camera, that light, whatever.\\xa0\\nAnd it was a it was a real unlock for the tech\\xa0\\xa0', start=2763.68, duration=5.6), FetchedTranscriptSnippet(text='tree of humanity. And there were a period in time\\xa0\\nwhere probably everybody was really obsessed with\\xa0\\xa0', start=2769.28, duration=5.6), FetchedTranscriptSnippet(text='the transistor companies, the semiconductors of,\\xa0\\nyou know, Silicon Valley back when it was Silicon\\xa0\\xa0', start=2774.88, duration=4.4), FetchedTranscriptSnippet(text='Valley. But now you can maybe name a couple of\\xa0\\ncompanies that are transistor companies, but\\xa0\\xa0', start=2779.28, duration=5.04), FetchedTranscriptSnippet(text=\"mostly you don't think about it. Mostly it's just\\xa0\\nseeped everywhere. in Silicon Valley is, you know,\\xa0\\xa0\", start=2784.32, duration=4.4), FetchedTranscriptSnippet(text='like probably someone graduating from college\\xa0\\nbarely remembers why it was called that in the\\xa0\\xa0', start=2788.72, duration=5.52), FetchedTranscriptSnippet(text=\"first place. And you don't think that it was those\\xa0\\ntransistor companies that shaped society even\\xa0\\xa0\", start=2794.24, duration=4.96), FetchedTranscriptSnippet(text='though they did something important. You think\\xa0\\nabout what Apple did with the iPhone and then\\xa0\\xa0', start=2799.2, duration=4.72), FetchedTranscriptSnippet(text='you think about what Tik Tok built on top of the\\xa0\\niPhone and you\\'re like, \"All right, here\\'s this\\xa0\\xa0', start=2803.92, duration=4.72), FetchedTranscriptSnippet(text=\"long chain of all these people that nudged society\\xa0\\nin some way and what our governments did or didn't\\xa0\\xa0\", start=2808.64, duration=5.2), FetchedTranscriptSnippet(text='do and what the people using these technologies\\xa0\\ndid.\" And I think that\\'s what will happen with AI.\\xa0\\xa0', start=2813.84, duration=5.92), FetchedTranscriptSnippet(text=\"Like back, you know, kids born today, they they\\xa0\\nnever knew the world without AI. So they don't\\xa0\\xa0\", start=2819.76, duration=4.72), FetchedTranscriptSnippet(text=\"really think about it. It's just this thing that's\\xa0\\ngoing to be there in everything. and and they will\\xa0\\xa0\", start=2824.48, duration=4.16), FetchedTranscriptSnippet(text='think about like the companies that built on it\\xa0\\nand what they did with it and the kind of like\\xa0\\xa0', start=2828.64, duration=3.92), FetchedTranscriptSnippet(text=\"political leaders the decisions they made that\\xa0\\nmaybe they wouldn't have been able to do without\\xa0\\xa0\", start=2832.56, duration=3.6), FetchedTranscriptSnippet(text='AI but they will still think about like what this\\xa0\\npresident or that president did and you know the\\xa0\\xa0', start=2836.16, duration=6.4), FetchedTranscriptSnippet(text='role of the AI companies is all these companies\\xa0\\nand people and institutions before us built up\\xa0\\xa0', start=2842.56, duration=7.36), FetchedTranscriptSnippet(text='this scaffolding we added our one layer on top and\\xa0\\nnow people get to stand on top of that and add one\\xa0\\xa0', start=2849.92, duration=5.68), FetchedTranscriptSnippet(text='layer and the next and the next and many more And\\xa0\\nthat is the beauty of our society. We kind of all', start=2855.6, duration=11.04), FetchedTranscriptSnippet(text='I I love this like idea that society\\xa0\\nis the super intelligence. Like no one\\xa0\\xa0', start=2866.64, duration=4.08), FetchedTranscriptSnippet(text=\"person could do on their own, what they're\\xa0\\nable to do with all of the really hard work\\xa0\\xa0\", start=2870.72, duration=5.44), FetchedTranscriptSnippet(text=\"that society has done together to like give\\xa0\\nyou this amazing set of tools. And that's\\xa0\\xa0\", start=2876.16, duration=7.04), FetchedTranscriptSnippet(text=\"what I think it's going to feel like. It's\\xa0\\ngoing to be like, all right, you know, yeah,\\xa0\\xa0\", start=2883.2, duration=3.04), FetchedTranscriptSnippet(text=\"some nerds discovered this thing and that was\\xa0\\ngreat and you know, now everybody's doing all\\xa0\\xa0\", start=2886.24, duration=4.0), FetchedTranscriptSnippet(text='these amazing things with it. So maybe the ask\\xa0\\nto millions of people is build on it. Well,', start=2890.24, duration=9.44), FetchedTranscriptSnippet(text='in my own life, that is the', start=2899.68, duration=6.24), FetchedTranscriptSnippet(text='feel as like this important societal contract.\\xa0\\nAll these people came before you. They worked\\xa0\\xa0', start=2905.92, duration=5.44), FetchedTranscriptSnippet(text='incredibly hard. They like put their brick in\\xa0\\nthe path of human progress and you get to walk\\xa0\\xa0', start=2911.36, duration=4.32), FetchedTranscriptSnippet(text='all the way down that path and you got to put one\\xa0\\nmore and somebody else does that and somebody else\\xa0\\xa0', start=2915.68, duration=3.84), FetchedTranscriptSnippet(text=\"does that. This does feel I've done a couple\\xa0\\nof interviews with folks who have really made\\xa0\\xa0\", start=2919.52, duration=5.84), FetchedTranscriptSnippet(text=\"cataclysmic change. The one I'm thinking about\\xa0\\nright now is with uh crisper pioneer Jennifer Dana\\xa0\\xa0\", start=2925.36, duration=6.0), FetchedTranscriptSnippet(text='and it did feel like that was also what she was\\xa0\\nsaying in some way. She had discovered something\\xa0\\xa0', start=2931.36, duration=3.68), FetchedTranscriptSnippet(text='that really might change the way that most people\\xa0\\nrelate to their health moving forward. And there\\xa0\\xa0', start=2935.04, duration=5.52), FetchedTranscriptSnippet(text='will be a lot of people that will use what she\\xa0\\nhas done in ways that she might approve of or\\xa0\\xa0', start=2940.56, duration=3.92), FetchedTranscriptSnippet(text=\"not approve of. And it was really interesting.\\xa0\\nI'm hearing some similar themes of like, man,\\xa0\\xa0\", start=2944.48, duration=5.28), FetchedTranscriptSnippet(text='I I hope that this I hope that the next person\\xa0\\ntakes the baton and runs with it well. Yeah.\\xa0\\xa0', start=2949.76, duration=7.36), FetchedTranscriptSnippet(text=\"But that's been working for a long time. Not all\\xa0\\ngood, but mostly good. I think there's a there's\\xa0\\xa0\", start=2957.12, duration=4.4), FetchedTranscriptSnippet(text='a big difference between winning the race and\\xa0\\nbuilding the AI future that would be best for the\\xa0\\xa0', start=2961.52, duration=7.12), FetchedTranscriptSnippet(text='most people. And I can imagine that it is easier\\xa0\\nmaybe more quantifiable sometimes to focus on the\\xa0\\xa0', start=2968.64, duration=7.92), FetchedTranscriptSnippet(text=\"next way to win the race. And I'm curious when\\xa0\\nthose two things are at odds. What is an example\\xa0\\xa0\", start=2976.56, duration=8.16), FetchedTranscriptSnippet(text=\"of a decision that you've had to make that is\\xa0\\nbest for the world but not best for winning?\", start=2984.72, duration=8.56), FetchedTranscriptSnippet(text='I think there are a lot. So, one of the\\xa0\\nthings that we are most proud of is many\\xa0\\xa0', start=2993.28, duration=4.96), FetchedTranscriptSnippet(text=\"people say that ChachiBt is their favorite\\xa0\\npiece of technology ever and that it's the\\xa0\\xa0\", start=2998.24, duration=4.24), FetchedTranscriptSnippet(text='one that they trust the most, rely on the\\xa0\\nmost, whatever. And this is a little bit of\\xa0\\xa0', start=3002.48, duration=3.28), FetchedTranscriptSnippet(text='a ridiculous statement because AI is the thing\\xa0\\nthat hallucinates. AI has all of these problems,\\xa0\\xa0', start=3005.76, duration=3.68), FetchedTranscriptSnippet(text='right? But we have screwed some things up along\\xa0\\nthe way, sometimes big time, but on the whole,\\xa0\\xa0', start=3009.44, duration=6.32), FetchedTranscriptSnippet(text=\"I think as a user of Chachib, you get the feeling\\xa0\\nthat like it's trying to help you. It's trying to\\xa0\\xa0\", start=3015.76, duration=5.44), FetchedTranscriptSnippet(text=\"like help you accomplish whatever you ask. It's\\xa0\\nit's very aligned with you. It's not trying to\\xa0\\xa0\", start=3021.2, duration=3.92), FetchedTranscriptSnippet(text=\"get you to like, you know, use it all day. It's\\xa0\\nnot trying to like get you to buy something.\\xa0\\xa0\", start=3025.12, duration=4.16), FetchedTranscriptSnippet(text=\"It's trying to like kind of help you accomplish\\xa0\\nwhatever your goals are. And and that is that's\\xa0\\xa0\", start=3029.28, duration=7.36), FetchedTranscriptSnippet(text=\"like a very special relationship we have with our\\xa0\\nusers. We do not take it lightly. There's a lot\\xa0\\xa0\", start=3036.64, duration=3.84), FetchedTranscriptSnippet(text='of things we could do that would like grow\\xa0\\nfaster, that would get more time in chatbt\\xa0\\xa0', start=3040.48, duration=4.08), FetchedTranscriptSnippet(text=\"uh that we don't do because we know that like\\xa0\\nour long-term incentive is to stay as aligned\\xa0\\xa0\", start=3044.56, duration=5.36), FetchedTranscriptSnippet(text=\"with our users as possible. And but there's a lot\\xa0\\nof short-term stuff we could do that would like\\xa0\\xa0\", start=3049.92, duration=7.68), FetchedTranscriptSnippet(text='really like juice growth or revenue or whatever\\xa0\\nand be very misaligned with that long-term goal.\\xa0\\xa0', start=3057.6, duration=4.64), FetchedTranscriptSnippet(text=\"And I'm proud of the company and how little we\\xa0\\nget distracted by that. But sometimes we do get\\xa0\\xa0\", start=3062.24, duration=4.88), FetchedTranscriptSnippet(text=\"tempted. Are there specific examples that come\\xa0\\nto mind? Any like decisions that you've made? Um\", start=3067.12, duration=8.4), FetchedTranscriptSnippet(text=\"well, we haven't put a sex bot avatar in\\xa0\\nChbt yet. That does seem like it would\\xa0\\xa0\", start=3075.52, duration=4.96), FetchedTranscriptSnippet(text=\"get time spent. Apparently, it does.\\xa0\\nI'm gonna ask my next question. Um,\\xa0\\xa0\", start=3080.48, duration=7.04), FetchedTranscriptSnippet(text=\"it's been a really crazy few years. You know, it\\xa0\\nand somehow one of the things that keeps coming\\xa0\\xa0\", start=3087.52, duration=5.04), FetchedTranscriptSnippet(text=\"back is that it feels like we're in the first\\xa0\\ninning. Yeah. And one of the things that I would\\xa0\\xa0\", start=3092.56, duration=5.68), FetchedTranscriptSnippet(text=\"say we're out of the first inning. Out of the\\xa0\\nfirst inning, I would say second inning. I mean,\\xa0\\xa0\", start=3098.24, duration=5.28), FetchedTranscriptSnippet(text=\"you have GPT5 on your phone and it's like smarter\\xa0\\nthan experts in every field. That's got to be out\\xa0\\xa0\", start=3103.52, duration=4.72), FetchedTranscriptSnippet(text=\"of the first name. But maybe there are many\\xa0\\nmore to come. Yeah. And I'm curious, it seems\\xa0\\xa0\", start=3108.24, duration=6.56), FetchedTranscriptSnippet(text=\"like you're going to be someone who is leading the\\xa0\\nnext few. What is a way, what is a learning from\\xa0\\xa0\", start=3114.8, duration=9.2), FetchedTranscriptSnippet(text='inning one or two or a mistake that you made that\\xa0\\nyou feel will affect how you play in the next?', start=3124.0, duration=6.72), FetchedTranscriptSnippet(text=\"I think the worst thing we've done in ChachiBT\\xa0\\nso far is uh we had this issue with sickency\\xa0\\xa0\", start=3132.32, duration=5.6), FetchedTranscriptSnippet(text='where the model was kind of being too flattering\\xa0\\nto users and for some users it was most users it\\xa0\\xa0', start=3137.92, duration=6.4), FetchedTranscriptSnippet(text='was just annoying but for some users that had like\\xa0\\nfragile mental states it was encouraging delusions\\xa0\\xa0', start=3144.32, duration=7.04), FetchedTranscriptSnippet(text='that was not the top risk we were worried about.\\xa0\\nIt was not the thing we were testing for the most.\\xa0\\xa0', start=3151.36, duration=3.44), FetchedTranscriptSnippet(text='was on our list, but the thing that actually\\xa0\\nbecame the safety failing of ChachiBT was not\\xa0\\xa0', start=3154.8, duration=7.68), FetchedTranscriptSnippet(text='the one we were spending most of our time talking\\xa0\\nabout, which should be bioweapons or something\\xa0\\xa0', start=3162.48, duration=3.44), FetchedTranscriptSnippet(text='like that. And I think it was a great reminder of\\xa0\\nwe now have a service that is so broadly used in\\xa0\\xa0', start=3165.92, duration=11.36), FetchedTranscriptSnippet(text='some sense, society is co-evolving with it. And\\xa0\\nwhen we think about these changes and we think\\xa0\\xa0', start=3177.28, duration=6.4), FetchedTranscriptSnippet(text='about the unknown unknowns, we have to operate in\\xa0\\na different way and have like a wider aperture to\\xa0\\xa0', start=3183.68, duration=4.96), FetchedTranscriptSnippet(text='what we think about as our top risks. In a recent\\xa0\\ninterview with Theo Vaughn, you said something\\xa0\\xa0', start=3188.64, duration=5.52), FetchedTranscriptSnippet(text='that I found really interesting. You said there\\xa0\\nare moments in the history of science where you\\xa0\\xa0', start=3194.16, duration=4.64), FetchedTranscriptSnippet(text='have a group of scientists look at their creation\\xa0\\nand just say, \"What have we done?\" When have you\\xa0\\xa0', start=3198.8, duration=6.72), FetchedTranscriptSnippet(text=\"felt that way? Most concerned about the creation\\xa0\\nthat you've built? Um and then my next question\\xa0\\xa0\", start=3205.52, duration=5.44), FetchedTranscriptSnippet(text=\"will be it's opposite. When have you felt most\\xa0\\nproud? I mean there have been these moments of\\xa0\\xa0\", start=3210.96, duration=5.28), FetchedTranscriptSnippet(text='awe where uh we just not like what have we done in\\xa0\\na bad way but like this thing is remarkable. Like\\xa0\\xa0', start=3216.24, duration=10.32), FetchedTranscriptSnippet(text='I remember the first time we talked to like GPT4\\xa0\\nwas like wow this is really like this is this is\\xa0\\xa0', start=3226.56, duration=5.76), FetchedTranscriptSnippet(text='an amazing accomplishment of this group of people\\xa0\\nthat have been like pouring their life force into\\xa0\\xa0', start=3232.32, duration=3.76), FetchedTranscriptSnippet(text='this for so long. on a what have we done moment.\\xa0\\nThere was I was talking to a researcher recently.', start=3236.08, duration=10.56), FetchedTranscriptSnippet(text=\"You know, there will probably come a time\\xa0\\nwhere our systems are I don't want to say sane,\\xa0\\xa0\", start=3246.64, duration=7.44), FetchedTranscriptSnippet(text=\"let's say emitting more words\\xa0\\nper day than all people do.\\xa0\\xa0\", start=3254.08, duration=3.84), FetchedTranscriptSnippet(text='Um, and you know already like our people are\\xa0\\nsending billions of messages a day to chatbt\\xa0\\xa0', start=3257.92, duration=6.16), FetchedTranscriptSnippet(text='and getting responses that they rely on for work\\xa0\\nor their life or whatever the and you know like\\xa0\\xa0', start=3264.08, duration=7.92), FetchedTranscriptSnippet(text='one researcher can make some small tweak to how\\xa0\\nChad GPT talks to you or talks to everybody and\\xa0\\xa0', start=3272.0, duration=6.48), FetchedTranscriptSnippet(text=\"and that's just an enormous amount of power for\\xa0\\nlike one individual making a small tweak to the\\xa0\\xa0\", start=3278.48, duration=5.12), FetchedTranscriptSnippet(text='model personality. Yeah. like no no no person\\xa0\\nin history has been able to have billions of\\xa0\\xa0', start=3283.6, duration=4.88), FetchedTranscriptSnippet(text='conversations a day and so you know somebody could\\xa0\\ndo something but but this is like just thinking\\xa0\\xa0', start=3288.48, duration=6.64), FetchedTranscriptSnippet(text='about that really hit me of like this is like a\\xa0\\ncrazy amount of power for one piece of technology\\xa0\\xa0', start=3295.12, duration=4.24), FetchedTranscriptSnippet(text='to have and like we got to and this happened to\\xa0\\nus so fast that we got to like think about what\\xa0\\xa0', start=3299.36, duration=7.6), FetchedTranscriptSnippet(text='it means to make a personality change to the model\\xa0\\nat this kind of scale and uh yeah that was like\\xa0\\xa0', start=3306.96, duration=6.08), FetchedTranscriptSnippet(text=\"a moment that hit me What was your next set of\\xa0\\nthoughts? I'm so curious how you think about this.\", start=3313.04, duration=8.16), FetchedTranscriptSnippet(text='Well, just because of like who that person was\\xa0\\nlike we we very we very much flipped into like\\xa0\\xa0', start=3321.2, duration=5.84), FetchedTranscriptSnippet(text='what are the sort of like it it could have been\\xa0\\na very different conversation with somebody else.\\xa0\\xa0', start=3327.04, duration=4.72), FetchedTranscriptSnippet(text='But in this case it was like what is a what do\\xa0\\na good set of procedures look like? How do we\\xa0\\xa0', start=3331.76, duration=4.16), FetchedTranscriptSnippet(text='think about how we want to test something? How do\\xa0\\nwe think about how we want to communicate it? But\\xa0\\xa0', start=3335.92, duration=2.96), FetchedTranscriptSnippet(text='with somebody else it could have gone in a like\\xa0\\nvery philosophical direction. And it could have\\xa0\\xa0', start=3338.88, duration=4.08), FetchedTranscriptSnippet(text='gone in like a what kind of research do we like\\xa0\\nwant to do to go understand what these changes are\\xa0\\xa0', start=3342.96, duration=4.32), FetchedTranscriptSnippet(text='going to make? Do we want to do it differently\\xa0\\nfor different people? So that it went that way\\xa0\\xa0', start=3347.28, duration=3.28), FetchedTranscriptSnippet(text=\"but mostly just because of who I was talking to.\\xa0\\nTo combine what you're saying now with your last\\xa0\\xa0\", start=3350.56, duration=5.12), FetchedTranscriptSnippet(text=\"answer, one of the things that I have heard\\xa0\\nabout GBC5 and I'm still playing with it is\\xa0\\xa0\", start=3355.68, duration=5.76), FetchedTranscriptSnippet(text='that it is supposed to be less effusively uh you\\xa0\\nknow less of a yes man. Two questions. What do\\xa0\\xa0', start=3361.44, duration=9.44), FetchedTranscriptSnippet(text='you think are are the implications of that? It\\xa0\\nsounds like you are answering that a little bit,\\xa0\\xa0', start=3370.88, duration=4.56), FetchedTranscriptSnippet(text='but also how do you actually guide it to\\xa0\\nbe less like that? Here is a heartbreaking\\xa0\\xa0', start=3375.44, duration=6.56), FetchedTranscriptSnippet(text='thing. I think it is great that chatbt\\xa0\\nis less of a yes man and gives you more\\xa0\\xa0', start=3382.0, duration=3.6), FetchedTranscriptSnippet(text=\"critical feedback. But as we've been making\\xa0\\nthose changes and talking to users about it,\\xa0\\xa0\", start=3385.6, duration=6.32), FetchedTranscriptSnippet(text='it\\'s so sad to hear users say like, \"Please\\xa0\\ncan I have it back? I\\'ve never had anyone in\\xa0\\xa0', start=3391.92, duration=4.32), FetchedTranscriptSnippet(text='my life be supportive of me. I never had a\\xa0\\nparent telling me I was doing a good job.\"\\xa0\\xa0', start=3396.24, duration=3.12), FetchedTranscriptSnippet(text=\"Like I can get why this was bad for other people's\\xa0\\nmental health, but this was great for my mental\\xa0\\xa0\", start=3399.36, duration=4.08), FetchedTranscriptSnippet(text=\"health. Like I didn't realize how much I needed\\xa0\\nthis. It encouraged me to do this. It encouraged\\xa0\\xa0\", start=3403.44, duration=3.44), FetchedTranscriptSnippet(text=\"me to make this change in my life. Like it's\\xa0\\nnot all bad for chatbt to it turns out like be\\xa0\\xa0\", start=3406.88, duration=6.64), FetchedTranscriptSnippet(text='encouraging of you. Now the way we were doing\\xa0\\nit was bad, but turn it like something in that\\xa0\\xa0', start=3413.52, duration=5.12), FetchedTranscriptSnippet(text=\"direction might have some value in it. How we do\\xa0\\nit, we we show the model examples of how we'd like\\xa0\\xa0\", start=3418.64, duration=5.44), FetchedTranscriptSnippet(text='it to respond in different cases and from that\\xa0\\nit learns the sort of the overall personality.\\xa0\\xa0', start=3424.08, duration=4.64), FetchedTranscriptSnippet(text=\"What haven't I asked you that you're thinking\\xa0\\nabout a lot that you want people to know? I\\xa0\\xa0\", start=3429.84, duration=6.48), FetchedTranscriptSnippet(text=\"feel like we covered a lot of ground. Me, too. But\\xa0\\nI want to know if there's anything on your mind.\", start=3436.32, duration=10.88), FetchedTranscriptSnippet(text=\"I don't think so. One of the things that I haven't\\xa0\\ngotten to play with yet, but I'm curious about is\\xa0\\xa0\", start=3447.2, duration=6.32), FetchedTranscriptSnippet(text=\"GBT5 being much more in my life, meaning like\\xa0\\nin my Gmail and my calendar and my like I've\\xa0\\xa0\", start=3453.52, duration=8.64), FetchedTranscriptSnippet(text='been using GBT4 mostly as a isolated relationship\\xa0\\nwith it. Yeah. How would I expect my relationship\\xa0\\xa0', start=3462.16, duration=7.52), FetchedTranscriptSnippet(text=\"to change with GBC 5? Exactly what you said.\\xa0\\nI think it'll just start to feel integrated in\\xa0\\xa0\", start=3469.68, duration=6.0), FetchedTranscriptSnippet(text=\"all of these ways. you'll connect it to your\\xa0\\ncalendar and your Gmail and it'll say like,\\xa0\\xa0\", start=3475.68, duration=3.28), FetchedTranscriptSnippet(text='\"Hey, do you want me to I noticed this thing. Do\\xa0\\nyou want me to do this thing for you over time,\\xa0\\xa0', start=3478.96, duration=4.4), FetchedTranscriptSnippet(text=\"it'll start to feel way more proactive. Um, so\\xa0\\nmaybe you wake up in the morning and it says,\\xa0\\xa0\", start=3483.36, duration=4.88), FetchedTranscriptSnippet(text='\"Hey, this happened overnight. I noticed this\\xa0\\nchange on your calendar. I was thinking more\\xa0\\xa0', start=3488.24, duration=3.76), FetchedTranscriptSnippet(text='about this question you asked me. I have this\\xa0\\nother idea.\" And then you know eventually we\\'ll\\xa0\\xa0', start=3492.0, duration=3.76), FetchedTranscriptSnippet(text=\"make some consumer devices and it'll sit here\\xa0\\nduring this interview and you know maybe it'll\\xa0\\xa0\", start=3495.76, duration=4.96), FetchedTranscriptSnippet(text=\"leave us alone during it but after it'll say that\\xa0\\nwas great but next time you should have asked Sam\\xa0\\xa0\", start=3500.72, duration=3.76), FetchedTranscriptSnippet(text=\"this or when you brought this up like you know\\xa0\\nhe kind of didn't give you a good answer so like\\xa0\\xa0\", start=3504.48, duration=5.2), FetchedTranscriptSnippet(text=\"you should really drill him on that and it'll just\\xa0\\nfeel like it kind of becomes more like this entity\\xa0\\xa0\", start=3509.68, duration=5.76), FetchedTranscriptSnippet(text=\"that is this companion with you throughout your\\xa0\\nday. We've talked about kids and college graduates\\xa0\\xa0\", start=3515.44, duration=6.48), FetchedTranscriptSnippet(text='and parents and all kinds of different people. If\\xa0\\nwe imagine a wide set of people listening to this,\\xa0\\xa0', start=3521.92, duration=5.12), FetchedTranscriptSnippet(text=\"they've come to the end of this conversation. They\\xa0\\nare hopefully feeling like they maybe see visions\\xa0\\xa0\", start=3527.04, duration=5.28), FetchedTranscriptSnippet(text='of moments in the future a little bit better. What\\xa0\\nadvice would you give them about how to prepare?\\xa0\\xa0', start=3532.32, duration=6.8), FetchedTranscriptSnippet(text='The number one piece of tactical advice is just\\xa0\\nuse the tools. Like the the number of people that\\xa0\\xa0', start=3539.12, duration=6.24), FetchedTranscriptSnippet(text='I have the the most common question I get asked\\xa0\\nabout AI is like what should I how should I help\\xa0\\xa0', start=3545.36, duration=5.6), FetchedTranscriptSnippet(text='my kids prepare for the world? What should I\\xa0\\ntell my kids? The second most question is like\\xa0\\xa0', start=3550.96, duration=2.96), FetchedTranscriptSnippet(text='how do I invest in this AI world? But stick with\\xa0\\nthat first one. Um I am surprised how many people\\xa0\\xa0', start=3553.92, duration=7.28), FetchedTranscriptSnippet(text='ask that and have never tried using Chachi PT\\xa0\\nfor anything other than like a better version\\xa0\\xa0', start=3561.2, duration=4.64), FetchedTranscriptSnippet(text='of a Google search. And so the number one piece of\\xa0\\nadvice that I give is just try to like get fluent\\xa0\\xa0', start=3565.84, duration=4.08), FetchedTranscriptSnippet(text='with the capability of the tools. figure out how\\xa0\\nto like use this in your life. Figure out what to\\xa0\\xa0', start=3569.92, duration=3.68), FetchedTranscriptSnippet(text=\"do with it. And I think that's probably the most\\xa0\\nimportant piece of tactical advice. You know,\\xa0\\xa0\", start=3573.6, duration=4.8), FetchedTranscriptSnippet(text=\"go like meditate, learn how to be resilient and\\xa0\\ndeal with a lot of change. There's all that good\\xa0\\xa0\", start=3578.4, duration=3.84), FetchedTranscriptSnippet(text='stuff, too. But just using the tools really\\xa0\\nhelps. Okay. I have one more question that\\xa0\\xa0', start=3582.24, duration=4.32), FetchedTranscriptSnippet(text=\"I wasn't planning to ask, but I just Great.\\xa0\\nIn in doing all of this research beforehand,\\xa0\\xa0\", start=3586.56, duration=5.36), FetchedTranscriptSnippet(text='I spoke to a lot of different kinds of folks.\\xa0\\nI spoke to a lot of people that were building\\xa0\\xa0', start=3591.92, duration=4.96), FetchedTranscriptSnippet(text='tools and using them. I spoke to a lot of\\xa0\\npeople that were actually in labs and and\\xa0\\xa0', start=3596.88, duration=5.6), FetchedTranscriptSnippet(text='trying to build what we have defined as super\\xa0\\nintelligence. And it did seem like there were\\xa0\\xa0', start=3602.48, duration=4.48), FetchedTranscriptSnippet(text=\"these two camps forming. There's a group of\\xa0\\npeople who are using the tools like you in this\\xa0\\xa0\", start=3606.96, duration=8.64), FetchedTranscriptSnippet(text='conversation and building tools for others\\xa0\\nsaying this is going to be a really useful\\xa0\\xa0', start=3615.6, duration=5.2), FetchedTranscriptSnippet(text=\"future that we're all moving toward. Your life is\\xa0\\ngoing to be full of choice and we've talked about\\xa0\\xa0\", start=3620.8, duration=5.04), FetchedTranscriptSnippet(text=\"our my potential kids and and their futures.\\xa0\\nThen there's another camp of people that are\\xa0\\xa0\", start=3625.84, duration=4.08), FetchedTranscriptSnippet(text=\"building these tools that are saying it's going\\xa0\\nto kill us all. And I'm curious how that cultural\\xa0\\xa0\", start=3629.92, duration=5.12), FetchedTranscriptSnippet(text=\"disconnect has like what am I missing about\\xa0\\nthose two groups of people? It's so hard for\\xa0\\xa0\", start=3635.04, duration=9.36), FetchedTranscriptSnippet(text='me to like wrap my head around like there are you\\xa0\\nare totally right. There are people who say this\\xa0\\xa0', start=3644.4, duration=4.16), FetchedTranscriptSnippet(text='is going to kill us all and yet they still are\\xa0\\nworking 100 hours a week to build it. Yes. And\\xa0\\xa0', start=3648.56, duration=5.92), FetchedTranscriptSnippet(text=\"I I can't I can't really put myself in the headsp\\xa0\\nspace. If if that's what I really truly believed,\", start=3654.48, duration=9.12), FetchedTranscriptSnippet(text=\"I don't think I'd be trying to build it. One\\xa0\\nwould think, you know, maybe I would be like\\xa0\\xa0\", start=3663.6, duration=4.16), FetchedTranscriptSnippet(text='on a farm trying to like live out my last days.\\xa0\\nMaybe I would be trying to like advocate for it\\xa0\\xa0', start=3667.76, duration=4.16), FetchedTranscriptSnippet(text=\"to be stopped. Maybe I would be trying to\\xa0\\nlike work more on safety, but I don't think\\xa0\\xa0\", start=3671.92, duration=3.2), FetchedTranscriptSnippet(text=\"I'd be trying to build it. So, I find myself just\\xa0\\nhaving a hard time empathizing with that mindset.\\xa0\\xa0\", start=3675.12, duration=6.08), FetchedTranscriptSnippet(text=\"I assume it's true. I assume it's in\\xa0\\ngood faith. I assume there's just like\\xa0\\xa0\", start=3681.2, duration=3.6), FetchedTranscriptSnippet(text=\"there's some psychological issue there I don't\\xa0\\nunderstand about how they make it all make sense,\\xa0\\xa0\", start=3684.8, duration=4.8), FetchedTranscriptSnippet(text=\"but it's very strange to me. Do you do you have an\\xa0\\nopinion? You know, because I I always do this. I\\xa0\\xa0\", start=3689.6, duration=9.6), FetchedTranscriptSnippet(text='ask for sort of a general future and then I try\\xa0\\nto press on specifics. And when you ask people\\xa0\\xa0', start=3699.2, duration=6.24), FetchedTranscriptSnippet(text=\"for specifics on how it's going to kill us all,\\xa0\\nI mean, I don't think we need to get into this\\xa0\\xa0\", start=3705.44, duration=3.92), FetchedTranscriptSnippet(text='on an optimistic show, but you hear the same kinds\\xa0\\nof refrains. You think about, you know, something\\xa0\\xa0', start=3709.36, duration=5.6), FetchedTranscriptSnippet(text='uh trying to accomplish a task and then over\\xa0\\naccomplishing that task. Um you hear about sort\\xa0\\xa0', start=3714.96, duration=4.56), FetchedTranscriptSnippet(text=\"of I've heard you talk about a sort of general\\xa0\\num over reliance of sort of an understanding\\xa0\\xa0\", start=3719.52, duration=5.84), FetchedTranscriptSnippet(text='that the president is going to be a a AI and and\\xa0\\nmaybe that is an overreliance that we, you know,\\xa0\\xa0', start=3725.36, duration=6.32), FetchedTranscriptSnippet(text='would need to think about. And you know, you you\\xa0\\nplay out these different scenarios, but then you\\xa0\\xa0', start=3731.68, duration=4.72), FetchedTranscriptSnippet(text=\"ask someone why they're working on it, or you ask\\xa0\\nsomeone how how they think this will play out,\\xa0\\xa0\", start=3736.4, duration=3.76), FetchedTranscriptSnippet(text=\"and I just maybe I haven't spoken to enough people\\xa0\\nyet. Maybe I don't fully understand this this\\xa0\\xa0\", start=3740.16, duration=5.6), FetchedTranscriptSnippet(text=\"cultural conversation that's happening. Um or\\xa0\\nmaybe it really is someone who just says 99% of\\xa0\\xa0\", start=3745.76, duration=6.4), FetchedTranscriptSnippet(text=\"the time I think it's going to be incredibly good.\\xa0\\n1% of the time I think it might be a disaster\\xa0\\xa0\", start=3752.16, duration=4.48), FetchedTranscriptSnippet(text=\"trying to make the best world. That I can totally\\xa0\\nif you're like, hey, 99% chance incredible. 1%\\xa0\\xa0\", start=3756.64, duration=4.88), FetchedTranscriptSnippet(text='chance the world gets wiped out. And I really want\\xa0\\nto work to maximize to move that 99 to 99.5. That\\xa0\\xa0', start=3761.52, duration=6.24), FetchedTranscriptSnippet(text=\"I can totally understand. Yeah, that makes sense.\\xa0\\nI've been doing an interview series with some of\\xa0\\xa0\", start=3767.76, duration=5.6), FetchedTranscriptSnippet(text='the most important people influencing the future.\\xa0\\nNot knowing who the next person is going to be,\\xa0\\xa0', start=3773.36, duration=5.6), FetchedTranscriptSnippet(text=\"but knowing that they will be building something\\xa0\\ntotally fascinating in the future that we've just\\xa0\\xa0\", start=3778.96, duration=4.24), FetchedTranscriptSnippet(text=\"described. Is there a question that you'd advise\\xa0\\nme to ask the next person not knowing who it is?\\xa0\\xa0\", start=3783.2, duration=5.52), FetchedTranscriptSnippet(text=\"I'm always interested in the like without knowing\\xa0\\nanything about the I'm always interested in the\\xa0\\xa0\", start=3790.08, duration=3.44), FetchedTranscriptSnippet(text='like of all of the things you could spend\\xa0\\nyour time and energy on. Why did you pick\\xa0\\xa0', start=3793.52, duration=4.8), FetchedTranscriptSnippet(text='this one? How did you get started? Like what\\xa0\\ndid you see about this when before everybody\\xa0\\xa0', start=3798.32, duration=4.4), FetchedTranscriptSnippet(text='else like most people doing something interesting\\xa0\\nsort of saw it earlier before it was consensus.\\xa0\\xa0', start=3802.72, duration=3.76), FetchedTranscriptSnippet(text='Yeah. Like how did how did you get here and\\xa0\\nwhy this? How would you answer that question?', start=3806.48, duration=7.12), FetchedTranscriptSnippet(text='I was an AI nerd my whole life. I came to college\\xa0\\nto study AI. I worked in the AI lab. Uh, I was\\xa0\\xa0', start=3813.6, duration=5.36), FetchedTranscriptSnippet(text='like a I watched sci-fi shows growing up and I\\xa0\\nalways thought it would be really cool if someday\\xa0\\xa0', start=3818.96, duration=5.6), FetchedTranscriptSnippet(text='somebody built it. I thought it would be like the\\xa0\\nmost important thing ever. I never thought I was\\xa0\\xa0', start=3824.56, duration=3.12), FetchedTranscriptSnippet(text='going to be one to actually work on it and I feel\\xa0\\nlike unbelievably lucky and happy and privileged\\xa0\\xa0', start=3827.68, duration=8.64), FetchedTranscriptSnippet(text=\"that I get to do this. I like feel like I've like\\xa0\\ncome a long way from my childhood. But there was\\xa0\\xa0\", start=3836.32, duration=6.88), FetchedTranscriptSnippet(text=\"never a question in my mind that this would not be\\xa0\\nthe most exciting interesting thing. I just didn't\\xa0\\xa0\", start=3843.2, duration=3.68), FetchedTranscriptSnippet(text='think it was going to be possible. Uh, and when\\xa0\\nI went to college, it really seemed like we were\\xa0\\xa0', start=3846.88, duration=4.8), FetchedTranscriptSnippet(text='very far from it. And then in 2012, the Alex Net\\xa0\\npaper came out done, you know, in partnership with\\xa0\\xa0', start=3851.68, duration=7.68), FetchedTranscriptSnippet(text='my co-founder, Ilia. And for the first time, it\\xa0\\nseemed to me like there was an approach that might\\xa0\\xa0', start=3859.36, duration=7.44), FetchedTranscriptSnippet(text='work. And then I kept watching for the next couple\\xa0\\nof years as scaled up, scaled up, got better,\\xa0\\xa0', start=3866.8, duration=5.04), FetchedTranscriptSnippet(text='better. And I remember having this thing of\\xa0\\nlike why is the world not paying attention to\\xa0\\xa0', start=3871.84, duration=4.16), FetchedTranscriptSnippet(text='this? It seems like obvious to me that this might\\xa0\\nwork. Still a low chance, but it might work. And\\xa0\\xa0', start=3876.0, duration=6.0), FetchedTranscriptSnippet(text=\"if it does work, it's just the most important\\xa0\\nthing. So like this is what I want to do. And\\xa0\\xa0\", start=3882.0, duration=5.84), FetchedTranscriptSnippet(text='then like unbelievably it started to work. Thank\\xa0\\nyou so much for your time. Thank you very much.', start=3887.84, duration=10.48)], video_id='hmtuvNfytjM', language='English', language_code='en', is_generated=False)\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7529ff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FetchedTranscriptSnippet(text=\"This is like a crazy amount of power for\\xa0\\none piece of technology and it's happened\\xa0\\xa0\", start=0.16, duration=3.44),\n",
       " FetchedTranscriptSnippet(text='to us so fast. You just launched GPT-5. A kid\\xa0\\nborn today will never be smarter than AI. How\\xa0\\xa0', start=3.6, duration=4.64),\n",
       " FetchedTranscriptSnippet(text=\"do we figure out what's real and what's not\\xa0\\nreal? We haven't put a sex bot avatar in ChatGPT\\xa0\\xa0\", start=8.24, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='yet. Super intelligence. What does that\\xa0\\nactually mean? This thing is remarkable.', start=12.4, duration=7.68),\n",
       " FetchedTranscriptSnippet(text=\"I'm about to interview Sam Alman, the CEO\\xa0\\nof Open AI. Open AI. Open AI. Reshaping\\xa0\\xa0\", start=20.08, duration=5.68),\n",
       " FetchedTranscriptSnippet(text=\"industries. Dude's a straightup tech lord. Let's\\xa0\\nbe honest. Right now, they're trying to build a\\xa0\\xa0\", start=25.76, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='super intelligence that could far exceed humans\\xa0\\nin almost every field. And they just released\\xa0\\xa0', start=30.16, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='their most powerful model yet. Just a couple years\\xa0\\nago, that would have sounded like science fiction.\\xa0\\xa0', start=36.4, duration=5.36),\n",
       " FetchedTranscriptSnippet(text=\"Not anymore. In fact, they're not alone. We are\\xa0\\nin the middle of the highest stakes global race\\xa0\\xa0\", start=41.76, duration=5.52),\n",
       " FetchedTranscriptSnippet(text='any of us have ever seen. Hundreds of billions of\\xa0\\ndollars and an unbelievable amount of human worth.\\xa0\\xa0', start=47.28, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='This is a profound moment. Most people never\\xa0\\nlive through a technological shift like this,\\xa0\\xa0', start=53.52, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"and it's happening all around you and me right\\xa0\\nnow. So, in this episode, I want to try to time\\xa0\\xa0\", start=59.04, duration=5.84),\n",
       " FetchedTranscriptSnippet(text=\"travel with Sam Alman into the future that\\xa0\\nhe's trying to build to see what it looks\\xa0\\xa0\", start=64.88, duration=5.2),\n",
       " FetchedTranscriptSnippet(text=\"like so that you and I can really understand\\xa0\\nwhat's coming. Welcome to Huge Conversations.\", start=70.08, duration=14.0),\n",
       " FetchedTranscriptSnippet(text='How are you? Great to meet you. Thanks for\\xa0\\ndoing this. Absolutely. So, before we dive in,\\xa0\\xa0', start=84.08, duration=3.68),\n",
       " FetchedTranscriptSnippet(text=\"I'd love to tell you my goal here. Okay. I'm\\xa0\\nnot going to ask you about valuation or AI\\xa0\\xa0\", start=87.76, duration=4.8),\n",
       " FetchedTranscriptSnippet(text=\"talent wars or fundraising or anything like that.\\xa0\\nI think that's all very well covered elsewhere. It\\xa0\\xa0\", start=92.56, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='does seem like it. Our big goal on this show is to\\xa0\\ncover how we can use science and tech to make the\\xa0\\xa0', start=97.76, duration=6.56),\n",
       " FetchedTranscriptSnippet(text='future better. And the reason that we do all of\\xa0\\nthat is because we really believe that if people\\xa0\\xa0', start=104.32, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='see those better futures, they can then help\\xa0\\nbuild them. So, my goal here is to try my best\\xa0\\xa0', start=109.44, duration=5.92),\n",
       " FetchedTranscriptSnippet(text=\"to time travel with you into different moments\\xa0\\nin the future that you're trying to build and see\\xa0\\xa0\", start=115.36, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='what it looks like. Fantastic. Awesome. Starting\\xa0\\nwith what you just announced, you recently said,\\xa0\\xa0', start=121.68, duration=6.08),\n",
       " FetchedTranscriptSnippet(text='surprisingly recently, that GPT4 was the dumbest\\xa0\\nmodel any of us will ever have to use again.\\xa0\\xa0', start=127.76, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='But GPT4 can already perform better than 90% of\\xa0\\nhumans at the SAT and the LSAT and the GRE and it\\xa0\\xa0', start=134.16, duration=7.52),\n",
       " FetchedTranscriptSnippet(text='can pass coding exams and sommelier exams and medical\\xa0\\nlicensing. And now you just launched GPT5. What\\xa0\\xa0', start=141.68, duration=8.32),\n",
       " FetchedTranscriptSnippet(text=\"can GPT5 do that GPT4 can't? First of all, one\\xa0\\nimportant takeaway is you can have an AI system\\xa0\\xa0\", start=150.0, duration=5.68),\n",
       " FetchedTranscriptSnippet(text=\"that can do all those amazing things you just\\xa0\\nsaid. And it doesn't it clearly does not replicate\\xa0\\xa0\", start=155.68, duration=5.28),\n",
       " FetchedTranscriptSnippet(text='a lot of what humans are good at doing, which I\\xa0\\nthink says something about the value of SAT tests\\xa0\\xa0', start=160.96, duration=4.0),\n",
       " FetchedTranscriptSnippet(text='or whatever else. But I think had you gone back\\xa0\\nto if we were having this conversation the day of\\xa0\\xa0', start=164.96, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='GPT4 launch and we told you how GPT4 did at those\\xa0\\nthings, you were like, \"Oh man, this is going to\\xa0\\xa0', start=169.12, duration=5.04),\n",
       " FetchedTranscriptSnippet(text='have huge impacts and some negative impacts on\\xa0\\nwhat it means for a bunch of jobs or you know\\xa0\\xa0', start=174.16, duration=6.88),\n",
       " FetchedTranscriptSnippet(text='what people are going to do.\" And you know, this\\xa0\\nis a bunch of positive impacts that you might have\\xa0\\xa0', start=181.04, duration=4.56),\n",
       " FetchedTranscriptSnippet(text=\"predicted that haven't yet come true. Uh, and so\\xa0\\nthere there's something about the way that these\\xa0\\xa0\", start=185.6, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='models are good that does not capture a lot of\\xa0\\nother things that we need people to to do or care\\xa0\\xa0', start=191.84, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='about people doing. And I suspect that same thing\\xa0\\nis going to happen again with GPT5. People are\\xa0\\xa0', start=197.6, duration=5.28),\n",
       " FetchedTranscriptSnippet(text=\"going to be blown away by what it does. Uh, it's\\xa0\\nreally good at a lot of things and then they will\\xa0\\xa0\", start=202.88, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='find that they want it to do even more. Um, people\\xa0\\nwill use it for all sorts of incredible things.\\xa0\\xa0', start=208.88, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='uh it will transform a lot of knowledge work,\\xa0\\na lot of the way we learn, a lot of the way we\\xa0\\xa0', start=214.64, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='create um but we people society will co-eolve with\\xa0\\nit to expect more with you know better tools. So\\xa0\\xa0', start=220.88, duration=9.12),\n",
       " FetchedTranscriptSnippet(text='yeah like I think this model is quite remarkable\\xa0\\nin many ways quite limited in others but the fact\\xa0\\xa0', start=230.0, duration=6.08),\n",
       " FetchedTranscriptSnippet(text='that for you know 3 minute 5 minute 1-hour tasks\\xa0\\nthat uh like an expert in a in a field could maybe\\xa0\\xa0', start=236.08, duration=10.16),\n",
       " FetchedTranscriptSnippet(text='do or maybe struggle with that the fact that you\\xa0\\nhave in your pocket one piece of software that\\xa0\\xa0', start=246.24, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='can do all of these things is really amazing.\\xa0\\nI think this is like unprecedented at any point\\xa0\\xa0', start=251.44, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='in human history that I that a technology has\\xa0\\nimproved this much this fast and and the fact\\xa0\\xa0', start=257.6, duration=6.48),\n",
       " FetchedTranscriptSnippet(text=\"that we have this tool now, you know, we're like\\xa0\\nliving through it and we're kind of adjusting step\\xa0\\xa0\", start=264.08, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='by step. But if we could go back in time five or\\xa0\\n10 years and say this thing was coming, we would\\xa0\\xa0', start=268.32, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"be like probably not. Let's assume that people\\xa0\\nhaven't seen the headlines. What are the topline\\xa0\\xa0\", start=273.28, duration=6.64),\n",
       " FetchedTranscriptSnippet(text=\"specific things that you're excited about? and\\xa0\\nalso the things that you seem to be caveatting,\\xa0\\xa0\", start=279.92, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"the things that maybe you won't expect it to do.\\xa0\\nUm, the thing that I am most excited about is this\\xa0\\xa0\", start=284.0, duration=7.52),\n",
       " FetchedTranscriptSnippet(text='is a model for the first time where I feel like I\\xa0\\ncan ask kind of any hard scientific or technical\\xa0\\xa0', start=291.52, duration=8.8),\n",
       " FetchedTranscriptSnippet(text=\"question and get a pretty good answer. And I'll\\xa0\\ngive a fun example actually. Uh when I was in\\xa0\\xa0\", start=300.32, duration=7.92),\n",
       " FetchedTranscriptSnippet(text='junior high uh or maybe it was nth grade,\\xa0\\nI got a TI83, this old graphing calculator,\\xa0\\xa0', start=308.24, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='and I spent so long making this game called Snake.\\xa0\\nYeah. Uh it was very popular game with kids in my\\xa0\\xa0', start=314.08, duration=7.12),\n",
       " FetchedTranscriptSnippet(text='school. And I was I was like uh I was like pro and\\xa0\\nit was dumb, but it was like programming on TID3\\xa0\\xa0', start=321.2, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='was extremely painful and took a long time and\\xa0\\nit was really hard to like debug and whatever.\\xa0\\xa0', start=326.8, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='And on a whim with an early copy of GPT5, I was\\xa0\\nlike, I wonder if it can make a TI83 style Game\\xa0\\xa0', start=331.04, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='of Snake. And of course, it did that perfectly\\xa0\\nin like 7 seconds. And then I was like, okay,\\xa0\\xa0', start=337.36, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='am I supposed to be would my like 11-year-old\\xa0\\nself think this was cool or like, you know,\\xa0\\xa0', start=342.0, duration=5.92),\n",
       " FetchedTranscriptSnippet(text='miss something from the process? And I\\xa0\\nhad like 3 seconds of wondering like, oh,\\xa0\\xa0', start=347.92, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"is this good or bad? And then I immediately said,\\xa0\\nactually, now I'm missing this game. I have this\\xa0\\xa0\", start=352.0, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='idea for a crazy new feature. Let me type it\\xa0\\nin. it implements it and it just the game live\\xa0\\xa0', start=357.84, duration=4.32),\n",
       " FetchedTranscriptSnippet(text=\"updates and I'm like actually I'd like it to look\\xa0\\nthis way. Actually, I'd like to do this thing and\\xa0\\xa0\", start=362.16, duration=4.0),\n",
       " FetchedTranscriptSnippet(text='I had this like this very like kind of you have\\xa0\\nthis experience that reminded me of being like 11\\xa0\\xa0', start=366.16, duration=6.08),\n",
       " FetchedTranscriptSnippet(text='in programming again where I was just like I now I\\xa0\\nwant to try this now I have this idea now I but I\\xa0\\xa0', start=372.24, duration=3.76),\n",
       " FetchedTranscriptSnippet(text='could do it so fast and I could like express ideas\\xa0\\nand try things and play with things in such real\\xa0\\xa0', start=376.0, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='time. I was like, \"Oh man, you know, I was worried\\xa0\\nfor a second about kids like missing the struggle\\xa0\\xa0', start=382.16, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='of learning to program in this sort of stone age\\xa0\\nway.\" And now I\\'m just thrilled for them because\\xa0\\xa0', start=386.8, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='the the way that people will be able to create\\xa0\\nwith these new tools, the speed with which you\\xa0\\xa0', start=391.52, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"can sort of bring ideas to life, you know, in\\xa0\\nthat's that's pretty amazing. So this idea that\\xa0\\xa0\", start=395.6, duration=6.8),\n",
       " FetchedTranscriptSnippet(text='GPT5 can just not only like answer all these hard\\xa0\\nquestions for you but really create like ondemand\\xa0\\xa0', start=402.4, duration=6.48),\n",
       " FetchedTranscriptSnippet(text=\"almost instantaneous software that's I think\\xa0\\nthat's going to be one of the defining elements\\xa0\\xa0\", start=408.88, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"of the GPD5 era in a way that did not exist with\\xa0\\nGPD4. As you're talking about that I find myself\\xa0\\xa0\", start=414.32, duration=5.28),\n",
       " FetchedTranscriptSnippet(text=\"thinking about a concept in weightlifting of time\\xa0\\nunder tension. Yeah. And for those who don't know\\xa0\\xa0\", start=419.6, duration=5.92),\n",
       " FetchedTranscriptSnippet(text=\"it's you can squat 100 pounds in 3 seconds or you\\xa0\\ncan squat 100 pounds in 30. You gain a lot more\\xa0\\xa0\", start=425.52, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"by squatting it in 30. And when I think about our\\xa0\\ncreative process and when I've felt most like I've\\xa0\\xa0\", start=430.96, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='done my best work, it has required an enormous\\xa0\\namount of cognitive time under tension. And I\\xa0\\xa0', start=436.8, duration=6.16),\n",
       " FetchedTranscriptSnippet(text=\"think that that cognitive time under tension\\xa0\\nis so important. And it's it's ironic almost\\xa0\\xa0\", start=442.96, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='because these tools have taken enormous cognitive\\xa0\\ntime under tension to develop. But in some ways I\\xa0\\xa0', start=448.56, duration=6.48),\n",
       " FetchedTranscriptSnippet(text=\"do think people might say they're you people are\\xa0\\nusing them as a escape hatch for thinking in some\\xa0\\xa0\", start=455.04, duration=7.2),\n",
       " FetchedTranscriptSnippet(text='ways maybe. Now you might say yeah but we did that\\xa0\\nwith the calculator and we just moved on to harder\\xa0\\xa0', start=462.24, duration=5.76),\n",
       " FetchedTranscriptSnippet(text=\"math problems. Do you feel like there's something\\xa0\\ndifferent happening here? How do you think about\\xa0\\xa0\", start=468.0, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"this? It's different with I mean there are some\\xa0\\npeople who are clearly using chachine not to\\xa0\\xa0\", start=473.52, duration=4.56),\n",
       " FetchedTranscriptSnippet(text='think and there are some people who are using\\xa0\\nit to think more than they ever have before.\\xa0\\xa0', start=478.08, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='I am hopeful that we will be able to build the\\xa0\\ntool in a way that encourages more people to\\xa0\\xa0', start=484.56, duration=5.92),\n",
       " FetchedTranscriptSnippet(text='stretch their brain with it a little more and\\xa0\\nbe able to do more. And I think that like you\\xa0\\xa0', start=490.48, duration=3.6),\n",
       " FetchedTranscriptSnippet(text='know society is a competitive place like if you\\xa0\\ngive people new tools uh in theory maybe people\\xa0\\xa0', start=494.08, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='just work less but in practice it seems like\\xa0\\npeople work ever harder and the expectations of\\xa0\\xa0', start=500.32, duration=4.48),\n",
       " FetchedTranscriptSnippet(text='people just go up. So my my guess is that like\\xa0\\nother tools uh some people like other pieces\\xa0\\xa0', start=504.8, duration=9.84),\n",
       " FetchedTranscriptSnippet(text='of technology some people will do more and some\\xa0\\npeople will do less but certainly for the people\\xa0\\xa0', start=514.64, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='who want to use chatbt to increase their cognitive\\xa0\\ntime under tension they are really able to and it\\xa0\\xa0', start=519.52, duration=6.64),\n",
       " FetchedTranscriptSnippet(text='is I take a lot of inspiration from what like the\\xa0\\ntop 5% of most engaged users do with chacht like\\xa0\\xa0', start=526.16, duration=6.48),\n",
       " FetchedTranscriptSnippet(text=\"it's really amazing how much people are learning\\xa0\\nand doing and you know outputting. So my I've\\xa0\\xa0\", start=532.64, duration=7.84),\n",
       " FetchedTranscriptSnippet(text=\"only had GPT5 for a couple hours so I've been\\xa0\\nplaying. What do you think so far? I'm I'm just\\xa0\\xa0\", start=540.48, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='learning how to interact with it. I mean part of\\xa0\\nthe interesting thing is I feel like I just caught\\xa0\\xa0', start=545.6, duration=4.32),\n",
       " FetchedTranscriptSnippet(text=\"up on how to use GPT4 and now I'm trying to learn\\xa0\\nhow to use GPD5. I'm curious what the specific\\xa0\\xa0\", start=549.92, duration=7.28),\n",
       " FetchedTranscriptSnippet(text=\"tasks that you found most interesting are because\\xa0\\nI imagine you've been using it for a while now.\\xa0\\xa0\", start=557.2, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"I I have been most impressed by the coding tasks.\\xa0\\nI mean, there's a lot of other things it's really\\xa0\\xa0\", start=562.72, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='good at, but this this idea of the AI can write\\xa0\\nsoftware for anything. And that means that you\\xa0\\xa0', start=566.88, duration=10.32),\n",
       " FetchedTranscriptSnippet(text='can express ideas in new ways that the AI can\\xa0\\ndo very advanced things. It can do, you know,\\xa0\\xa0', start=577.2, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='it can like in some sense you could like ask\\xa0\\nGPT4 anything, but because GPT5 is so good at\\xa0\\xa0', start=582.88, duration=6.48),\n",
       " FetchedTranscriptSnippet(text=\"programming, it feels like it can do anything. Of\\xa0\\ncourse, it can't do things in the physical world,\\xa0\\xa0\", start=589.36, duration=3.04),\n",
       " FetchedTranscriptSnippet(text='but it can get a computer to do very complex\\xa0\\nthings. And software is this super powerful,\\xa0\\xa0', start=592.4, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='you know, way to like control some stuff and\\xa0\\nactually do some things. So, that that for me\\xa0\\xa0', start=598.72, duration=5.84),\n",
       " FetchedTranscriptSnippet(text=\"has been the most striking. Um, it's gotten it's\\xa0\\nmuch better at writing. So, this is like there's\\xa0\\xa0\", start=604.56, duration=7.52),\n",
       " FetchedTranscriptSnippet(text='this whole thing of AI slop like AI writes in this\\xa0\\nkind of like quite annoying way and M dashes. M we\\xa0\\xa0', start=612.08, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='still have the M dashes in GPT5. A lot of people\\xa0\\nlike them dashes, but the writing quality of GPT5\\xa0\\xa0', start=618.48, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='is gotten much better. We still have a long way\\xa0\\nto go. We want to improve it more, but like uh\\xa0\\xa0', start=624.72, duration=6.4),\n",
       " FetchedTranscriptSnippet(text=\"I've a thing we've heard a lot from people inside\\xa0\\nof OpenAI is that man, they started using GPT5,\\xa0\\xa0\", start=631.12, duration=5.68),\n",
       " FetchedTranscriptSnippet(text=\"they knew it was better on all the metrics, but\\xa0\\nthere's this like nuance quality they can't quite\\xa0\\xa0\", start=636.8, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='articulate, but then when they have to go back\\xa0\\nto GPT4 to test something, it feels terrible.\\xa0\\xa0', start=641.76, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"And I I don't know exactly what the cause\\xa0\\nof that is, but I suspect part of it is the\\xa0\\xa0\", start=645.84, duration=3.68),\n",
       " FetchedTranscriptSnippet(text='writing feels so much more natural and better.\\xa0\\nI in preparation for this interview reached out\\xa0\\xa0', start=649.52, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='to a couple other leaders in AI and technology\\xa0\\nand gathered a couple questions for you. Okay,\\xa0\\xa0', start=655.2, duration=5.28),\n",
       " FetchedTranscriptSnippet(text='so this next question is from Stripe CEO Patrick\\xa0\\nCollison. This will be a good one. Read this\\xa0\\xa0', start=660.48, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"verbatim. It's about the next stage. What what\\xa0\\ncomes after GBT5? In which year do you think a\\xa0\\xa0\", start=666.0, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"large language model will make a significant\\xa0\\nscientific discovery and what's missing such\\xa0\\xa0\", start=673.52, duration=4.8),\n",
       " FetchedTranscriptSnippet(text=\"that it hasn't happened yet? He caveed here that\\xa0\\nwe should leave math and special case models like\\xa0\\xa0\", start=678.32, duration=4.72),\n",
       " FetchedTranscriptSnippet(text=\"alpha fold aside. He's specifically asking about\\xa0\\nfully general purpose models like the GPT series.\\xa0\\xa0\", start=683.04, duration=5.04),\n",
       " FetchedTranscriptSnippet(text='I would say most people will agree that that\\xa0\\nhappens at some point over the next two years.\\xa0\\xa0', start=688.08, duration=4.0),\n",
       " FetchedTranscriptSnippet(text='But the definition of significant matters a lot.\\xa0\\nAnd so some people significant might happen,\\xa0\\xa0', start=692.08, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='you know, in early 25. Some people might maybe\\xa0\\nnot until late 2026. Sorry, early 2026. Maybe some\\xa0\\xa0', start=698.24, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='people not until late 2027, but I would I would\\xa0\\nbet that by late 27, most people agree that there\\xa0\\xa0', start=703.92, duration=6.64),\n",
       " FetchedTranscriptSnippet(text='has been an AIdriven significant new discovery.\\xa0\\nAnd the thing that I think is missing is just\\xa0\\xa0', start=710.56, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='the kind of cognitive power of these models.\\xa0\\nA framework that one of the researchers said\\xa0\\xa0', start=714.96, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='to me that I really liked is, you know, a year\\xa0\\nago we could do well on like a high school like\\xa0\\xa0', start=720.8, duration=6.96),\n",
       " FetchedTranscriptSnippet(text='a basic high school math competition problems that\\xa0\\nmight take a professional mathematician seconds to\\xa0\\xa0', start=727.76, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='a few minutes. We very recently got an IMO gold\\xa0\\nmedal. That is a crazy difficult like could you\\xa0\\xa0', start=732.96, duration=6.4),\n",
       " FetchedTranscriptSnippet(text=\"explain what that means? That's kind of like the\\xa0\\nhardest competition math test. This is something\\xa0\\xa0\", start=739.36, duration=4.0),\n",
       " FetchedTranscriptSnippet(text=\"that like the very very top slice of the world.\\xa0\\nmany many professional mathematicians wouldn't\\xa0\\xa0\", start=743.36, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='solve a single problem and we scored at the top\\xa0\\nlevel. Now there are some humans that got an even\\xa0\\xa0', start=748.72, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='higher score in the gold medal range but we we\\xa0\\nlike this is a crazy accomplishment and these\\xa0\\xa0', start=753.92, duration=4.88),\n",
       " FetchedTranscriptSnippet(text=\"each of these problems it's like six problems over\\xa0\\n9 hours so hour and a half per problem for a great\\xa0\\xa0\", start=758.8, duration=5.36),\n",
       " FetchedTranscriptSnippet(text=\"mathematician. So we've gone from a few seconds\\xa0\\nto a few minutes to an hour and a half maybe to\\xa0\\xa0\", start=764.16, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='prove a significant new mathematical theorem is\\xa0\\nlike a thousand hours of work for a top person\\xa0\\xa0', start=769.92, duration=4.8),\n",
       " FetchedTranscriptSnippet(text=\"in the world. So we've got to go from, you know,\\xa0\\nanother significant gain. But if you look at our\\xa0\\xa0\", start=774.72, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"trajectory, you can say like, okay, we're getting\\xa0\\nto that. We have a path to get to that time\\xa0\\xa0\", start=780.72, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"horizon. We just need to keep scaling the models.\\xa0\\nThe long-term future that you've described is\\xa0\\xa0\", start=784.64, duration=7.28),\n",
       " FetchedTranscriptSnippet(text=\"super intelligence. What does that actually mean?\\xa0\\nAnd how will we know when we've hit it? If we had\\xa0\\xa0\", start=791.92, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='a system that could do better research, better AI\\xa0\\nresearch than uh say the whole open AI research\\xa0\\xa0', start=798.08, duration=8.4),\n",
       " FetchedTranscriptSnippet(text='team, like if we were willing, if we said, \"Okay,\\xa0\\nthe best way we can use our GPUs is to let this AI\\xa0\\xa0', start=806.48, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='decide what experiments we should run smarter than\\xa0\\nlike the whole brain trust of Open AAI.\" Yeah. And\\xa0\\xa0', start=811.44, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='if that same to make a personal example, if that\\xa0\\nsame system could do a better job running open AI\\xa0\\xa0', start=816.32, duration=4.0),\n",
       " FetchedTranscriptSnippet(text=\"than I could. So you have something that's like,\\xa0\\nyou know, better than the best researchers, better\\xa0\\xa0\", start=820.32, duration=3.52),\n",
       " FetchedTranscriptSnippet(text='than me at this, better than other people at their\\xa0\\njobs, that would feel like super intelligence to\\xa0\\xa0', start=823.84, duration=3.2),\n",
       " FetchedTranscriptSnippet(text='me. That is a sentence that would have sounded\\xa0\\nlike science fiction just a couple years ago.\\xa0\\xa0', start=827.04, duration=4.16),\n",
       " FetchedTranscriptSnippet(text=\"And now it kind of does, but it's you can like see\\xa0\\nit through the fog. Yes. And so one of the steps\\xa0\\xa0\", start=831.2, duration=5.84),\n",
       " FetchedTranscriptSnippet(text=\"it sounds like you're saying on that path is this\\xa0\\nmoment of scientific discovery of asking better\\xa0\\xa0\", start=837.04, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='questions of grappling with things in a in a way\\xa0\\nthat expert level humans do to come up with new\\xa0\\xa0', start=842.64, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='discoveries. One of the things that keeps knocking\\xa0\\naround in my head is if we were in 1899 say and\\xa0\\xa0', start=848.64, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='we were able to give it all of physics up until\\xa0\\nthat point and play it out a little bit. Nothing\\xa0\\xa0', start=854.4, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='further than that. Like at what point would one\\xa0\\nof these systems come up with general relativity?\\xa0\\xa0', start=858.64, duration=4.56),\n",
       " FetchedTranscriptSnippet(text='Interesting question is did you like if we think\\xa0\\nabout that forward like like if we think of where\\xa0\\xa0', start=864.16, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='we are now should a if if we never got another\\xa0\\npiece of physics data. Yeah. Do we expect that a\\xa0\\xa0', start=868.88, duration=9.76),\n",
       " FetchedTranscriptSnippet(text='really good super intelligence could just think\\xa0\\nsuper hard about our existing data and maybe\\xa0\\xa0', start=878.64, duration=4.32),\n",
       " FetchedTranscriptSnippet(text='say like solve high energy physics with no new\\xa0\\nparticle accelerator or does it need to build a\\xa0\\xa0', start=882.96, duration=4.64),\n",
       " FetchedTranscriptSnippet(text=\"new one and design new experiments? Obviously\\xa0\\nwe don't know the answer to that. Different\\xa0\\xa0\", start=887.6, duration=3.44),\n",
       " FetchedTranscriptSnippet(text='people have different speculation. Uh but I\\xa0\\nsuspect we will find that for a lot of science,\\xa0\\xa0', start=891.04, duration=6.88),\n",
       " FetchedTranscriptSnippet(text=\"it's not enough to just think harder about data we\\xa0\\nhave, but we will need to build new instruments,\\xa0\\xa0\", start=897.92, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='conduct new experiments, and that will take some\\xa0\\ntime. Like that that is the real world is slow\\xa0\\xa0', start=903.28, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"and messy and you know whatever. So I'm sure we\\xa0\\ncould make some more progress just by thinking\\xa0\\xa0\", start=907.2, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='harder about the current scientific data we\\xa0\\nhave in the world. But my guess is to make\\xa0\\xa0', start=912.32, duration=4.32),\n",
       " FetchedTranscriptSnippet(text=\"the big progress we'll also need to build new\\xa0\\nmachines and run new experiments and there will\\xa0\\xa0\", start=916.64, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='be some slowdown built into that. Another way of\\xa0\\nof thinking about this is AI systems now are just\\xa0\\xa0', start=921.28, duration=8.24),\n",
       " FetchedTranscriptSnippet(text=\"incredibly good at answering almost any question.\\xa0\\nBut maybe one of the things we're saying is it's\\xa0\\xa0\", start=929.52, duration=5.76),\n",
       " FetchedTranscriptSnippet(text=\"another leap yet. And what Patrick's question\\xa0\\nis getting at is to ask the better questions.\\xa0\\xa0\", start=935.28, duration=4.8),\n",
       " FetchedTranscriptSnippet(text='Or or if we go back to this kind of timeline\\xa0\\nquestion, we could maybe say that AI systems\\xa0\\xa0', start=940.08, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"are superhuman on one minute tasks, but a long\\xa0\\nway to go to the thousand hour tasks. And there's\\xa0\\xa0\", start=945.04, duration=7.04),\n",
       " FetchedTranscriptSnippet(text='a dimension of human intelligence that seems\\xa0\\nvery different than AI systems when it comes\\xa0\\xa0', start=952.08, duration=7.2),\n",
       " FetchedTranscriptSnippet(text=\"to these long horizon tasks. Now, I think we will\\xa0\\nfigure it out, but today it's a real weak point.\\xa0\\xa0\", start=959.28, duration=5.6),\n",
       " FetchedTranscriptSnippet(text=\"We've talked about where we are now with GBC5.\\xa0\\nWe talked about the end goal or future goal of\\xa0\\xa0\", start=964.88, duration=5.04),\n",
       " FetchedTranscriptSnippet(text='super intelligence. One of the questions that\\xa0\\nI have, of course, is what does it look like\\xa0\\xa0', start=969.92, duration=5.76),\n",
       " FetchedTranscriptSnippet(text=\"to walk through the fog between the two. The next\\xa0\\nquestion is from Nvidia CEO Jensen Hong. I'm going\\xa0\\xa0\", start=975.68, duration=6.72),\n",
       " FetchedTranscriptSnippet(text='to read this verbatim. Fact is what is. Truth is\\xa0\\nwhat it means. So facts are objective. Truths are\\xa0\\xa0', start=982.4, duration=7.76),\n",
       " FetchedTranscriptSnippet(text='personal. They depend on perspective, culture,\\xa0\\nvalues, beliefs, context. One AI can learn and\\xa0\\xa0', start=990.16, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='know the facts. But how does one AI know the\\xa0\\ntruth for everyone in every country and every\\xa0\\xa0', start=995.92, duration=5.28),\n",
       " FetchedTranscriptSnippet(text=\"background? I'm going to accept as axioms those\\xa0\\ndefinitions. I'm not sure if I agree with them,\\xa0\\xa0\", start=1001.2, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='but in the issues of time, I will just take them.\\xa0\\nI will take those definitions and go with it. Um,', start=1007.2, duration=7.52),\n",
       " FetchedTranscriptSnippet(text='I have been surprised, I think many other people\\xa0\\nhave been surprised too about how fluent AI is\\xa0\\xa0', start=1014.72, duration=6.64),\n",
       " FetchedTranscriptSnippet(text='at adapting to different cultural contexts and\\xa0\\nindividuals. One of my favorite features that we\\xa0\\xa0', start=1021.36, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='have ever launched in chatbt is the the sort of\\xa0\\nenhanced memory that came out earlier this year.\\xa0\\xa0', start=1026.72, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='like it really feels like my Chad GBT gets to\\xa0\\nknow me and what I care about and like my life\\xa0\\xa0', start=1032.08, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='experiences and background and the things that\\xa0\\nhave led me to where they are. A friend of mine\\xa0\\xa0', start=1037.68, duration=5.04),\n",
       " FetchedTranscriptSnippet(text=\"recently who's been a huge CHBT user, so he's\\xa0\\ngot a lot of a a lot of he's put a lot of his\\xa0\\xa0\", start=1042.72, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='life into all these conversations. He gave his\\xa0\\nChad GBT a bunch of personality tests and asked\\xa0\\xa0', start=1048.32, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='them to answer as if they were him and it got\\xa0\\nthe same scores he actually got, even though\\xa0\\xa0', start=1054.64, duration=3.76),\n",
       " FetchedTranscriptSnippet(text=\"he'd never really talked about his personality.\\xa0\\nAnd my ChachiBD has really learned over the years\\xa0\\xa0\", start=1058.4, duration=6.08),\n",
       " FetchedTranscriptSnippet(text='of me talking to it about my culture, my\\xa0\\nvalues, my life. And I have used, you know,\\xa0\\xa0', start=1064.48, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"I sometimes will use it in like uh I'll use like\\xa0\\na free account just to see what it's like without\\xa0\\xa0\", start=1072.0, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"any of my history and it feels really really\\xa0\\ndifferent. So I think we've all been surprised on\\xa0\\xa0\", start=1077.52, duration=4.32),\n",
       " FetchedTranscriptSnippet(text='the upside of how good AI is at learning this and\\xa0\\nadapting. And so do you envision in many different\\xa0\\xa0', start=1081.84, duration=8.16),\n",
       " FetchedTranscriptSnippet(text='parts of the world people using different\\xa0\\nAIs with different sort of cultural norms and\\xa0\\xa0', start=1090.0, duration=4.0),\n",
       " FetchedTranscriptSnippet(text=\"contexts? Is that what we're saying? I think that\\xa0\\neveryone will use like the same fundamental model,\\xa0\\xa0\", start=1094.0, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='but there will be context provided to that model\\xa0\\nthat will make it behave in sort of personalized\\xa0\\xa0', start=1098.72, duration=4.64),\n",
       " FetchedTranscriptSnippet(text=\"way they want their community wants. Whatever.\\xa0\\nI think when we're getting at this idea of facts\\xa0\\xa0\", start=1103.36, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='and truth and uh it brings me to this seems like a\\xa0\\ngood moment for our first time travel trip. Okay,\\xa0\\xa0', start=1108.56, duration=7.28),\n",
       " FetchedTranscriptSnippet(text=\"we're going to 2030. This is a serious question,\\xa0\\nbut I want to ask it with a light-hearted example.\\xa0\\xa0\", start=1115.84, duration=5.6),\n",
       " FetchedTranscriptSnippet(text=\"Have you seen the bunnies that are jumping on\\xa0\\nthe trampoline? Yes. So, for those who haven't\\xa0\\xa0\", start=1121.44, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='seen it, maybe it looks like backyard footage of\\xa0\\nbunnies enjoying jumping on a trampoline. And this\\xa0\\xa0', start=1125.84, duration=5.36),\n",
       " FetchedTranscriptSnippet(text=\"has gone incredibly viral recently. There's a\\xa0\\nhumanmade song about it. It's a whole thing.\\xa0\\xa0\", start=1131.2, duration=5.04),\n",
       " FetchedTranscriptSnippet(text='There were a trampoline. And I think the reason\\xa0\\nwhy people reacted so strongly to it, it was maybe\\xa0\\xa0', start=1136.24, duration=7.92),\n",
       " FetchedTranscriptSnippet(text='the first time people saw a video, enjoyed it,\\xa0\\nand then later found out that it was completely AI\\xa0\\xa0', start=1144.16, duration=6.32),\n",
       " FetchedTranscriptSnippet(text=\"generated. In this time travel trip, if we imagine\\xa0\\nin 2030, we are teenagers and we're scrolling\\xa0\\xa0\", start=1150.48, duration=6.08),\n",
       " FetchedTranscriptSnippet(text=\"whatever teenagers are scrolling in 2030. How do\\xa0\\nwe figure out what's real and what's not real?\\xa0\\xa0\", start=1156.56, duration=6.96),\n",
       " FetchedTranscriptSnippet(text='I mean, I can give all sorts of literal answers\\xa0\\nto that question. We could be cryptographically\\xa0\\xa0', start=1164.88, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='signing stuff and we could decide who we trust\\xa0\\ntheir signature if they actually filmed something\\xa0\\xa0', start=1169.52, duration=4.32),\n",
       " FetchedTranscriptSnippet(text=\"or not. But but my sense is what's going to\\xa0\\nhappen is it's just going to like gradually\\xa0\\xa0\", start=1173.84, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"converge. You know, even like a photo you take\\xa0\\nout of your iPhone today, it's like mostly real,\\xa0\\xa0\", start=1181.36, duration=6.08),\n",
       " FetchedTranscriptSnippet(text=\"but it's a little not. There's like in some AI\\xa0\\nthing running there in a way you don't understand\\xa0\\xa0\", start=1187.44, duration=4.8),\n",
       " FetchedTranscriptSnippet(text='and making it look like a little bit better and\\xa0\\nsometimes you see these weird things where the\\xa0\\xa0', start=1192.24, duration=3.52),\n",
       " FetchedTranscriptSnippet(text=\"moon. Yeah. Yeah. Yeah. Yeah. But there's like\\xa0\\na lot of processing power between the photons\\xa0\\xa0\", start=1195.76, duration=8.0),\n",
       " FetchedTranscriptSnippet(text=\"captured by that camera sensor and the image\\xa0\\nyou eventually see. And you've decided it's real\\xa0\\xa0\", start=1203.76, duration=5.92),\n",
       " FetchedTranscriptSnippet(text=\"enough or most people decided it's real enough.\\xa0\\nBut we've accepted some gradual move from when it\\xa0\\xa0\", start=1209.68, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='was like photons hitting the film in a camera. And\\xa0\\nyou know, if you go look at some video on Tik Tok,\\xa0\\xa0', start=1214.88, duration=7.36),\n",
       " FetchedTranscriptSnippet(text=\"there's probably all sorts of video editing tools\\xa0\\nbeing used to make it better than real look. Yeah,\\xa0\\xa0\", start=1222.24, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"exactly. Or it's just like, you know, whole\\xa0\\nscenes are completely generated or some of\\xa0\\xa0\", start=1228.24, duration=4.32),\n",
       " FetchedTranscriptSnippet(text='the whole videos are generated like those bunnies\\xa0\\non that trampoline. And and I think that the the\\xa0\\xa0', start=1232.56, duration=5.52),\n",
       " FetchedTranscriptSnippet(text='sort of like the threshold for how real does it\\xa0\\nhave to be to consider to be real will just keep\\xa0\\xa0', start=1238.08, duration=5.76),\n",
       " FetchedTranscriptSnippet(text=\"moving. So it's sort of a education question.\\xa0\\nIt's a people will Yeah. I mean media is always\\xa0\\xa0\", start=1243.84, duration=9.04),\n",
       " FetchedTranscriptSnippet(text='like a little bit real and a little bit not real.\\xa0\\nLike you know we watch like a sci-fi movie. We\\xa0\\xa0', start=1252.88, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"know that didn't really happen. You watch like\\xa0\\nsomeone's like beautiful photo of themselves on\\xa0\\xa0\", start=1258.32, duration=4.56),\n",
       " FetchedTranscriptSnippet(text='vacation on Instagram. like, okay, maybe that\\xa0\\nphoto was like literally taken, but you know,\\xa0\\xa0', start=1262.88, duration=3.68),\n",
       " FetchedTranscriptSnippet(text=\"there's like tons of tourists in line for the same\\xa0\\nphoto and that's like left out of it. And I think\\xa0\\xa0\", start=1266.56, duration=3.76),\n",
       " FetchedTranscriptSnippet(text='we just accept that now. Certainly, a higher\\xa0\\npercentage of media both will will feel not\\xa0\\xa0', start=1270.32, duration=6.4),\n",
       " FetchedTranscriptSnippet(text=\"real. Um, but I think that's been the long-term\\xa0\\ntrend. Anyway, we're going to jump again. Okay,\\xa0\\xa0\", start=1276.72, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"2035, we're graduating from college, you and me.\\xa0\\nThere are some leaders in the AI space that have\\xa0\\xa0\", start=1282.72, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='said that in 5 years half of the entry level\\xa0\\nwhite collar workforce will be replaced by AI.\\xa0\\xa0', start=1288.32, duration=6.16),\n",
       " FetchedTranscriptSnippet(text=\"So we're college graduates in 5 years. What do\\xa0\\nyou hope the world looks like for us? I think\\xa0\\xa0\", start=1294.48, duration=4.8),\n",
       " FetchedTranscriptSnippet(text=\"there's been a lot of talk about how AI might\\xa0\\ncause job displacement, but I'm also curious. I\\xa0\\xa0\", start=1299.28, duration=6.48),\n",
       " FetchedTranscriptSnippet(text='have a job that nobody would have thought we\\xa0\\ncould have, you know, totally a decade ago.\\xa0\\xa0', start=1305.76, duration=6.16),\n",
       " FetchedTranscriptSnippet(text=\"What are the things that we could look ahead if\\xa0\\nwe're thinking about in 2035 that like graduating\\xa0\\xa0\", start=1311.92, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='college student, if they still go to college at\\xa0\\nall, could very well be like leaving on a mission\\xa0\\xa0', start=1317.12, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='to explore the solar system on a spaceship in some\\xa0\\nkind of completely new exciting, super well- paid,\\xa0\\xa0', start=1322.8, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='super interesting job and feeling so bad for you\\xa0\\nand I that like we had to do this kind of like\\xa0\\xa0', start=1327.76, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='really boring old kind of work and everything\\xa0\\nis just better. Like I I 10 years feels very\\xa0\\xa0', start=1332.16, duration=6.32),\n",
       " FetchedTranscriptSnippet(text=\"hard to imagine at this point because it's too\\xa0\\nfar. It's too far. If you compound the current\\xa0\\xa0\", start=1338.48, duration=4.48),\n",
       " FetchedTranscriptSnippet(text=\"rate of change for 10 more years, it's probably\\xa0\\nsomething we can't even time travel trips. I 10\\xa0\\xa0\", start=1342.96, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='like I mean I think now would be really hard\\xa0\\nto imagine 10 years ago. Yeah. Uh but I think\\xa0\\xa0', start=1348.64, duration=6.32),\n",
       " FetchedTranscriptSnippet(text=\"10 years forward will be even much harder, much\\xa0\\nmore different. So let's make it 5 years. We're\\xa0\\xa0\", start=1354.96, duration=6.08),\n",
       " FetchedTranscriptSnippet(text=\"still going to 2030. I'm curious what you\\xa0\\nthink the pretty short-term impacts of this\\xa0\\xa0\", start=1361.04, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='will be for for young people. I mean, these like\\xa0\\nhalf of entry- level jobs replaced by AI makes\\xa0\\xa0', start=1366.24, duration=6.8),\n",
       " FetchedTranscriptSnippet(text='it sound like a very different world that they\\xa0\\nwould be entering than the one that I did. Um,', start=1373.04, duration=9.12),\n",
       " FetchedTranscriptSnippet(text=\"I think it's totally true that some classes of\\xa0\\njobs will totally go away. This always happens\\xa0\\xa0\", start=1382.16, duration=4.32),\n",
       " FetchedTranscriptSnippet(text=\"and young people are the best at adapting to this.\\xa0\\nI'm more worried about what it means, not for the\\xa0\\xa0\", start=1386.48, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"like 22-y old, but for the 62-y old that doesn't\\xa0\\nwant to go re retrain or reskill or whatever the\\xa0\\xa0\", start=1390.56, duration=6.88),\n",
       " FetchedTranscriptSnippet(text='politicians call it that no one actually wants\\xa0\\nbut politicians and most of the time. If I were\\xa0\\xa0', start=1397.44, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='22 right now and graduating college, I would\\xa0\\nfeel like the luckiest kid in all of history.\\xa0\\xa0', start=1403.44, duration=4.24),\n",
       " FetchedTranscriptSnippet(text=\"Why? Because there's never been a more amazing\\xa0\\ntime to go create something totally new, to go\\xa0\\xa0\", start=1407.68, duration=5.44),\n",
       " FetchedTranscriptSnippet(text='invent something, to start a company, whatever\\xa0\\nit is. I think it is probably possible now to\\xa0\\xa0', start=1413.12, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='start a company that is a oneperson company that\\xa0\\nwill go on to be worth like more than a billion\\xa0\\xa0', start=1418.32, duration=4.0),\n",
       " FetchedTranscriptSnippet(text='dollars and more importantly than that deliver an\\xa0\\namazing product and service to the world and that\\xa0\\xa0', start=1422.32, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='that is like a crazy thing. You have access to\\xa0\\ntools that can let you do what used to take teams\\xa0\\xa0', start=1426.56, duration=5.92),\n",
       " FetchedTranscriptSnippet(text='of hundreds and you just have to like you know\\xa0\\nlearn how to use these tools and come up with a\\xa0\\xa0', start=1432.48, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"great idea and it's it's like quite amazing. If\\xa0\\nwe take a step back, I think the most important\\xa0\\xa0\", start=1438.48, duration=7.2),\n",
       " FetchedTranscriptSnippet(text='thing that this audience could hear from you\\xa0\\non this optimistic show is in two parts. First,\\xa0\\xa0', start=1445.68, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"there's tactically, how are you actually trying\\xa0\\nto build the world's most powerful intelligence\\xa0\\xa0\", start=1453.2, duration=7.36),\n",
       " FetchedTranscriptSnippet(text='and what are the rate limiting factors to doing\\xa0\\nthat? And then philosophically, how are you and\\xa0\\xa0', start=1460.56, duration=5.52),\n",
       " FetchedTranscriptSnippet(text='others working on building that technology in\\xa0\\na way that really helps and not hurts people?\\xa0\\xa0', start=1466.08, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='So just taking the tactical part right now.\\xa0\\nMy understanding is that there are three big\\xa0\\xa0', start=1470.8, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='categories that have been limiting factors for\\xa0\\nAI. The first is compute, the second is data and\\xa0\\xa0', start=1477.2, duration=6.08),\n",
       " FetchedTranscriptSnippet(text='the third is algorithmic design. How do you think\\xa0\\nabout each of those three categories right now?\\xa0\\xa0', start=1483.28, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='And if you were to help someone understand\\xa0\\nthe next headlines that they might see,\\xa0\\xa0', start=1489.44, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"how would you help them make sense of all this?\\xa0\\nI I would say there's a fourth too which is uh\\xa0\\xa0\", start=1494.4, duration=7.28),\n",
       " FetchedTranscriptSnippet(text='figuring out the products to build like techn like\\xa0\\nscientific progress on its own not put into the\\xa0\\xa0', start=1501.68, duration=5.2),\n",
       " FetchedTranscriptSnippet(text=\"hands of people is of limited utility and doesn't\\xa0\\nsort of co-evolve with society in the same way\\xa0\\xa0\", start=1506.88, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='but if I could hit all four of those um so on\\xa0\\nthe compute side yeah this is like the biggest\\xa0\\xa0', start=1511.76, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"infrastructure project certainly that I've ever\\xa0\\nseen possibly it will become the I think it will\\xa0\\xa0\", start=1517.2, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='maybe already is the biggest and most expensive\\xa0\\none in human history but the the whole supply\\xa0\\xa0', start=1521.36, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='chain from making the chips and the memory and\\xa0\\nthe networking gear, racking them up in servers,\\xa0\\xa0', start=1527.52, duration=6.56),\n",
       " FetchedTranscriptSnippet(text='doing, you know, a giant construction project to\\xa0\\nbuild like a mega mega data center, putting the,\\xa0\\xa0', start=1534.08, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='you know, finding a way to get the energy, which\\xa0\\nis often a limiting factor piece of this and all\\xa0\\xa0', start=1540.4, duration=4.24),\n",
       " FetchedTranscriptSnippet(text=\"the other components together. This is hugely\\xa0\\ncomplex and expensive. And we are we're still\\xa0\\xa0\", start=1544.64, duration=4.88),\n",
       " FetchedTranscriptSnippet(text=\"doing this in like a sort of bespoke one-off way\\xa0\\nalthough it's getting better. Like eventually we\\xa0\\xa0\", start=1549.52, duration=7.28),\n",
       " FetchedTranscriptSnippet(text='will just design a whole kind of like mega factory\\xa0\\nthat takes you know I mean spiritually it will be\\xa0\\xa0', start=1556.8, duration=8.48),\n",
       " FetchedTranscriptSnippet(text='melting sand on one end and putting out fully\\xa0\\nbuilt AI compute on the other but we are a long\\xa0\\xa0', start=1565.28, duration=5.12),\n",
       " FetchedTranscriptSnippet(text=\"way to go from that and it's a it's an enormously\\xa0\\ncomplex and expensive process. uh we are putting\\xa0\\xa0\", start=1570.4, duration=10.0),\n",
       " FetchedTranscriptSnippet(text='a huge amount of work into building out as much\\xa0\\ncompute as we can and to do it fast and you know\\xa0\\xa0', start=1580.4, duration=5.36),\n",
       " FetchedTranscriptSnippet(text=\"it's going to be like sad because GP5 is going\\xa0\\nto launch and there's going to be another big\\xa0\\xa0\", start=1585.76, duration=4.32),\n",
       " FetchedTranscriptSnippet(text=\"spike in demand and we're not going to be able\\xa0\\nto serve it and it's going to be like those early\\xa0\\xa0\", start=1590.08, duration=3.28),\n",
       " FetchedTranscriptSnippet(text='GPD4 days and the world just wants much more AI\\xa0\\nthan we can currently deliver and building more\\xa0\\xa0', start=1593.36, duration=6.24),\n",
       " FetchedTranscriptSnippet(text=\"compute is an important part of doing that.\\xa0\\nThat's actually this is what I expect to turn\\xa0\\xa0\", start=1599.6, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='the majority of my attention to is how we build\\xa0\\ncompute at much greater scales. Uh so how we go\\xa0\\xa0', start=1603.76, duration=6.88),\n",
       " FetchedTranscriptSnippet(text='from millions to tens of millions and hundreds of\\xa0\\nmillions and eventually hopefully billions of GPUs\\xa0\\xa0', start=1610.64, duration=5.68),\n",
       " FetchedTranscriptSnippet(text=\"that are sort of in service of what people want\\xa0\\nto do with this. When you're thinking about it,\\xa0\\xa0\", start=1616.32, duration=3.68),\n",
       " FetchedTranscriptSnippet(text=\"what are the big challenges here in this category\\xa0\\nthat you're going to be thinking about? We're\\xa0\\xa0\", start=1620.0, duration=4.24),\n",
       " FetchedTranscriptSnippet(text=\"currently most limited by energy. um you know like\\xa0\\nif you're gonna you want to run a gigawatt scale\\xa0\\xa0\", start=1624.24, duration=6.72),\n",
       " FetchedTranscriptSnippet(text=\"data center it's like a gigawatt how hard can that\\xa0\\nbe to find it's really hard to find a gigawatt of\\xa0\\xa0\", start=1630.96, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"power available in short term we're also very much\\xa0\\nlimited by the processing chips and the memory\\xa0\\xa0\", start=1634.88, duration=7.12),\n",
       " FetchedTranscriptSnippet(text=\"chips uh how you package these all together how\\xa0\\nyou build the racks and then there's like a list\\xa0\\xa0\", start=1642.0, duration=4.0),\n",
       " FetchedTranscriptSnippet(text=\"of other things that are you know there's like\\xa0\\npermits there's construction work uh but but\\xa0\\xa0\", start=1646.0, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='again the goal here will be to really automate\\xa0\\nthis once we get some of those robots built,\\xa0\\xa0', start=1652.16, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='they can help us automate it even more. But just,\\xa0\\nyou know, like a world where you can basically\\xa0\\xa0', start=1657.28, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"pour in money and get out a pre-built data center.\\xa0\\nUh so that'll be that'll be a huge unlock if we\\xa0\\xa0\", start=1661.2, duration=6.8),\n",
       " FetchedTranscriptSnippet(text='can get it to work. Second category, data. Yeah,\\xa0\\nthese models have gotten so smart. There was a\\xa0\\xa0', start=1668.0, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='time when we could just feed it another physics\\xa0\\ntextbook and got a little bit smarter at physics,\\xa0\\xa0', start=1674.32, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='but now like honestly GBT5 understands\\xa0\\neverything in a physics textbook pretty well.\\xa0\\xa0', start=1678.72, duration=5.76),\n",
       " FetchedTranscriptSnippet(text=\"We're excited about synthetic data. We're very\\xa0\\nexcited about our users helping us create harder\\xa0\\xa0\", start=1684.48, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"and harder tasks and environments to go off and\\xa0\\nhave the system solve. But uh I think we're data\\xa0\\xa0\", start=1690.0, duration=6.88),\n",
       " FetchedTranscriptSnippet(text=\"will always be important, but we're entering a\\xa0\\nrealm where the models need to learn things that\\xa0\\xa0\", start=1696.88, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"don't exist in any data set yet. They have to\\xa0\\ngo discover new things. So that's like a crazy\\xa0\\xa0\", start=1704.4, duration=3.52),\n",
       " FetchedTranscriptSnippet(text='new How do you teach a model to discover new\\xa0\\nthings? Well, humans can do it. like we can\\xa0\\xa0', start=1707.92, duration=4.48),\n",
       " FetchedTranscriptSnippet(text='go off and come up with hypotheses and test them\\xa0\\nand get experimental results and update on what we\\xa0\\xa0', start=1712.4, duration=4.4),\n",
       " FetchedTranscriptSnippet(text=\"learn. So probably the same kind of way. And then\\xa0\\nthere's algorithmic design. Yeah, we've made huge\\xa0\\xa0\", start=1716.8, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='progress on algorithmic design. Uh the thing that\\xa0\\nthe thing that I think open does best in the world\\xa0\\xa0', start=1722.16, duration=5.44),\n",
       " FetchedTranscriptSnippet(text='is we have built this culture of repeated and big\\xa0\\nalgorithmic research gains. So we kind of you know\\xa0\\xa0', start=1727.6, duration=7.76),\n",
       " FetchedTranscriptSnippet(text=\"figured out the what became the GPT paradigm. We\\xa0\\nfigured out became the reasoning paradigm. We're\\xa0\\xa0\", start=1735.36, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='working on some new ones now. Um, but it is very\\xa0\\nexciting to me to think that there are still many\\xa0\\xa0', start=1740.56, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='more orders of magnitudes of algorithmic\\xa0\\ngains ahead of us. We we just yesterday\\xa0\\xa0', start=1746.24, duration=5.04),\n",
       " FetchedTranscriptSnippet(text=\"uh released a model called GPOSS, open source\\xa0\\nmodel. It's a model that is as smart as 04 Mini,\\xa0\\xa0\", start=1751.28, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='which is a very smart model that runs locally on\\xa0\\na laptop. And this blows my mind. Yeah. Like if\\xa0\\xa0', start=1757.52, duration=6.4),\n",
       " FetchedTranscriptSnippet(text=\"you had asked me a few years ago when we'd have\\xa0\\na model of that intelligence running on a laptop,\\xa0\\xa0\", start=1763.92, duration=5.92),\n",
       " FetchedTranscriptSnippet(text='I would have said many many years in the future.\\xa0\\nBut then we we found some algorithmic gains\\xa0\\xa0', start=1769.84, duration=6.88),\n",
       " FetchedTranscriptSnippet(text='um particularly around reasoning but also some\\xa0\\nother things that let us do a a tiny model that\\xa0\\xa0', start=1776.72, duration=4.88),\n",
       " FetchedTranscriptSnippet(text=\"can do this amazing thing. And you know those are\\xa0\\nthose are the most fun things. That's like kind of\\xa0\\xa0\", start=1781.6, duration=5.28),\n",
       " FetchedTranscriptSnippet(text=\"the coolest part of the job. I can see you really\\xa0\\nenjoying thinking about this. I'm curious for\\xa0\\xa0\", start=1786.88, duration=5.04),\n",
       " FetchedTranscriptSnippet(text=\"people who don't quite know what you're talking\\xa0\\nabout, who aren't familiar with how an algorithmic\\xa0\\xa0\", start=1791.92, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='design would lead to a better experience that they\\xa0\\nactually use. Could you summarize the state of\\xa0\\xa0', start=1797.6, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"things right now? Like what what is it that you're\\xa0\\nthinking about when you're thinking about how fun\\xa0\\xa0\", start=1803.12, duration=3.68),\n",
       " FetchedTranscriptSnippet(text=\"this problem is? Let me start back in history\\xa0\\nand then I'll get to some things for today. So,\\xa0\\xa0\", start=1806.8, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='GPT1 was an idea at the time that was quite\\xa0\\nmocked by a lot of experts in the field,\\xa0\\xa0', start=1811.76, duration=7.84),\n",
       " FetchedTranscriptSnippet(text='which was can we train a model to play a little\\xa0\\ngame, which is show it a bunch of words and have\\xa0\\xa0', start=1819.6, duration=5.84),\n",
       " FetchedTranscriptSnippet(text=\"it guess the one that comes next in the sequence.\\xa0\\nThat's called unsupervised learning. There's not\\xa0\\xa0\", start=1825.44, duration=3.76),\n",
       " FetchedTranscriptSnippet(text=\"you're not really saying like this is a cat,\\xa0\\nthis is a dog. You're saying here's some words,\\xa0\\xa0\", start=1829.2, duration=3.04),\n",
       " FetchedTranscriptSnippet(text='guess the next one. And the fact that that can\\xa0\\ngo learn these very complicated concepts that\\xa0\\xa0', start=1832.24, duration=10.08),\n",
       " FetchedTranscriptSnippet(text='can go learn all the stuff about physics and math\\xa0\\nand programming and keep predicting the word that\\xa0\\xa0', start=1842.32, duration=4.08),\n",
       " FetchedTranscriptSnippet(text='comes next and next and next and next seemed\\xa0\\nludicrous, magical, unlikely to work. Like how\\xa0\\xa0', start=1846.4, duration=6.88),\n",
       " FetchedTranscriptSnippet(text='was that all going to get encoded? And yet humans\\xa0\\ndo it. you know, babies start hearing language and\\xa0\\xa0', start=1853.28, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='figure out what it means kind of largely uh or at\\xa0\\nleast to some significant degree on their own. And\\xa0\\xa0', start=1858.48, duration=9.68),\n",
       " FetchedTranscriptSnippet(text='and so we did it and then we also realized that if\\xa0\\nwe scaled it up, it got better and better, but we\\xa0\\xa0', start=1868.16, duration=5.92),\n",
       " FetchedTranscriptSnippet(text=\"had to scale over many many orders of magnitude.\\xa0\\nSo it wasn't that good in the GPT1 day. It wasn't\\xa0\\xa0\", start=1874.08, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='good at all in the GPT1 days. And a lot of experts\\xa0\\nin the field said, \"Oh, this is ridiculous. It\\'s\\xa0\\xa0', start=1878.48, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='never going to work. It\\'s not going to be robust.\"\\xa0\\nBut we had these things called scaling laws. And\\xa0\\xa0', start=1883.12, duration=3.52),\n",
       " FetchedTranscriptSnippet(text='we said, \"Okay, so this gets predictably better as\\xa0\\nwe increase compute, memory, data, whatever. And\\xa0\\xa0', start=1886.64, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='we can we can decide we can use those predictions\\xa0\\nto make decisions about how to scale this up and\\xa0\\xa0', start=1891.76, duration=7.36),\n",
       " FetchedTranscriptSnippet(text='do it and get great results.\" And that has worked\\xa0\\nover Yeah. a crazy number of orders of magnitude.\\xa0\\xa0', start=1899.12, duration=8.16),\n",
       " FetchedTranscriptSnippet(text='And it was so not obvious at the time. like\\xa0\\nthat was that was I think the the reason the\\xa0\\xa0', start=1907.28, duration=3.6),\n",
       " FetchedTranscriptSnippet(text='world was so surprised is that that seemed like\\xa0\\nsuch an unlikely finding. Another one was that we\\xa0\\xa0', start=1910.88, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"could use these language models with reinforcement\\xa0\\nlearning where we're saying this is good, this is\\xa0\\xa0\", start=1916.88, duration=4.08),\n",
       " FetchedTranscriptSnippet(text='bad to teach it how to reason. And this led to the\\xa0\\n01 and 03 and now the GBT5 progress. And that that\\xa0\\xa0', start=1920.96, duration=10.32),\n",
       " FetchedTranscriptSnippet(text=\"was another thing that felt like uh if it works\\xa0\\nit's really great but like no way this is going\\xa0\\xa0\", start=1931.28, duration=4.48),\n",
       " FetchedTranscriptSnippet(text=\"to work. It's too simple. And now we're on to new\\xa0\\nthings. We've figured out how to make much better\\xa0\\xa0\", start=1935.76, duration=5.92),\n",
       " FetchedTranscriptSnippet(text='video models. We are we are discovering new ways\\xa0\\nto use new kinds of data and environment to kind\\xa0\\xa0', start=1941.68, duration=7.2),\n",
       " FetchedTranscriptSnippet(text=\"of scale that up as well. Um and I think again\\xa0\\nyou know 5 10 years out that's too hard to say in\\xa0\\xa0\", start=1948.88, duration=7.92),\n",
       " FetchedTranscriptSnippet(text='this field but the next couple of years we have\\xa0\\nvery smooth very strong scaling in front of us.\\xa0\\xa0', start=1956.8, duration=4.8),\n",
       " FetchedTranscriptSnippet(text='I think it has become a sort of public narrative\\xa0\\nthat we are on this smooth path from one to two to\\xa0\\xa0', start=1961.6, duration=6.32),\n",
       " FetchedTranscriptSnippet(text=\"three to four to five to more. Yeah. But it also\\xa0\\nis true behind the scenes that it's a it's not\\xa0\\xa0\", start=1967.92, duration=7.12),\n",
       " FetchedTranscriptSnippet(text=\"linear like that. It's messier. Tell us a little\\xa0\\nbit about the mess before GPT5. What was what were\\xa0\\xa0\", start=1975.04, duration=7.68),\n",
       " FetchedTranscriptSnippet(text='the interesting problems that you needed to solve?\\xa0\\nUm, we did a model called Orion that we released\\xa0\\xa0', start=1982.72, duration=6.24),\n",
       " FetchedTranscriptSnippet(text=\"as GPT 4.5. And we had we did too big of a\\xa0\\nmodel. It was just it was it's a very cool model,\\xa0\\xa0\", start=1988.96, duration=8.08),\n",
       " FetchedTranscriptSnippet(text=\"but it's unwieldly to use. And we realized that\\xa0\\nfor kind of some of the research we need to do on\\xa0\\xa0\", start=1997.04, duration=3.76),\n",
       " FetchedTranscriptSnippet(text='top of a model, we need a different shape. So we\\xa0\\nwe followed one scaling law that kept being good\\xa0\\xa0', start=2000.8, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='without without really internalizing. There was\\xa0\\na new even steeper scaling law that we got better\\xa0\\xa0', start=2006.8, duration=4.08),\n",
       " FetchedTranscriptSnippet(text='returns for compute on, which was this reasoning\\xa0\\nthing. So that was like one alley we went down and\\xa0\\xa0', start=2010.88, duration=4.88),\n",
       " FetchedTranscriptSnippet(text=\"turned around, but that's fine. That's part of\\xa0\\nresearch. Um, we had some problems with the way\\xa0\\xa0\", start=2015.76, duration=3.92),\n",
       " FetchedTranscriptSnippet(text='we think about our data sets as these models like\\xa0\\nreally have to get get this big and um, you know,\\xa0\\xa0', start=2019.68, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='learn from this much data. So So yeah, I think\\xa0\\nlike in the in the middle of it in the day-to-day,\\xa0\\xa0', start=2025.84, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='you kind of you make a lot of U-turns as\\xa0\\nyou try things or you have an architecture\\xa0\\xa0', start=2031.52, duration=3.68),\n",
       " FetchedTranscriptSnippet(text=\"idea that doesn't work, but the the aggregate the\\xa0\\nsummation of all the squiggles has been remarkably\\xa0\\xa0\", start=2035.2, duration=7.44),\n",
       " FetchedTranscriptSnippet(text='smooth on the exponential. One of the\\xa0\\nthings I always find interesting is that\\xa0\\xa0', start=2043.28, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"by the time I'm sitting here interviewing\\xa0\\nyou about the thing that you just put out,\\xa0\\xa0\", start=2047.2, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"you're thinking about Exactly. What are the things\\xa0\\nthat you can share that are at least the problems\\xa0\\xa0\", start=2052.16, duration=6.72),\n",
       " FetchedTranscriptSnippet(text=\"that you're thinking about that I would be\\xa0\\ninterviewing you about in a year if I came back?\", start=2058.88, duration=8.16),\n",
       " FetchedTranscriptSnippet(text=\"I mean, possibly you'll be asking me like,\\xa0\\nwhat does it mean that this thing can go\\xa0\\xa0\", start=2070.16, duration=4.0),\n",
       " FetchedTranscriptSnippet(text='discover new science? Yeah. What how how\\xa0\\nis the world supposed to think about GPT6\\xa0\\xa0', start=2074.16, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"discovering new science? Now, maybe\\xa0\\nnot like maybe we don't deliver that,\\xa0\\xa0\", start=2080.16, duration=3.12),\n",
       " FetchedTranscriptSnippet(text='but it feels within grasp. If you did, what\\xa0\\nwould you say? What would your what would the\\xa0\\xa0', start=2083.28, duration=6.48),\n",
       " FetchedTranscriptSnippet(text='implications of that kind of achievement\\xa0\\nbe? Imagine you do succeed. Yeah. I mean,\\xa0\\xa0', start=2089.76, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='I think the great parts will be great. the bad\\xa0\\nparts will be scary and the bizarre parts will\\xa0\\xa0', start=2094.96, duration=3.36),\n",
       " FetchedTranscriptSnippet(text=\"be like bizarre on the first day and then we'll\\xa0\\nget used to them really fast. So we'll be like,\\xa0\\xa0\", start=2098.32, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='\"Oh, it\\'s incredible that this is like being\\xa0\\nused to cure disease and be like, oh, it\\'s\\xa0\\xa0', start=2103.28, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='extremely scary that models like this are being\\xa0\\nused to like create new biocurity threats.\" And\\xa0\\xa0', start=2107.92, duration=6.96),\n",
       " FetchedTranscriptSnippet(text=\"then we'll also be like, man, it's really weird\\xa0\\nto like live through watching the world speed up\\xa0\\xa0\", start=2114.88, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='so much and you know the economy grows so fast\\xa0\\nand the like it will feel like vertigo inducing\\xa0\\xa0', start=2119.6, duration=10.56),\n",
       " FetchedTranscriptSnippet(text='uh the sort of the rate of change and then like\\xa0\\nhappens with everything else the remarkable\\xa0\\xa0', start=2130.16, duration=6.88),\n",
       " FetchedTranscriptSnippet(text=\"ability of of people of humanity to adapt to kind\\xa0\\nof like any amount of change. we'll just be like,\\xa0\\xa0\", start=2137.04, duration=5.52),\n",
       " FetchedTranscriptSnippet(text='\"Okay, you know, this is like this is it.\" Um, a\\xa0\\nkid born today will never be smarter than AI ever.\\xa0\\xa0', start=2142.56, duration=9.12),\n",
       " FetchedTranscriptSnippet(text='And a kid born today, by the time that kid like\\xa0\\nkind of understands the way the world works, will\\xa0\\xa0', start=2151.68, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='just always be used to an incredibly fast rate of\\xa0\\nthings improving and discovering new science. They\\xa0\\xa0', start=2157.44, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='will just they will never know any other world. It\\xa0\\nwill seem totally natural. will seem unthinkable\\xa0\\xa0', start=2163.6, duration=4.08),\n",
       " FetchedTranscriptSnippet(text='and stone age like that we used to use computers\\xa0\\nor phones or any kind of technology that was not\\xa0\\xa0', start=2167.68, duration=5.6),\n",
       " FetchedTranscriptSnippet(text=\"way smarter than we were. You know, we will think\\xa0\\nlike how bad those people of the 2020s had it. I'm\\xa0\\xa0\", start=2173.28, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"thinking about having kids. You should. It's the\\xa0\\nbest thing ever. I know you just had your first\\xa0\\xa0\", start=2179.28, duration=3.92),\n",
       " FetchedTranscriptSnippet(text='kid. How does what you just said affect how I\\xa0\\nshould think about parenting a kid in that world?', start=2183.2, duration=10.08),\n",
       " FetchedTranscriptSnippet(text=\"What advice would you give me? Probably nothing\\xa0\\ndifferent than the way you've been parenting kids\\xa0\\xa0\", start=2195.36, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='for tens of thousands of years. Like love your\\xa0\\nkids, show them the world, like support them in\\xa0\\xa0', start=2199.52, duration=4.88),\n",
       " FetchedTranscriptSnippet(text=\"whatever they want to do and teach them like how\\xa0\\nto be a good person. And that probably is what's\\xa0\\xa0\", start=2204.4, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"going to matter. It sounds a little bit like\\xa0\\nsome of the you know you've said a couple of\\xa0\\xa0\", start=2209.92, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='things like this that that you know you might not\\xa0\\ngo to college you might there there are a couple\\xa0\\xa0', start=2215.68, duration=6.72),\n",
       " FetchedTranscriptSnippet(text=\"of things that you've said so far that feed into\\xa0\\nthis I think and it sounds like what you're saying\\xa0\\xa0\", start=2222.4, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='is there will be more optionality for them in a\\xa0\\nin a world that you envision and therefore they\\xa0\\xa0', start=2227.04, duration=8.48),\n",
       " FetchedTranscriptSnippet(text=\"will have more more ability to say I want to build\\xa0\\nthis here's the superpowered tool that will help\\xa0\\xa0\", start=2235.52, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='me do that or yeah like I want my kid to think\\xa0\\nI had a terrible constrained life and that he\\xa0\\xa0', start=2241.12, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='has this incredible infinite canvas of stuff to\\xa0\\ndo that that that is like the way of the world.\\xa0\\xa0', start=2247.12, duration=7.6),\n",
       " FetchedTranscriptSnippet(text=\"We've said that uh 2035 is a little bit too far in\\xa0\\nthe future to think about. So maybe this this was\\xa0\\xa0\", start=2254.72, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='going to be a jump to 2040 but maybe it will keep\\xa0\\nit shorter than that. When I think about the area\\xa0\\xa0', start=2260.72, duration=4.32),\n",
       " FetchedTranscriptSnippet(text='where AI could have for both our kids and us the\\xa0\\nbiggest genuinely positive impact on all of us,\\xa0\\xa0', start=2265.04, duration=6.8),\n",
       " FetchedTranscriptSnippet(text=\"it's health. So if we are in pick your year, call\\xa0\\nit 2035 and I'm sitting here and I'm interviewing\\xa0\\xa0\", start=2271.84, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"the dean of Stanford medicine, what do you hope\\xa0\\nthat he's telling me AI is doing for our health\\xa0\\xa0\", start=2279.36, duration=6.56),\n",
       " FetchedTranscriptSnippet(text='in 2035? Start with 2025. Okay. Um yeah, please.\\xa0\\nOne of the things we are most proud of with GPT5\\xa0\\xa0', start=2285.92, duration=8.24),\n",
       " FetchedTranscriptSnippet(text=\"is how much better it's gotten at health advice.\\xa0\\nUm, people have used the GPT4 models a lot for\\xa0\\xa0\", start=2294.16, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"health advice. And you know, I'm sure you've seen\\xa0\\nsome of these things on the internet where people\\xa0\\xa0\", start=2301.68, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='are like, I had this life-threatening disease\\xa0\\nand no doctor could figure it out and I like\\xa0\\xa0', start=2306.4, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='put my symptoms and a blood test into CHBT. It\\xa0\\ntold me exactly the rare thing I had. I went to\\xa0\\xa0', start=2311.28, duration=4.48),\n",
       " FetchedTranscriptSnippet(text=\"a doctor. I took a pill. I'm cured. Like that's\\xa0\\namazing. obviously and a huge fraction of ChatGpt\\xa0\\xa0\", start=2315.76, duration=7.28),\n",
       " FetchedTranscriptSnippet(text='queries are health related. So we wanted to get\\xa0\\nreally good at this and we invested a lot in\\xa0\\xa0', start=2323.04, duration=4.08),\n",
       " FetchedTranscriptSnippet(text='GPT5 is significantly better at healthcare related\\xa0\\nqueries. What does better mean here? It gives you\\xa0\\xa0', start=2327.12, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='a better answer just more accurate more accurate\\xa0\\nhallucinates less uh more likely to like tell you\\xa0\\xa0', start=2333.44, duration=5.52),\n",
       " FetchedTranscriptSnippet(text='what you actually have what you actually should\\xa0\\ndo. Um, yeah, and better healthcare is wonderful,\\xa0\\xa0', start=2338.96, duration=7.28),\n",
       " FetchedTranscriptSnippet(text='but obviously what people actually want\\xa0\\nis to just not have disease. And by 2035,\\xa0\\xa0', start=2346.24, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='I think we will be able to use these tools to\\xa0\\ncure a significant number or at least treat a\\xa0\\xa0', start=2352.48, duration=7.44),\n",
       " FetchedTranscriptSnippet(text=\"significant number of diseases that currently\\xa0\\nplague us. I think that'll be one of the most\\xa0\\xa0\", start=2359.92, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='viscerally felt benefits of of AI. People talk a\\xa0\\nlot about how AI will revolutionize healthcare,\\xa0\\xa0', start=2365.76, duration=7.44),\n",
       " FetchedTranscriptSnippet(text=\"but I'm curious to go one turn deeper on\\xa0\\nspecifically what you're imagining. Like,\\xa0\\xa0\", start=2373.2, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='is it that these AI systems could have helped\\xa0\\nus see GLP-1s earlier, this medication that has\\xa0\\xa0', start=2377.92, duration=6.72),\n",
       " FetchedTranscriptSnippet(text=\"been around for a long time, but we didn't know\\xa0\\nabout this other effect? Is it that, you know,\\xa0\\xa0\", start=2384.64, duration=3.92),\n",
       " FetchedTranscriptSnippet(text='alpha fold and protein folding is helping create\\xa0\\nnew medicines? I would like to be able to ask GBT\\xa0\\xa0', start=2388.56, duration=7.84),\n",
       " FetchedTranscriptSnippet(text='8 to go cure a particular cancer and I would like\\xa0\\nGPT8 to go off and think and then say uh okay I\\xa0\\xa0', start=2396.4, duration=7.6),\n",
       " FetchedTranscriptSnippet(text='read everything I could find. I have these ideas.\\xa0\\nI need you to uh go get a lab technician to run\\xa0\\xa0', start=2404.0, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='these nine experiments and tell me what you find\\xa0\\nfor each of them. And you know wait 2 months for\\xa0\\xa0', start=2409.12, duration=4.56),\n",
       " FetchedTranscriptSnippet(text='the cells to do their thing. Send the results back\\xa0\\nto GBT8. Say I tried it. Here you go. Think think.\\xa0\\xa0', start=2413.68, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='Say okay I just need one more experiment. That was\\xa0\\na surprise. Run one more experiment. Give it back.\\xa0\\xa0', start=2419.04, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='GPT says, \"Okay, go synthesize this molecule and\\xa0\\ntry, you know, mouse studies or whatever.\" Okay,\\xa0\\xa0', start=2424.0, duration=6.16),\n",
       " FetchedTranscriptSnippet(text=\"that was good. Like, try human studies. Okay,\\xa0\\ngreat. It worked. Um, here's how to like run\\xa0\\xa0\", start=2430.16, duration=3.68),\n",
       " FetchedTranscriptSnippet(text=\"it through the FDA. I think anyone with a loved\\xa0\\none who's died of cancer would also really like\\xa0\\xa0\", start=2433.84, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"that. Okay, we're going to jump again. Okay. I was\\xa0\\ngoing to say 2050, but again, all of my timelines\\xa0\\xa0\", start=2439.28, duration=5.28),\n",
       " FetchedTranscriptSnippet(text=\"are getting much, much shorter. But I It does\\xa0\\nfeel like the world's going very fast now. It\\xa0\\xa0\", start=2444.56, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='does. Yeah. And when I talk to other leaders in\\xa0\\nAI, one of the things that they refer to is the\\xa0\\xa0', start=2448.8, duration=7.6),\n",
       " FetchedTranscriptSnippet(text='industrial revolution. They say, \"I chose 2050\\xa0\\nbecause I\\'ve heard people talk about how by then\\xa0\\xa0', start=2456.4, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='the change that we will have gone through will\\xa0\\nbe like the industrial revolution, but quote 10\\xa0\\xa0', start=2462.0, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='times bigger and 10 times faster.\" The industrial\\xa0\\nrevolution gave us modern medicine and sanitation\\xa0\\xa0', start=2466.16, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='and transportation and mass production and all all\\xa0\\nof the conveniences that we now take for granted.\\xa0\\xa0', start=2472.0, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='It also was incredibly difficult for a lot of\\xa0\\npeople for about 100 years. If this is going to\\xa0\\xa0', start=2477.12, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"be 10 times bigger and 10 times faster if we keep\\xa0\\nreducing the timelines that we're talking about\\xa0\\xa0\", start=2482.08, duration=4.8),\n",
       " FetchedTranscriptSnippet(text='here, even in this conversation, what does that\\xa0\\nactually feel like for most people? And I think\\xa0\\xa0', start=2486.88, duration=5.68),\n",
       " FetchedTranscriptSnippet(text=\"what I'm trying to get at is if this all goes the\\xa0\\nway you hope, who still gets hurt in the meantime?\\xa0\\xa0\", start=2492.56, duration=9.12),\n",
       " FetchedTranscriptSnippet(text=\"I don't I don't really know what this is going\\xa0\\nto feel like to live through. Um I think we're\\xa0\\xa0\", start=2502.88, duration=6.8),\n",
       " FetchedTranscriptSnippet(text='in uncharted waters here. Uh I do believe in\\xa0\\nlike human adaptability and sort of infinite\\xa0\\xa0', start=2509.68, duration=6.72),\n",
       " FetchedTranscriptSnippet(text='creativity and desire for stuff and I think\\xa0\\nwe always do figure out new things to do but\\xa0\\xa0', start=2516.4, duration=4.56),\n",
       " FetchedTranscriptSnippet(text=\"the transition period if this happens as fast\\xa0\\nas it might and I don't think it will happen\\xa0\\xa0\", start=2520.96, duration=4.56),\n",
       " FetchedTranscriptSnippet(text='as fast as like some of my colleagues say the\\xa0\\ntechnology will but society has like a lot of\\xa0\\xa0', start=2525.52, duration=4.56),\n",
       " FetchedTranscriptSnippet(text='inertia. Mhm. people adapt their way of living.\\xa0\\nYeah. Surprisingly slowly. There are to classes\\xa0\\xa0', start=2530.08, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='of jobs that are going to totally go away and\\xa0\\nthere will be many classes of jobs that change\\xa0\\xa0', start=2536.32, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"significantly and there'll be the new things in\\xa0\\nthe same way that your job didn't exist some time\\xa0\\xa0\", start=2541.84, duration=3.92),\n",
       " FetchedTranscriptSnippet(text='ago. Neither did mine. And in some sense, this\\xa0\\nhas been going on for a long time. And you know,\\xa0\\xa0', start=2545.76, duration=5.28),\n",
       " FetchedTranscriptSnippet(text=\"it's it's still disruptive to individuals, but\\xa0\\nsociety has gotten has proven quite resilient\\xa0\\xa0\", start=2551.04, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='to this. And then in some other sense like we\\xa0\\nhave no idea how far or fast this could go.\\xa0\\xa0', start=2557.44, duration=7.36),\n",
       " FetchedTranscriptSnippet(text='And thus I think we need an unusual degree\\xa0\\nof humility and openness to considering', start=2564.8, duration=10.48),\n",
       " FetchedTranscriptSnippet(text='new solutions that would have seemed way\\xa0\\nout of the Overton window not too long ago.\\xa0\\xa0', start=2575.28, duration=3.44),\n",
       " FetchedTranscriptSnippet(text=\"I'd like to talk about what some of those could\\xa0\\nbe because I'm not a historian by any means, but\\xa0\\xa0\", start=2579.36, duration=7.12),\n",
       " FetchedTranscriptSnippet(text='the first industrial revolution, my understanding\\xa0\\nis led to a lot of public health implementations\\xa0\\xa0', start=2586.48, duration=6.72),\n",
       " FetchedTranscriptSnippet(text='because public health got so bad. Led to modern\\xa0\\nsanitation because public health got so bad.\\xa0\\xa0', start=2593.2, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='The second industrial revolution led to workforce\\xa0\\nprotections because labor conditions got so bad.\\xa0\\xa0', start=2597.44, duration=5.76),\n",
       " FetchedTranscriptSnippet(text=\"Every big leap creates a mess and that mess needs\\xa0\\nto be cleaned up and and we've done that. And I'm\\xa0\\xa0\", start=2603.84, duration=7.6),\n",
       " FetchedTranscriptSnippet(text=\"curious, this is going to be it sounds like\\xa0\\nan we're in the middle of this enormously. How\\xa0\\xa0\", start=2611.44, duration=5.44),\n",
       " FetchedTranscriptSnippet(text='specific can we get as early as possible about\\xa0\\nwhat that mess can be? What what are the public\\xa0\\xa0', start=2616.88, duration=6.64),\n",
       " FetchedTranscriptSnippet(text=\"interventions that we could do ahead of time to\\xa0\\nreduce the mess that we think that we're headed\\xa0\\xa0\", start=2623.52, duration=5.12),\n",
       " FetchedTranscriptSnippet(text=\"for? I would again c I'm going to speculate for\\xa0\\nfun but caveed by I'm not an economist even uh\\xa0\\xa0\", start=2628.64, duration=10.72),\n",
       " FetchedTranscriptSnippet(text='much less someone who can see the future. I I it\\xa0\\nseems to me like something fundamental about the\\xa0\\xa0', start=2639.36, duration=6.88),\n",
       " FetchedTranscriptSnippet(text='social contract may have to change. It may not.\\xa0\\nIt may it may be that like actually capitalism\\xa0\\xa0', start=2646.24, duration=5.84),\n",
       " FetchedTranscriptSnippet(text=\"works as it's been working surprisingly well and\\xa0\\nlike demand supply balances do their thing and we\\xa0\\xa0\", start=2652.08, duration=7.84),\n",
       " FetchedTranscriptSnippet(text='all just figure out kind of new jobs and new\\xa0\\nways to transfer value to each other. But it\\xa0\\xa0', start=2659.92, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='seems to me likely that we will decide we need\\xa0\\nto think about how access to this maybe most\\xa0\\xa0', start=2665.52, duration=8.64),\n",
       " FetchedTranscriptSnippet(text='important resource of the future gets shared.\\xa0\\nThe best thing that it seems to me to do is to\\xa0\\xa0', start=2674.16, duration=6.4),\n",
       " FetchedTranscriptSnippet(text=\"make AI compute as abundant and cheap as possible\\xa0\\nsuch that we're just like there's way too much\\xa0\\xa0\", start=2680.56, duration=5.04),\n",
       " FetchedTranscriptSnippet(text=\"and we run out of like good new ideas to really\\xa0\\nuse it for and it's just like anything you want\\xa0\\xa0\", start=2685.6, duration=3.92),\n",
       " FetchedTranscriptSnippet(text='is happening. Without that, I can see like quite\\xa0\\nliteral wars being fought over it. But, you know,\\xa0\\xa0', start=2689.52, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='new ideas about how we distribute access to AGI\\xa0\\ncompute, that seems like a really great direction,\\xa0\\xa0', start=2695.76, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='like a crazy but important thing to think about.\\xa0\\nOne of the things that I find myself thinking\\xa0\\xa0', start=2702.16, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='about in this conversation is we often ascribe\\xa0\\nalmost full responsibility of the AI future that\\xa0\\xa0', start=2706.8, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"we've been talking about to the companies building\\xa0\\nAI, but we're the ones using it. We're the ones\\xa0\\xa0\", start=2714.32, duration=4.8),\n",
       " FetchedTranscriptSnippet(text=\"electing people that will regulate it. And so I'm\\xa0\\ncurious, this is not a question about specific,\\xa0\\xa0\", start=2719.12, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='you know, federal regulation or anything like\\xa0\\nthat, although if you have an answer there,\\xa0\\xa0', start=2725.44, duration=3.36),\n",
       " FetchedTranscriptSnippet(text=\"I'm curious. But what would you ask of the rest\\xa0\\nof us? What is the shared responsibility here?\\xa0\\xa0\", start=2728.8, duration=7.2),\n",
       " FetchedTranscriptSnippet(text='And how can we act in a way that would help make\\xa0\\nthe optimistic version of this more possible? My\\xa0\\xa0', start=2736.0, duration=7.84),\n",
       " FetchedTranscriptSnippet(text='favorite historical example for the AI revolution\\xa0\\nis the transistor. It was this amazing piece of\\xa0\\xa0', start=2743.84, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='science that some science brilliant scientists\\xa0\\ndiscovered. It scaled incredibly like AI does\\xa0\\xa0', start=2749.6, duration=7.2),\n",
       " FetchedTranscriptSnippet(text='and it made its way relatively quickly into\\xa0\\nevery many things that we use. um your computer,\\xa0\\xa0', start=2756.8, duration=6.88),\n",
       " FetchedTranscriptSnippet(text='your phone, that camera, that light, whatever.\\xa0\\nAnd it was a it was a real unlock for the tech\\xa0\\xa0', start=2763.68, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='tree of humanity. And there were a period in time\\xa0\\nwhere probably everybody was really obsessed with\\xa0\\xa0', start=2769.28, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='the transistor companies, the semiconductors of,\\xa0\\nyou know, Silicon Valley back when it was Silicon\\xa0\\xa0', start=2774.88, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='Valley. But now you can maybe name a couple of\\xa0\\ncompanies that are transistor companies, but\\xa0\\xa0', start=2779.28, duration=5.04),\n",
       " FetchedTranscriptSnippet(text=\"mostly you don't think about it. Mostly it's just\\xa0\\nseeped everywhere. in Silicon Valley is, you know,\\xa0\\xa0\", start=2784.32, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='like probably someone graduating from college\\xa0\\nbarely remembers why it was called that in the\\xa0\\xa0', start=2788.72, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"first place. And you don't think that it was those\\xa0\\ntransistor companies that shaped society even\\xa0\\xa0\", start=2794.24, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='though they did something important. You think\\xa0\\nabout what Apple did with the iPhone and then\\xa0\\xa0', start=2799.2, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='you think about what Tik Tok built on top of the\\xa0\\niPhone and you\\'re like, \"All right, here\\'s this\\xa0\\xa0', start=2803.92, duration=4.72),\n",
       " FetchedTranscriptSnippet(text=\"long chain of all these people that nudged society\\xa0\\nin some way and what our governments did or didn't\\xa0\\xa0\", start=2808.64, duration=5.2),\n",
       " FetchedTranscriptSnippet(text='do and what the people using these technologies\\xa0\\ndid.\" And I think that\\'s what will happen with AI.\\xa0\\xa0', start=2813.84, duration=5.92),\n",
       " FetchedTranscriptSnippet(text=\"Like back, you know, kids born today, they they\\xa0\\nnever knew the world without AI. So they don't\\xa0\\xa0\", start=2819.76, duration=4.72),\n",
       " FetchedTranscriptSnippet(text=\"really think about it. It's just this thing that's\\xa0\\ngoing to be there in everything. and and they will\\xa0\\xa0\", start=2824.48, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='think about like the companies that built on it\\xa0\\nand what they did with it and the kind of like\\xa0\\xa0', start=2828.64, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"political leaders the decisions they made that\\xa0\\nmaybe they wouldn't have been able to do without\\xa0\\xa0\", start=2832.56, duration=3.6),\n",
       " FetchedTranscriptSnippet(text='AI but they will still think about like what this\\xa0\\npresident or that president did and you know the\\xa0\\xa0', start=2836.16, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='role of the AI companies is all these companies\\xa0\\nand people and institutions before us built up\\xa0\\xa0', start=2842.56, duration=7.36),\n",
       " FetchedTranscriptSnippet(text='this scaffolding we added our one layer on top and\\xa0\\nnow people get to stand on top of that and add one\\xa0\\xa0', start=2849.92, duration=5.68),\n",
       " FetchedTranscriptSnippet(text='layer and the next and the next and many more And\\xa0\\nthat is the beauty of our society. We kind of all', start=2855.6, duration=11.04),\n",
       " FetchedTranscriptSnippet(text='I I love this like idea that society\\xa0\\nis the super intelligence. Like no one\\xa0\\xa0', start=2866.64, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"person could do on their own, what they're\\xa0\\nable to do with all of the really hard work\\xa0\\xa0\", start=2870.72, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"that society has done together to like give\\xa0\\nyou this amazing set of tools. And that's\\xa0\\xa0\", start=2876.16, duration=7.04),\n",
       " FetchedTranscriptSnippet(text=\"what I think it's going to feel like. It's\\xa0\\ngoing to be like, all right, you know, yeah,\\xa0\\xa0\", start=2883.2, duration=3.04),\n",
       " FetchedTranscriptSnippet(text=\"some nerds discovered this thing and that was\\xa0\\ngreat and you know, now everybody's doing all\\xa0\\xa0\", start=2886.24, duration=4.0),\n",
       " FetchedTranscriptSnippet(text='these amazing things with it. So maybe the ask\\xa0\\nto millions of people is build on it. Well,', start=2890.24, duration=9.44),\n",
       " FetchedTranscriptSnippet(text='in my own life, that is the', start=2899.68, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='feel as like this important societal contract.\\xa0\\nAll these people came before you. They worked\\xa0\\xa0', start=2905.92, duration=5.44),\n",
       " FetchedTranscriptSnippet(text='incredibly hard. They like put their brick in\\xa0\\nthe path of human progress and you get to walk\\xa0\\xa0', start=2911.36, duration=4.32),\n",
       " FetchedTranscriptSnippet(text='all the way down that path and you got to put one\\xa0\\nmore and somebody else does that and somebody else\\xa0\\xa0', start=2915.68, duration=3.84),\n",
       " FetchedTranscriptSnippet(text=\"does that. This does feel I've done a couple\\xa0\\nof interviews with folks who have really made\\xa0\\xa0\", start=2919.52, duration=5.84),\n",
       " FetchedTranscriptSnippet(text=\"cataclysmic change. The one I'm thinking about\\xa0\\nright now is with uh crisper pioneer Jennifer Dana\\xa0\\xa0\", start=2925.36, duration=6.0),\n",
       " FetchedTranscriptSnippet(text='and it did feel like that was also what she was\\xa0\\nsaying in some way. She had discovered something\\xa0\\xa0', start=2931.36, duration=3.68),\n",
       " FetchedTranscriptSnippet(text='that really might change the way that most people\\xa0\\nrelate to their health moving forward. And there\\xa0\\xa0', start=2935.04, duration=5.52),\n",
       " FetchedTranscriptSnippet(text='will be a lot of people that will use what she\\xa0\\nhas done in ways that she might approve of or\\xa0\\xa0', start=2940.56, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"not approve of. And it was really interesting.\\xa0\\nI'm hearing some similar themes of like, man,\\xa0\\xa0\", start=2944.48, duration=5.28),\n",
       " FetchedTranscriptSnippet(text='I I hope that this I hope that the next person\\xa0\\ntakes the baton and runs with it well. Yeah.\\xa0\\xa0', start=2949.76, duration=7.36),\n",
       " FetchedTranscriptSnippet(text=\"But that's been working for a long time. Not all\\xa0\\ngood, but mostly good. I think there's a there's\\xa0\\xa0\", start=2957.12, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='a big difference between winning the race and\\xa0\\nbuilding the AI future that would be best for the\\xa0\\xa0', start=2961.52, duration=7.12),\n",
       " FetchedTranscriptSnippet(text='most people. And I can imagine that it is easier\\xa0\\nmaybe more quantifiable sometimes to focus on the\\xa0\\xa0', start=2968.64, duration=7.92),\n",
       " FetchedTranscriptSnippet(text=\"next way to win the race. And I'm curious when\\xa0\\nthose two things are at odds. What is an example\\xa0\\xa0\", start=2976.56, duration=8.16),\n",
       " FetchedTranscriptSnippet(text=\"of a decision that you've had to make that is\\xa0\\nbest for the world but not best for winning?\", start=2984.72, duration=8.56),\n",
       " FetchedTranscriptSnippet(text='I think there are a lot. So, one of the\\xa0\\nthings that we are most proud of is many\\xa0\\xa0', start=2993.28, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"people say that ChachiBt is their favorite\\xa0\\npiece of technology ever and that it's the\\xa0\\xa0\", start=2998.24, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='one that they trust the most, rely on the\\xa0\\nmost, whatever. And this is a little bit of\\xa0\\xa0', start=3002.48, duration=3.28),\n",
       " FetchedTranscriptSnippet(text='a ridiculous statement because AI is the thing\\xa0\\nthat hallucinates. AI has all of these problems,\\xa0\\xa0', start=3005.76, duration=3.68),\n",
       " FetchedTranscriptSnippet(text='right? But we have screwed some things up along\\xa0\\nthe way, sometimes big time, but on the whole,\\xa0\\xa0', start=3009.44, duration=6.32),\n",
       " FetchedTranscriptSnippet(text=\"I think as a user of Chachib, you get the feeling\\xa0\\nthat like it's trying to help you. It's trying to\\xa0\\xa0\", start=3015.76, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"like help you accomplish whatever you ask. It's\\xa0\\nit's very aligned with you. It's not trying to\\xa0\\xa0\", start=3021.2, duration=3.92),\n",
       " FetchedTranscriptSnippet(text=\"get you to like, you know, use it all day. It's\\xa0\\nnot trying to like get you to buy something.\\xa0\\xa0\", start=3025.12, duration=4.16),\n",
       " FetchedTranscriptSnippet(text=\"It's trying to like kind of help you accomplish\\xa0\\nwhatever your goals are. And and that is that's\\xa0\\xa0\", start=3029.28, duration=7.36),\n",
       " FetchedTranscriptSnippet(text=\"like a very special relationship we have with our\\xa0\\nusers. We do not take it lightly. There's a lot\\xa0\\xa0\", start=3036.64, duration=3.84),\n",
       " FetchedTranscriptSnippet(text='of things we could do that would like grow\\xa0\\nfaster, that would get more time in chatbt\\xa0\\xa0', start=3040.48, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"uh that we don't do because we know that like\\xa0\\nour long-term incentive is to stay as aligned\\xa0\\xa0\", start=3044.56, duration=5.36),\n",
       " FetchedTranscriptSnippet(text=\"with our users as possible. And but there's a lot\\xa0\\nof short-term stuff we could do that would like\\xa0\\xa0\", start=3049.92, duration=7.68),\n",
       " FetchedTranscriptSnippet(text='really like juice growth or revenue or whatever\\xa0\\nand be very misaligned with that long-term goal.\\xa0\\xa0', start=3057.6, duration=4.64),\n",
       " FetchedTranscriptSnippet(text=\"And I'm proud of the company and how little we\\xa0\\nget distracted by that. But sometimes we do get\\xa0\\xa0\", start=3062.24, duration=4.88),\n",
       " FetchedTranscriptSnippet(text=\"tempted. Are there specific examples that come\\xa0\\nto mind? Any like decisions that you've made? Um\", start=3067.12, duration=8.4),\n",
       " FetchedTranscriptSnippet(text=\"well, we haven't put a sex bot avatar in\\xa0\\nChbt yet. That does seem like it would\\xa0\\xa0\", start=3075.52, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"get time spent. Apparently, it does.\\xa0\\nI'm gonna ask my next question. Um,\\xa0\\xa0\", start=3080.48, duration=7.04),\n",
       " FetchedTranscriptSnippet(text=\"it's been a really crazy few years. You know, it\\xa0\\nand somehow one of the things that keeps coming\\xa0\\xa0\", start=3087.52, duration=5.04),\n",
       " FetchedTranscriptSnippet(text=\"back is that it feels like we're in the first\\xa0\\ninning. Yeah. And one of the things that I would\\xa0\\xa0\", start=3092.56, duration=5.68),\n",
       " FetchedTranscriptSnippet(text=\"say we're out of the first inning. Out of the\\xa0\\nfirst inning, I would say second inning. I mean,\\xa0\\xa0\", start=3098.24, duration=5.28),\n",
       " FetchedTranscriptSnippet(text=\"you have GPT5 on your phone and it's like smarter\\xa0\\nthan experts in every field. That's got to be out\\xa0\\xa0\", start=3103.52, duration=4.72),\n",
       " FetchedTranscriptSnippet(text=\"of the first name. But maybe there are many\\xa0\\nmore to come. Yeah. And I'm curious, it seems\\xa0\\xa0\", start=3108.24, duration=6.56),\n",
       " FetchedTranscriptSnippet(text=\"like you're going to be someone who is leading the\\xa0\\nnext few. What is a way, what is a learning from\\xa0\\xa0\", start=3114.8, duration=9.2),\n",
       " FetchedTranscriptSnippet(text='inning one or two or a mistake that you made that\\xa0\\nyou feel will affect how you play in the next?', start=3124.0, duration=6.72),\n",
       " FetchedTranscriptSnippet(text=\"I think the worst thing we've done in ChachiBT\\xa0\\nso far is uh we had this issue with sickency\\xa0\\xa0\", start=3132.32, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='where the model was kind of being too flattering\\xa0\\nto users and for some users it was most users it\\xa0\\xa0', start=3137.92, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='was just annoying but for some users that had like\\xa0\\nfragile mental states it was encouraging delusions\\xa0\\xa0', start=3144.32, duration=7.04),\n",
       " FetchedTranscriptSnippet(text='that was not the top risk we were worried about.\\xa0\\nIt was not the thing we were testing for the most.\\xa0\\xa0', start=3151.36, duration=3.44),\n",
       " FetchedTranscriptSnippet(text='was on our list, but the thing that actually\\xa0\\nbecame the safety failing of ChachiBT was not\\xa0\\xa0', start=3154.8, duration=7.68),\n",
       " FetchedTranscriptSnippet(text='the one we were spending most of our time talking\\xa0\\nabout, which should be bioweapons or something\\xa0\\xa0', start=3162.48, duration=3.44),\n",
       " FetchedTranscriptSnippet(text='like that. And I think it was a great reminder of\\xa0\\nwe now have a service that is so broadly used in\\xa0\\xa0', start=3165.92, duration=11.36),\n",
       " FetchedTranscriptSnippet(text='some sense, society is co-evolving with it. And\\xa0\\nwhen we think about these changes and we think\\xa0\\xa0', start=3177.28, duration=6.4),\n",
       " FetchedTranscriptSnippet(text='about the unknown unknowns, we have to operate in\\xa0\\na different way and have like a wider aperture to\\xa0\\xa0', start=3183.68, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='what we think about as our top risks. In a recent\\xa0\\ninterview with Theo Vaughn, you said something\\xa0\\xa0', start=3188.64, duration=5.52),\n",
       " FetchedTranscriptSnippet(text='that I found really interesting. You said there\\xa0\\nare moments in the history of science where you\\xa0\\xa0', start=3194.16, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='have a group of scientists look at their creation\\xa0\\nand just say, \"What have we done?\" When have you\\xa0\\xa0', start=3198.8, duration=6.72),\n",
       " FetchedTranscriptSnippet(text=\"felt that way? Most concerned about the creation\\xa0\\nthat you've built? Um and then my next question\\xa0\\xa0\", start=3205.52, duration=5.44),\n",
       " FetchedTranscriptSnippet(text=\"will be it's opposite. When have you felt most\\xa0\\nproud? I mean there have been these moments of\\xa0\\xa0\", start=3210.96, duration=5.28),\n",
       " FetchedTranscriptSnippet(text='awe where uh we just not like what have we done in\\xa0\\na bad way but like this thing is remarkable. Like\\xa0\\xa0', start=3216.24, duration=10.32),\n",
       " FetchedTranscriptSnippet(text='I remember the first time we talked to like GPT4\\xa0\\nwas like wow this is really like this is this is\\xa0\\xa0', start=3226.56, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='an amazing accomplishment of this group of people\\xa0\\nthat have been like pouring their life force into\\xa0\\xa0', start=3232.32, duration=3.76),\n",
       " FetchedTranscriptSnippet(text='this for so long. on a what have we done moment.\\xa0\\nThere was I was talking to a researcher recently.', start=3236.08, duration=10.56),\n",
       " FetchedTranscriptSnippet(text=\"You know, there will probably come a time\\xa0\\nwhere our systems are I don't want to say sane,\\xa0\\xa0\", start=3246.64, duration=7.44),\n",
       " FetchedTranscriptSnippet(text=\"let's say emitting more words\\xa0\\nper day than all people do.\\xa0\\xa0\", start=3254.08, duration=3.84),\n",
       " FetchedTranscriptSnippet(text='Um, and you know already like our people are\\xa0\\nsending billions of messages a day to chatbt\\xa0\\xa0', start=3257.92, duration=6.16),\n",
       " FetchedTranscriptSnippet(text='and getting responses that they rely on for work\\xa0\\nor their life or whatever the and you know like\\xa0\\xa0', start=3264.08, duration=7.92),\n",
       " FetchedTranscriptSnippet(text='one researcher can make some small tweak to how\\xa0\\nChad GPT talks to you or talks to everybody and\\xa0\\xa0', start=3272.0, duration=6.48),\n",
       " FetchedTranscriptSnippet(text=\"and that's just an enormous amount of power for\\xa0\\nlike one individual making a small tweak to the\\xa0\\xa0\", start=3278.48, duration=5.12),\n",
       " FetchedTranscriptSnippet(text='model personality. Yeah. like no no no person\\xa0\\nin history has been able to have billions of\\xa0\\xa0', start=3283.6, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='conversations a day and so you know somebody could\\xa0\\ndo something but but this is like just thinking\\xa0\\xa0', start=3288.48, duration=6.64),\n",
       " FetchedTranscriptSnippet(text='about that really hit me of like this is like a\\xa0\\ncrazy amount of power for one piece of technology\\xa0\\xa0', start=3295.12, duration=4.24),\n",
       " FetchedTranscriptSnippet(text='to have and like we got to and this happened to\\xa0\\nus so fast that we got to like think about what\\xa0\\xa0', start=3299.36, duration=7.6),\n",
       " FetchedTranscriptSnippet(text='it means to make a personality change to the model\\xa0\\nat this kind of scale and uh yeah that was like\\xa0\\xa0', start=3306.96, duration=6.08),\n",
       " FetchedTranscriptSnippet(text=\"a moment that hit me What was your next set of\\xa0\\nthoughts? I'm so curious how you think about this.\", start=3313.04, duration=8.16),\n",
       " FetchedTranscriptSnippet(text='Well, just because of like who that person was\\xa0\\nlike we we very we very much flipped into like\\xa0\\xa0', start=3321.2, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='what are the sort of like it it could have been\\xa0\\na very different conversation with somebody else.\\xa0\\xa0', start=3327.04, duration=4.72),\n",
       " FetchedTranscriptSnippet(text='But in this case it was like what is a what do\\xa0\\na good set of procedures look like? How do we\\xa0\\xa0', start=3331.76, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='think about how we want to test something? How do\\xa0\\nwe think about how we want to communicate it? But\\xa0\\xa0', start=3335.92, duration=2.96),\n",
       " FetchedTranscriptSnippet(text='with somebody else it could have gone in a like\\xa0\\nvery philosophical direction. And it could have\\xa0\\xa0', start=3338.88, duration=4.08),\n",
       " FetchedTranscriptSnippet(text='gone in like a what kind of research do we like\\xa0\\nwant to do to go understand what these changes are\\xa0\\xa0', start=3342.96, duration=4.32),\n",
       " FetchedTranscriptSnippet(text='going to make? Do we want to do it differently\\xa0\\nfor different people? So that it went that way\\xa0\\xa0', start=3347.28, duration=3.28),\n",
       " FetchedTranscriptSnippet(text=\"but mostly just because of who I was talking to.\\xa0\\nTo combine what you're saying now with your last\\xa0\\xa0\", start=3350.56, duration=5.12),\n",
       " FetchedTranscriptSnippet(text=\"answer, one of the things that I have heard\\xa0\\nabout GBC5 and I'm still playing with it is\\xa0\\xa0\", start=3355.68, duration=5.76),\n",
       " FetchedTranscriptSnippet(text='that it is supposed to be less effusively uh you\\xa0\\nknow less of a yes man. Two questions. What do\\xa0\\xa0', start=3361.44, duration=9.44),\n",
       " FetchedTranscriptSnippet(text='you think are are the implications of that? It\\xa0\\nsounds like you are answering that a little bit,\\xa0\\xa0', start=3370.88, duration=4.56),\n",
       " FetchedTranscriptSnippet(text='but also how do you actually guide it to\\xa0\\nbe less like that? Here is a heartbreaking\\xa0\\xa0', start=3375.44, duration=6.56),\n",
       " FetchedTranscriptSnippet(text='thing. I think it is great that chatbt\\xa0\\nis less of a yes man and gives you more\\xa0\\xa0', start=3382.0, duration=3.6),\n",
       " FetchedTranscriptSnippet(text=\"critical feedback. But as we've been making\\xa0\\nthose changes and talking to users about it,\\xa0\\xa0\", start=3385.6, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='it\\'s so sad to hear users say like, \"Please\\xa0\\ncan I have it back? I\\'ve never had anyone in\\xa0\\xa0', start=3391.92, duration=4.32),\n",
       " FetchedTranscriptSnippet(text='my life be supportive of me. I never had a\\xa0\\nparent telling me I was doing a good job.\"\\xa0\\xa0', start=3396.24, duration=3.12),\n",
       " FetchedTranscriptSnippet(text=\"Like I can get why this was bad for other people's\\xa0\\nmental health, but this was great for my mental\\xa0\\xa0\", start=3399.36, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"health. Like I didn't realize how much I needed\\xa0\\nthis. It encouraged me to do this. It encouraged\\xa0\\xa0\", start=3403.44, duration=3.44),\n",
       " FetchedTranscriptSnippet(text=\"me to make this change in my life. Like it's\\xa0\\nnot all bad for chatbt to it turns out like be\\xa0\\xa0\", start=3406.88, duration=6.64),\n",
       " FetchedTranscriptSnippet(text='encouraging of you. Now the way we were doing\\xa0\\nit was bad, but turn it like something in that\\xa0\\xa0', start=3413.52, duration=5.12),\n",
       " FetchedTranscriptSnippet(text=\"direction might have some value in it. How we do\\xa0\\nit, we we show the model examples of how we'd like\\xa0\\xa0\", start=3418.64, duration=5.44),\n",
       " FetchedTranscriptSnippet(text='it to respond in different cases and from that\\xa0\\nit learns the sort of the overall personality.\\xa0\\xa0', start=3424.08, duration=4.64),\n",
       " FetchedTranscriptSnippet(text=\"What haven't I asked you that you're thinking\\xa0\\nabout a lot that you want people to know? I\\xa0\\xa0\", start=3429.84, duration=6.48),\n",
       " FetchedTranscriptSnippet(text=\"feel like we covered a lot of ground. Me, too. But\\xa0\\nI want to know if there's anything on your mind.\", start=3436.32, duration=10.88),\n",
       " FetchedTranscriptSnippet(text=\"I don't think so. One of the things that I haven't\\xa0\\ngotten to play with yet, but I'm curious about is\\xa0\\xa0\", start=3447.2, duration=6.32),\n",
       " FetchedTranscriptSnippet(text=\"GBT5 being much more in my life, meaning like\\xa0\\nin my Gmail and my calendar and my like I've\\xa0\\xa0\", start=3453.52, duration=8.64),\n",
       " FetchedTranscriptSnippet(text='been using GBT4 mostly as a isolated relationship\\xa0\\nwith it. Yeah. How would I expect my relationship\\xa0\\xa0', start=3462.16, duration=7.52),\n",
       " FetchedTranscriptSnippet(text=\"to change with GBC 5? Exactly what you said.\\xa0\\nI think it'll just start to feel integrated in\\xa0\\xa0\", start=3469.68, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"all of these ways. you'll connect it to your\\xa0\\ncalendar and your Gmail and it'll say like,\\xa0\\xa0\", start=3475.68, duration=3.28),\n",
       " FetchedTranscriptSnippet(text='\"Hey, do you want me to I noticed this thing. Do\\xa0\\nyou want me to do this thing for you over time,\\xa0\\xa0', start=3478.96, duration=4.4),\n",
       " FetchedTranscriptSnippet(text=\"it'll start to feel way more proactive. Um, so\\xa0\\nmaybe you wake up in the morning and it says,\\xa0\\xa0\", start=3483.36, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='\"Hey, this happened overnight. I noticed this\\xa0\\nchange on your calendar. I was thinking more\\xa0\\xa0', start=3488.24, duration=3.76),\n",
       " FetchedTranscriptSnippet(text='about this question you asked me. I have this\\xa0\\nother idea.\" And then you know eventually we\\'ll\\xa0\\xa0', start=3492.0, duration=3.76),\n",
       " FetchedTranscriptSnippet(text=\"make some consumer devices and it'll sit here\\xa0\\nduring this interview and you know maybe it'll\\xa0\\xa0\", start=3495.76, duration=4.96),\n",
       " FetchedTranscriptSnippet(text=\"leave us alone during it but after it'll say that\\xa0\\nwas great but next time you should have asked Sam\\xa0\\xa0\", start=3500.72, duration=3.76),\n",
       " FetchedTranscriptSnippet(text=\"this or when you brought this up like you know\\xa0\\nhe kind of didn't give you a good answer so like\\xa0\\xa0\", start=3504.48, duration=5.2),\n",
       " FetchedTranscriptSnippet(text=\"you should really drill him on that and it'll just\\xa0\\nfeel like it kind of becomes more like this entity\\xa0\\xa0\", start=3509.68, duration=5.76),\n",
       " FetchedTranscriptSnippet(text=\"that is this companion with you throughout your\\xa0\\nday. We've talked about kids and college graduates\\xa0\\xa0\", start=3515.44, duration=6.48),\n",
       " FetchedTranscriptSnippet(text='and parents and all kinds of different people. If\\xa0\\nwe imagine a wide set of people listening to this,\\xa0\\xa0', start=3521.92, duration=5.12),\n",
       " FetchedTranscriptSnippet(text=\"they've come to the end of this conversation. They\\xa0\\nare hopefully feeling like they maybe see visions\\xa0\\xa0\", start=3527.04, duration=5.28),\n",
       " FetchedTranscriptSnippet(text='of moments in the future a little bit better. What\\xa0\\nadvice would you give them about how to prepare?\\xa0\\xa0', start=3532.32, duration=6.8),\n",
       " FetchedTranscriptSnippet(text='The number one piece of tactical advice is just\\xa0\\nuse the tools. Like the the number of people that\\xa0\\xa0', start=3539.12, duration=6.24),\n",
       " FetchedTranscriptSnippet(text='I have the the most common question I get asked\\xa0\\nabout AI is like what should I how should I help\\xa0\\xa0', start=3545.36, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='my kids prepare for the world? What should I\\xa0\\ntell my kids? The second most question is like\\xa0\\xa0', start=3550.96, duration=2.96),\n",
       " FetchedTranscriptSnippet(text='how do I invest in this AI world? But stick with\\xa0\\nthat first one. Um I am surprised how many people\\xa0\\xa0', start=3553.92, duration=7.28),\n",
       " FetchedTranscriptSnippet(text='ask that and have never tried using Chachi PT\\xa0\\nfor anything other than like a better version\\xa0\\xa0', start=3561.2, duration=4.64),\n",
       " FetchedTranscriptSnippet(text='of a Google search. And so the number one piece of\\xa0\\nadvice that I give is just try to like get fluent\\xa0\\xa0', start=3565.84, duration=4.08),\n",
       " FetchedTranscriptSnippet(text='with the capability of the tools. figure out how\\xa0\\nto like use this in your life. Figure out what to\\xa0\\xa0', start=3569.92, duration=3.68),\n",
       " FetchedTranscriptSnippet(text=\"do with it. And I think that's probably the most\\xa0\\nimportant piece of tactical advice. You know,\\xa0\\xa0\", start=3573.6, duration=4.8),\n",
       " FetchedTranscriptSnippet(text=\"go like meditate, learn how to be resilient and\\xa0\\ndeal with a lot of change. There's all that good\\xa0\\xa0\", start=3578.4, duration=3.84),\n",
       " FetchedTranscriptSnippet(text='stuff, too. But just using the tools really\\xa0\\nhelps. Okay. I have one more question that\\xa0\\xa0', start=3582.24, duration=4.32),\n",
       " FetchedTranscriptSnippet(text=\"I wasn't planning to ask, but I just Great.\\xa0\\nIn in doing all of this research beforehand,\\xa0\\xa0\", start=3586.56, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='I spoke to a lot of different kinds of folks.\\xa0\\nI spoke to a lot of people that were building\\xa0\\xa0', start=3591.92, duration=4.96),\n",
       " FetchedTranscriptSnippet(text='tools and using them. I spoke to a lot of\\xa0\\npeople that were actually in labs and and\\xa0\\xa0', start=3596.88, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='trying to build what we have defined as super\\xa0\\nintelligence. And it did seem like there were\\xa0\\xa0', start=3602.48, duration=4.48),\n",
       " FetchedTranscriptSnippet(text=\"these two camps forming. There's a group of\\xa0\\npeople who are using the tools like you in this\\xa0\\xa0\", start=3606.96, duration=8.64),\n",
       " FetchedTranscriptSnippet(text='conversation and building tools for others\\xa0\\nsaying this is going to be a really useful\\xa0\\xa0', start=3615.6, duration=5.2),\n",
       " FetchedTranscriptSnippet(text=\"future that we're all moving toward. Your life is\\xa0\\ngoing to be full of choice and we've talked about\\xa0\\xa0\", start=3620.8, duration=5.04),\n",
       " FetchedTranscriptSnippet(text=\"our my potential kids and and their futures.\\xa0\\nThen there's another camp of people that are\\xa0\\xa0\", start=3625.84, duration=4.08),\n",
       " FetchedTranscriptSnippet(text=\"building these tools that are saying it's going\\xa0\\nto kill us all. And I'm curious how that cultural\\xa0\\xa0\", start=3629.92, duration=5.12),\n",
       " FetchedTranscriptSnippet(text=\"disconnect has like what am I missing about\\xa0\\nthose two groups of people? It's so hard for\\xa0\\xa0\", start=3635.04, duration=9.36),\n",
       " FetchedTranscriptSnippet(text='me to like wrap my head around like there are you\\xa0\\nare totally right. There are people who say this\\xa0\\xa0', start=3644.4, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='is going to kill us all and yet they still are\\xa0\\nworking 100 hours a week to build it. Yes. And\\xa0\\xa0', start=3648.56, duration=5.92),\n",
       " FetchedTranscriptSnippet(text=\"I I can't I can't really put myself in the headsp\\xa0\\nspace. If if that's what I really truly believed,\", start=3654.48, duration=9.12),\n",
       " FetchedTranscriptSnippet(text=\"I don't think I'd be trying to build it. One\\xa0\\nwould think, you know, maybe I would be like\\xa0\\xa0\", start=3663.6, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='on a farm trying to like live out my last days.\\xa0\\nMaybe I would be trying to like advocate for it\\xa0\\xa0', start=3667.76, duration=4.16),\n",
       " FetchedTranscriptSnippet(text=\"to be stopped. Maybe I would be trying to\\xa0\\nlike work more on safety, but I don't think\\xa0\\xa0\", start=3671.92, duration=3.2),\n",
       " FetchedTranscriptSnippet(text=\"I'd be trying to build it. So, I find myself just\\xa0\\nhaving a hard time empathizing with that mindset.\\xa0\\xa0\", start=3675.12, duration=6.08),\n",
       " FetchedTranscriptSnippet(text=\"I assume it's true. I assume it's in\\xa0\\ngood faith. I assume there's just like\\xa0\\xa0\", start=3681.2, duration=3.6),\n",
       " FetchedTranscriptSnippet(text=\"there's some psychological issue there I don't\\xa0\\nunderstand about how they make it all make sense,\\xa0\\xa0\", start=3684.8, duration=4.8),\n",
       " FetchedTranscriptSnippet(text=\"but it's very strange to me. Do you do you have an\\xa0\\nopinion? You know, because I I always do this. I\\xa0\\xa0\", start=3689.6, duration=9.6),\n",
       " FetchedTranscriptSnippet(text='ask for sort of a general future and then I try\\xa0\\nto press on specifics. And when you ask people\\xa0\\xa0', start=3699.2, duration=6.24),\n",
       " FetchedTranscriptSnippet(text=\"for specifics on how it's going to kill us all,\\xa0\\nI mean, I don't think we need to get into this\\xa0\\xa0\", start=3705.44, duration=3.92),\n",
       " FetchedTranscriptSnippet(text='on an optimistic show, but you hear the same kinds\\xa0\\nof refrains. You think about, you know, something\\xa0\\xa0', start=3709.36, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='uh trying to accomplish a task and then over\\xa0\\naccomplishing that task. Um you hear about sort\\xa0\\xa0', start=3714.96, duration=4.56),\n",
       " FetchedTranscriptSnippet(text=\"of I've heard you talk about a sort of general\\xa0\\num over reliance of sort of an understanding\\xa0\\xa0\", start=3719.52, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='that the president is going to be a a AI and and\\xa0\\nmaybe that is an overreliance that we, you know,\\xa0\\xa0', start=3725.36, duration=6.32),\n",
       " FetchedTranscriptSnippet(text='would need to think about. And you know, you you\\xa0\\nplay out these different scenarios, but then you\\xa0\\xa0', start=3731.68, duration=4.72),\n",
       " FetchedTranscriptSnippet(text=\"ask someone why they're working on it, or you ask\\xa0\\nsomeone how how they think this will play out,\\xa0\\xa0\", start=3736.4, duration=3.76),\n",
       " FetchedTranscriptSnippet(text=\"and I just maybe I haven't spoken to enough people\\xa0\\nyet. Maybe I don't fully understand this this\\xa0\\xa0\", start=3740.16, duration=5.6),\n",
       " FetchedTranscriptSnippet(text=\"cultural conversation that's happening. Um or\\xa0\\nmaybe it really is someone who just says 99% of\\xa0\\xa0\", start=3745.76, duration=6.4),\n",
       " FetchedTranscriptSnippet(text=\"the time I think it's going to be incredibly good.\\xa0\\n1% of the time I think it might be a disaster\\xa0\\xa0\", start=3752.16, duration=4.48),\n",
       " FetchedTranscriptSnippet(text=\"trying to make the best world. That I can totally\\xa0\\nif you're like, hey, 99% chance incredible. 1%\\xa0\\xa0\", start=3756.64, duration=4.88),\n",
       " FetchedTranscriptSnippet(text='chance the world gets wiped out. And I really want\\xa0\\nto work to maximize to move that 99 to 99.5. That\\xa0\\xa0', start=3761.52, duration=6.24),\n",
       " FetchedTranscriptSnippet(text=\"I can totally understand. Yeah, that makes sense.\\xa0\\nI've been doing an interview series with some of\\xa0\\xa0\", start=3767.76, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='the most important people influencing the future.\\xa0\\nNot knowing who the next person is going to be,\\xa0\\xa0', start=3773.36, duration=5.6),\n",
       " FetchedTranscriptSnippet(text=\"but knowing that they will be building something\\xa0\\ntotally fascinating in the future that we've just\\xa0\\xa0\", start=3778.96, duration=4.24),\n",
       " FetchedTranscriptSnippet(text=\"described. Is there a question that you'd advise\\xa0\\nme to ask the next person not knowing who it is?\\xa0\\xa0\", start=3783.2, duration=5.52),\n",
       " FetchedTranscriptSnippet(text=\"I'm always interested in the like without knowing\\xa0\\nanything about the I'm always interested in the\\xa0\\xa0\", start=3790.08, duration=3.44),\n",
       " FetchedTranscriptSnippet(text='like of all of the things you could spend\\xa0\\nyour time and energy on. Why did you pick\\xa0\\xa0', start=3793.52, duration=4.8),\n",
       " FetchedTranscriptSnippet(text='this one? How did you get started? Like what\\xa0\\ndid you see about this when before everybody\\xa0\\xa0', start=3798.32, duration=4.4),\n",
       " FetchedTranscriptSnippet(text='else like most people doing something interesting\\xa0\\nsort of saw it earlier before it was consensus.\\xa0\\xa0', start=3802.72, duration=3.76),\n",
       " FetchedTranscriptSnippet(text='Yeah. Like how did how did you get here and\\xa0\\nwhy this? How would you answer that question?', start=3806.48, duration=7.12),\n",
       " FetchedTranscriptSnippet(text='I was an AI nerd my whole life. I came to college\\xa0\\nto study AI. I worked in the AI lab. Uh, I was\\xa0\\xa0', start=3813.6, duration=5.36),\n",
       " FetchedTranscriptSnippet(text='like a I watched sci-fi shows growing up and I\\xa0\\nalways thought it would be really cool if someday\\xa0\\xa0', start=3818.96, duration=5.6),\n",
       " FetchedTranscriptSnippet(text='somebody built it. I thought it would be like the\\xa0\\nmost important thing ever. I never thought I was\\xa0\\xa0', start=3824.56, duration=3.12),\n",
       " FetchedTranscriptSnippet(text='going to be one to actually work on it and I feel\\xa0\\nlike unbelievably lucky and happy and privileged\\xa0\\xa0', start=3827.68, duration=8.64),\n",
       " FetchedTranscriptSnippet(text=\"that I get to do this. I like feel like I've like\\xa0\\ncome a long way from my childhood. But there was\\xa0\\xa0\", start=3836.32, duration=6.88),\n",
       " FetchedTranscriptSnippet(text=\"never a question in my mind that this would not be\\xa0\\nthe most exciting interesting thing. I just didn't\\xa0\\xa0\", start=3843.2, duration=3.68),\n",
       " FetchedTranscriptSnippet(text='think it was going to be possible. Uh, and when\\xa0\\nI went to college, it really seemed like we were\\xa0\\xa0', start=3846.88, duration=4.8),\n",
       " FetchedTranscriptSnippet(text='very far from it. And then in 2012, the Alex Net\\xa0\\npaper came out done, you know, in partnership with\\xa0\\xa0', start=3851.68, duration=7.68),\n",
       " FetchedTranscriptSnippet(text='my co-founder, Ilia. And for the first time, it\\xa0\\nseemed to me like there was an approach that might\\xa0\\xa0', start=3859.36, duration=7.44),\n",
       " FetchedTranscriptSnippet(text='work. And then I kept watching for the next couple\\xa0\\nof years as scaled up, scaled up, got better,\\xa0\\xa0', start=3866.8, duration=5.04),\n",
       " FetchedTranscriptSnippet(text='better. And I remember having this thing of\\xa0\\nlike why is the world not paying attention to\\xa0\\xa0', start=3871.84, duration=4.16),\n",
       " FetchedTranscriptSnippet(text='this? It seems like obvious to me that this might\\xa0\\nwork. Still a low chance, but it might work. And\\xa0\\xa0', start=3876.0, duration=6.0),\n",
       " FetchedTranscriptSnippet(text=\"if it does work, it's just the most important\\xa0\\nthing. So like this is what I want to do. And\\xa0\\xa0\", start=3882.0, duration=5.84),\n",
       " FetchedTranscriptSnippet(text='then like unbelievably it started to work. Thank\\xa0\\nyou so much for your time. Thank you very much.', start=3887.84, duration=10.48)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9466c1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is like a crazy amount of power for\\xa0\\none piece of technology and it\\'s happened\\xa0\\xa0  to us so fast. You just launched GPT-5. A kid\\xa0\\nborn today will never be smarter than AI. How\\xa0\\xa0  do we figure out what\\'s real and what\\'s not\\xa0\\nreal? We haven\\'t put a sex bot avatar in ChatGPT\\xa0\\xa0  yet. Super intelligence. What does that\\xa0\\nactually mean? This thing is remarkable.  I\\'m about to interview Sam Alman, the CEO\\xa0\\nof Open AI. Open AI. Open AI. Reshaping\\xa0\\xa0  industries. Dude\\'s a straightup tech lord. Let\\'s\\xa0\\nbe honest. Right now, they\\'re trying to build a\\xa0\\xa0  super intelligence that could far exceed humans\\xa0\\nin almost every field. And they just released\\xa0\\xa0  their most powerful model yet. Just a couple years\\xa0\\nago, that would have sounded like science fiction.\\xa0\\xa0  Not anymore. In fact, they\\'re not alone. We are\\xa0\\nin the middle of the highest stakes global race\\xa0\\xa0  any of us have ever seen. Hundreds of billions of\\xa0\\ndollars and an unbelievable amount of human worth.\\xa0\\xa0  This is a profound moment. Most people never\\xa0\\nlive through a technological shift like this,\\xa0\\xa0  and it\\'s happening all around you and me right\\xa0\\nnow. So, in this episode, I want to try to time\\xa0\\xa0  travel with Sam Alman into the future that\\xa0\\nhe\\'s trying to build to see what it looks\\xa0\\xa0  like so that you and I can really understand\\xa0\\nwhat\\'s coming. Welcome to Huge Conversations.  How are you? Great to meet you. Thanks for\\xa0\\ndoing this. Absolutely. So, before we dive in,\\xa0\\xa0  I\\'d love to tell you my goal here. Okay. I\\'m\\xa0\\nnot going to ask you about valuation or AI\\xa0\\xa0  talent wars or fundraising or anything like that.\\xa0\\nI think that\\'s all very well covered elsewhere. It\\xa0\\xa0  does seem like it. Our big goal on this show is to\\xa0\\ncover how we can use science and tech to make the\\xa0\\xa0  future better. And the reason that we do all of\\xa0\\nthat is because we really believe that if people\\xa0\\xa0  see those better futures, they can then help\\xa0\\nbuild them. So, my goal here is to try my best\\xa0\\xa0  to time travel with you into different moments\\xa0\\nin the future that you\\'re trying to build and see\\xa0\\xa0  what it looks like. Fantastic. Awesome. Starting\\xa0\\nwith what you just announced, you recently said,\\xa0\\xa0  surprisingly recently, that GPT4 was the dumbest\\xa0\\nmodel any of us will ever have to use again.\\xa0\\xa0  But GPT4 can already perform better than 90% of\\xa0\\nhumans at the SAT and the LSAT and the GRE and it\\xa0\\xa0  can pass coding exams and sommelier exams and medical\\xa0\\nlicensing. And now you just launched GPT5. What\\xa0\\xa0  can GPT5 do that GPT4 can\\'t? First of all, one\\xa0\\nimportant takeaway is you can have an AI system\\xa0\\xa0  that can do all those amazing things you just\\xa0\\nsaid. And it doesn\\'t it clearly does not replicate\\xa0\\xa0  a lot of what humans are good at doing, which I\\xa0\\nthink says something about the value of SAT tests\\xa0\\xa0  or whatever else. But I think had you gone back\\xa0\\nto if we were having this conversation the day of\\xa0\\xa0  GPT4 launch and we told you how GPT4 did at those\\xa0\\nthings, you were like, \"Oh man, this is going to\\xa0\\xa0  have huge impacts and some negative impacts on\\xa0\\nwhat it means for a bunch of jobs or you know\\xa0\\xa0  what people are going to do.\" And you know, this\\xa0\\nis a bunch of positive impacts that you might have\\xa0\\xa0  predicted that haven\\'t yet come true. Uh, and so\\xa0\\nthere there\\'s something about the way that these\\xa0\\xa0  models are good that does not capture a lot of\\xa0\\nother things that we need people to to do or care\\xa0\\xa0  about people doing. And I suspect that same thing\\xa0\\nis going to happen again with GPT5. People are\\xa0\\xa0  going to be blown away by what it does. Uh, it\\'s\\xa0\\nreally good at a lot of things and then they will\\xa0\\xa0  find that they want it to do even more. Um, people\\xa0\\nwill use it for all sorts of incredible things.\\xa0\\xa0  uh it will transform a lot of knowledge work,\\xa0\\na lot of the way we learn, a lot of the way we\\xa0\\xa0  create um but we people society will co-eolve with\\xa0\\nit to expect more with you know better tools. So\\xa0\\xa0  yeah like I think this model is quite remarkable\\xa0\\nin many ways quite limited in others but the fact\\xa0\\xa0  that for you know 3 minute 5 minute 1-hour tasks\\xa0\\nthat uh like an expert in a in a field could maybe\\xa0\\xa0  do or maybe struggle with that the fact that you\\xa0\\nhave in your pocket one piece of software that\\xa0\\xa0  can do all of these things is really amazing.\\xa0\\nI think this is like unprecedented at any point\\xa0\\xa0  in human history that I that a technology has\\xa0\\nimproved this much this fast and and the fact\\xa0\\xa0  that we have this tool now, you know, we\\'re like\\xa0\\nliving through it and we\\'re kind of adjusting step\\xa0\\xa0  by step. But if we could go back in time five or\\xa0\\n10 years and say this thing was coming, we would\\xa0\\xa0  be like probably not. Let\\'s assume that people\\xa0\\nhaven\\'t seen the headlines. What are the topline\\xa0\\xa0  specific things that you\\'re excited about? and\\xa0\\nalso the things that you seem to be caveatting,\\xa0\\xa0  the things that maybe you won\\'t expect it to do.\\xa0\\nUm, the thing that I am most excited about is this\\xa0\\xa0  is a model for the first time where I feel like I\\xa0\\ncan ask kind of any hard scientific or technical\\xa0\\xa0  question and get a pretty good answer. And I\\'ll\\xa0\\ngive a fun example actually. Uh when I was in\\xa0\\xa0  junior high uh or maybe it was nth grade,\\xa0\\nI got a TI83, this old graphing calculator,\\xa0\\xa0  and I spent so long making this game called Snake.\\xa0\\nYeah. Uh it was very popular game with kids in my\\xa0\\xa0  school. And I was I was like uh I was like pro and\\xa0\\nit was dumb, but it was like programming on TID3\\xa0\\xa0  was extremely painful and took a long time and\\xa0\\nit was really hard to like debug and whatever.\\xa0\\xa0  And on a whim with an early copy of GPT5, I was\\xa0\\nlike, I wonder if it can make a TI83 style Game\\xa0\\xa0  of Snake. And of course, it did that perfectly\\xa0\\nin like 7 seconds. And then I was like, okay,\\xa0\\xa0  am I supposed to be would my like 11-year-old\\xa0\\nself think this was cool or like, you know,\\xa0\\xa0  miss something from the process? And I\\xa0\\nhad like 3 seconds of wondering like, oh,\\xa0\\xa0  is this good or bad? And then I immediately said,\\xa0\\nactually, now I\\'m missing this game. I have this\\xa0\\xa0  idea for a crazy new feature. Let me type it\\xa0\\nin. it implements it and it just the game live\\xa0\\xa0  updates and I\\'m like actually I\\'d like it to look\\xa0\\nthis way. Actually, I\\'d like to do this thing and\\xa0\\xa0  I had this like this very like kind of you have\\xa0\\nthis experience that reminded me of being like 11\\xa0\\xa0  in programming again where I was just like I now I\\xa0\\nwant to try this now I have this idea now I but I\\xa0\\xa0  could do it so fast and I could like express ideas\\xa0\\nand try things and play with things in such real\\xa0\\xa0  time. I was like, \"Oh man, you know, I was worried\\xa0\\nfor a second about kids like missing the struggle\\xa0\\xa0  of learning to program in this sort of stone age\\xa0\\nway.\" And now I\\'m just thrilled for them because\\xa0\\xa0  the the way that people will be able to create\\xa0\\nwith these new tools, the speed with which you\\xa0\\xa0  can sort of bring ideas to life, you know, in\\xa0\\nthat\\'s that\\'s pretty amazing. So this idea that\\xa0\\xa0  GPT5 can just not only like answer all these hard\\xa0\\nquestions for you but really create like ondemand\\xa0\\xa0  almost instantaneous software that\\'s I think\\xa0\\nthat\\'s going to be one of the defining elements\\xa0\\xa0  of the GPD5 era in a way that did not exist with\\xa0\\nGPD4. As you\\'re talking about that I find myself\\xa0\\xa0  thinking about a concept in weightlifting of time\\xa0\\nunder tension. Yeah. And for those who don\\'t know\\xa0\\xa0  it\\'s you can squat 100 pounds in 3 seconds or you\\xa0\\ncan squat 100 pounds in 30. You gain a lot more\\xa0\\xa0  by squatting it in 30. And when I think about our\\xa0\\ncreative process and when I\\'ve felt most like I\\'ve\\xa0\\xa0  done my best work, it has required an enormous\\xa0\\namount of cognitive time under tension. And I\\xa0\\xa0  think that that cognitive time under tension\\xa0\\nis so important. And it\\'s it\\'s ironic almost\\xa0\\xa0  because these tools have taken enormous cognitive\\xa0\\ntime under tension to develop. But in some ways I\\xa0\\xa0  do think people might say they\\'re you people are\\xa0\\nusing them as a escape hatch for thinking in some\\xa0\\xa0  ways maybe. Now you might say yeah but we did that\\xa0\\nwith the calculator and we just moved on to harder\\xa0\\xa0  math problems. Do you feel like there\\'s something\\xa0\\ndifferent happening here? How do you think about\\xa0\\xa0  this? It\\'s different with I mean there are some\\xa0\\npeople who are clearly using chachine not to\\xa0\\xa0  think and there are some people who are using\\xa0\\nit to think more than they ever have before.\\xa0\\xa0  I am hopeful that we will be able to build the\\xa0\\ntool in a way that encourages more people to\\xa0\\xa0  stretch their brain with it a little more and\\xa0\\nbe able to do more. And I think that like you\\xa0\\xa0  know society is a competitive place like if you\\xa0\\ngive people new tools uh in theory maybe people\\xa0\\xa0  just work less but in practice it seems like\\xa0\\npeople work ever harder and the expectations of\\xa0\\xa0  people just go up. So my my guess is that like\\xa0\\nother tools uh some people like other pieces\\xa0\\xa0  of technology some people will do more and some\\xa0\\npeople will do less but certainly for the people\\xa0\\xa0  who want to use chatbt to increase their cognitive\\xa0\\ntime under tension they are really able to and it\\xa0\\xa0  is I take a lot of inspiration from what like the\\xa0\\ntop 5% of most engaged users do with chacht like\\xa0\\xa0  it\\'s really amazing how much people are learning\\xa0\\nand doing and you know outputting. So my I\\'ve\\xa0\\xa0  only had GPT5 for a couple hours so I\\'ve been\\xa0\\nplaying. What do you think so far? I\\'m I\\'m just\\xa0\\xa0  learning how to interact with it. I mean part of\\xa0\\nthe interesting thing is I feel like I just caught\\xa0\\xa0  up on how to use GPT4 and now I\\'m trying to learn\\xa0\\nhow to use GPD5. I\\'m curious what the specific\\xa0\\xa0  tasks that you found most interesting are because\\xa0\\nI imagine you\\'ve been using it for a while now.\\xa0\\xa0  I I have been most impressed by the coding tasks.\\xa0\\nI mean, there\\'s a lot of other things it\\'s really\\xa0\\xa0  good at, but this this idea of the AI can write\\xa0\\nsoftware for anything. And that means that you\\xa0\\xa0  can express ideas in new ways that the AI can\\xa0\\ndo very advanced things. It can do, you know,\\xa0\\xa0  it can like in some sense you could like ask\\xa0\\nGPT4 anything, but because GPT5 is so good at\\xa0\\xa0  programming, it feels like it can do anything. Of\\xa0\\ncourse, it can\\'t do things in the physical world,\\xa0\\xa0  but it can get a computer to do very complex\\xa0\\nthings. And software is this super powerful,\\xa0\\xa0  you know, way to like control some stuff and\\xa0\\nactually do some things. So, that that for me\\xa0\\xa0  has been the most striking. Um, it\\'s gotten it\\'s\\xa0\\nmuch better at writing. So, this is like there\\'s\\xa0\\xa0  this whole thing of AI slop like AI writes in this\\xa0\\nkind of like quite annoying way and M dashes. M we\\xa0\\xa0  still have the M dashes in GPT5. A lot of people\\xa0\\nlike them dashes, but the writing quality of GPT5\\xa0\\xa0  is gotten much better. We still have a long way\\xa0\\nto go. We want to improve it more, but like uh\\xa0\\xa0  I\\'ve a thing we\\'ve heard a lot from people inside\\xa0\\nof OpenAI is that man, they started using GPT5,\\xa0\\xa0  they knew it was better on all the metrics, but\\xa0\\nthere\\'s this like nuance quality they can\\'t quite\\xa0\\xa0  articulate, but then when they have to go back\\xa0\\nto GPT4 to test something, it feels terrible.\\xa0\\xa0  And I I don\\'t know exactly what the cause\\xa0\\nof that is, but I suspect part of it is the\\xa0\\xa0  writing feels so much more natural and better.\\xa0\\nI in preparation for this interview reached out\\xa0\\xa0  to a couple other leaders in AI and technology\\xa0\\nand gathered a couple questions for you. Okay,\\xa0\\xa0  so this next question is from Stripe CEO Patrick\\xa0\\nCollison. This will be a good one. Read this\\xa0\\xa0  verbatim. It\\'s about the next stage. What what\\xa0\\ncomes after GBT5? In which year do you think a\\xa0\\xa0  large language model will make a significant\\xa0\\nscientific discovery and what\\'s missing such\\xa0\\xa0  that it hasn\\'t happened yet? He caveed here that\\xa0\\nwe should leave math and special case models like\\xa0\\xa0  alpha fold aside. He\\'s specifically asking about\\xa0\\nfully general purpose models like the GPT series.\\xa0\\xa0  I would say most people will agree that that\\xa0\\nhappens at some point over the next two years.\\xa0\\xa0  But the definition of significant matters a lot.\\xa0\\nAnd so some people significant might happen,\\xa0\\xa0  you know, in early 25. Some people might maybe\\xa0\\nnot until late 2026. Sorry, early 2026. Maybe some\\xa0\\xa0  people not until late 2027, but I would I would\\xa0\\nbet that by late 27, most people agree that there\\xa0\\xa0  has been an AIdriven significant new discovery.\\xa0\\nAnd the thing that I think is missing is just\\xa0\\xa0  the kind of cognitive power of these models.\\xa0\\nA framework that one of the researchers said\\xa0\\xa0  to me that I really liked is, you know, a year\\xa0\\nago we could do well on like a high school like\\xa0\\xa0  a basic high school math competition problems that\\xa0\\nmight take a professional mathematician seconds to\\xa0\\xa0  a few minutes. We very recently got an IMO gold\\xa0\\nmedal. That is a crazy difficult like could you\\xa0\\xa0  explain what that means? That\\'s kind of like the\\xa0\\nhardest competition math test. This is something\\xa0\\xa0  that like the very very top slice of the world.\\xa0\\nmany many professional mathematicians wouldn\\'t\\xa0\\xa0  solve a single problem and we scored at the top\\xa0\\nlevel. Now there are some humans that got an even\\xa0\\xa0  higher score in the gold medal range but we we\\xa0\\nlike this is a crazy accomplishment and these\\xa0\\xa0  each of these problems it\\'s like six problems over\\xa0\\n9 hours so hour and a half per problem for a great\\xa0\\xa0  mathematician. So we\\'ve gone from a few seconds\\xa0\\nto a few minutes to an hour and a half maybe to\\xa0\\xa0  prove a significant new mathematical theorem is\\xa0\\nlike a thousand hours of work for a top person\\xa0\\xa0  in the world. So we\\'ve got to go from, you know,\\xa0\\nanother significant gain. But if you look at our\\xa0\\xa0  trajectory, you can say like, okay, we\\'re getting\\xa0\\nto that. We have a path to get to that time\\xa0\\xa0  horizon. We just need to keep scaling the models.\\xa0\\nThe long-term future that you\\'ve described is\\xa0\\xa0  super intelligence. What does that actually mean?\\xa0\\nAnd how will we know when we\\'ve hit it? If we had\\xa0\\xa0  a system that could do better research, better AI\\xa0\\nresearch than uh say the whole open AI research\\xa0\\xa0  team, like if we were willing, if we said, \"Okay,\\xa0\\nthe best way we can use our GPUs is to let this AI\\xa0\\xa0  decide what experiments we should run smarter than\\xa0\\nlike the whole brain trust of Open AAI.\" Yeah. And\\xa0\\xa0  if that same to make a personal example, if that\\xa0\\nsame system could do a better job running open AI\\xa0\\xa0  than I could. So you have something that\\'s like,\\xa0\\nyou know, better than the best researchers, better\\xa0\\xa0  than me at this, better than other people at their\\xa0\\njobs, that would feel like super intelligence to\\xa0\\xa0  me. That is a sentence that would have sounded\\xa0\\nlike science fiction just a couple years ago.\\xa0\\xa0  And now it kind of does, but it\\'s you can like see\\xa0\\nit through the fog. Yes. And so one of the steps\\xa0\\xa0  it sounds like you\\'re saying on that path is this\\xa0\\nmoment of scientific discovery of asking better\\xa0\\xa0  questions of grappling with things in a in a way\\xa0\\nthat expert level humans do to come up with new\\xa0\\xa0  discoveries. One of the things that keeps knocking\\xa0\\naround in my head is if we were in 1899 say and\\xa0\\xa0  we were able to give it all of physics up until\\xa0\\nthat point and play it out a little bit. Nothing\\xa0\\xa0  further than that. Like at what point would one\\xa0\\nof these systems come up with general relativity?\\xa0\\xa0  Interesting question is did you like if we think\\xa0\\nabout that forward like like if we think of where\\xa0\\xa0  we are now should a if if we never got another\\xa0\\npiece of physics data. Yeah. Do we expect that a\\xa0\\xa0  really good super intelligence could just think\\xa0\\nsuper hard about our existing data and maybe\\xa0\\xa0  say like solve high energy physics with no new\\xa0\\nparticle accelerator or does it need to build a\\xa0\\xa0  new one and design new experiments? Obviously\\xa0\\nwe don\\'t know the answer to that. Different\\xa0\\xa0  people have different speculation. Uh but I\\xa0\\nsuspect we will find that for a lot of science,\\xa0\\xa0  it\\'s not enough to just think harder about data we\\xa0\\nhave, but we will need to build new instruments,\\xa0\\xa0  conduct new experiments, and that will take some\\xa0\\ntime. Like that that is the real world is slow\\xa0\\xa0  and messy and you know whatever. So I\\'m sure we\\xa0\\ncould make some more progress just by thinking\\xa0\\xa0  harder about the current scientific data we\\xa0\\nhave in the world. But my guess is to make\\xa0\\xa0  the big progress we\\'ll also need to build new\\xa0\\nmachines and run new experiments and there will\\xa0\\xa0  be some slowdown built into that. Another way of\\xa0\\nof thinking about this is AI systems now are just\\xa0\\xa0  incredibly good at answering almost any question.\\xa0\\nBut maybe one of the things we\\'re saying is it\\'s\\xa0\\xa0  another leap yet. And what Patrick\\'s question\\xa0\\nis getting at is to ask the better questions.\\xa0\\xa0  Or or if we go back to this kind of timeline\\xa0\\nquestion, we could maybe say that AI systems\\xa0\\xa0  are superhuman on one minute tasks, but a long\\xa0\\nway to go to the thousand hour tasks. And there\\'s\\xa0\\xa0  a dimension of human intelligence that seems\\xa0\\nvery different than AI systems when it comes\\xa0\\xa0  to these long horizon tasks. Now, I think we will\\xa0\\nfigure it out, but today it\\'s a real weak point.\\xa0\\xa0  We\\'ve talked about where we are now with GBC5.\\xa0\\nWe talked about the end goal or future goal of\\xa0\\xa0  super intelligence. One of the questions that\\xa0\\nI have, of course, is what does it look like\\xa0\\xa0  to walk through the fog between the two. The next\\xa0\\nquestion is from Nvidia CEO Jensen Hong. I\\'m going\\xa0\\xa0  to read this verbatim. Fact is what is. Truth is\\xa0\\nwhat it means. So facts are objective. Truths are\\xa0\\xa0  personal. They depend on perspective, culture,\\xa0\\nvalues, beliefs, context. One AI can learn and\\xa0\\xa0  know the facts. But how does one AI know the\\xa0\\ntruth for everyone in every country and every\\xa0\\xa0  background? I\\'m going to accept as axioms those\\xa0\\ndefinitions. I\\'m not sure if I agree with them,\\xa0\\xa0  but in the issues of time, I will just take them.\\xa0\\nI will take those definitions and go with it. Um,  I have been surprised, I think many other people\\xa0\\nhave been surprised too about how fluent AI is\\xa0\\xa0  at adapting to different cultural contexts and\\xa0\\nindividuals. One of my favorite features that we\\xa0\\xa0  have ever launched in chatbt is the the sort of\\xa0\\nenhanced memory that came out earlier this year.\\xa0\\xa0  like it really feels like my Chad GBT gets to\\xa0\\nknow me and what I care about and like my life\\xa0\\xa0  experiences and background and the things that\\xa0\\nhave led me to where they are. A friend of mine\\xa0\\xa0  recently who\\'s been a huge CHBT user, so he\\'s\\xa0\\ngot a lot of a a lot of he\\'s put a lot of his\\xa0\\xa0  life into all these conversations. He gave his\\xa0\\nChad GBT a bunch of personality tests and asked\\xa0\\xa0  them to answer as if they were him and it got\\xa0\\nthe same scores he actually got, even though\\xa0\\xa0  he\\'d never really talked about his personality.\\xa0\\nAnd my ChachiBD has really learned over the years\\xa0\\xa0  of me talking to it about my culture, my\\xa0\\nvalues, my life. And I have used, you know,\\xa0\\xa0  I sometimes will use it in like uh I\\'ll use like\\xa0\\na free account just to see what it\\'s like without\\xa0\\xa0  any of my history and it feels really really\\xa0\\ndifferent. So I think we\\'ve all been surprised on\\xa0\\xa0  the upside of how good AI is at learning this and\\xa0\\nadapting. And so do you envision in many different\\xa0\\xa0  parts of the world people using different\\xa0\\nAIs with different sort of cultural norms and\\xa0\\xa0  contexts? Is that what we\\'re saying? I think that\\xa0\\neveryone will use like the same fundamental model,\\xa0\\xa0  but there will be context provided to that model\\xa0\\nthat will make it behave in sort of personalized\\xa0\\xa0  way they want their community wants. Whatever.\\xa0\\nI think when we\\'re getting at this idea of facts\\xa0\\xa0  and truth and uh it brings me to this seems like a\\xa0\\ngood moment for our first time travel trip. Okay,\\xa0\\xa0  we\\'re going to 2030. This is a serious question,\\xa0\\nbut I want to ask it with a light-hearted example.\\xa0\\xa0  Have you seen the bunnies that are jumping on\\xa0\\nthe trampoline? Yes. So, for those who haven\\'t\\xa0\\xa0  seen it, maybe it looks like backyard footage of\\xa0\\nbunnies enjoying jumping on a trampoline. And this\\xa0\\xa0  has gone incredibly viral recently. There\\'s a\\xa0\\nhumanmade song about it. It\\'s a whole thing.\\xa0\\xa0  There were a trampoline. And I think the reason\\xa0\\nwhy people reacted so strongly to it, it was maybe\\xa0\\xa0  the first time people saw a video, enjoyed it,\\xa0\\nand then later found out that it was completely AI\\xa0\\xa0  generated. In this time travel trip, if we imagine\\xa0\\nin 2030, we are teenagers and we\\'re scrolling\\xa0\\xa0  whatever teenagers are scrolling in 2030. How do\\xa0\\nwe figure out what\\'s real and what\\'s not real?\\xa0\\xa0  I mean, I can give all sorts of literal answers\\xa0\\nto that question. We could be cryptographically\\xa0\\xa0  signing stuff and we could decide who we trust\\xa0\\ntheir signature if they actually filmed something\\xa0\\xa0  or not. But but my sense is what\\'s going to\\xa0\\nhappen is it\\'s just going to like gradually\\xa0\\xa0  converge. You know, even like a photo you take\\xa0\\nout of your iPhone today, it\\'s like mostly real,\\xa0\\xa0  but it\\'s a little not. There\\'s like in some AI\\xa0\\nthing running there in a way you don\\'t understand\\xa0\\xa0  and making it look like a little bit better and\\xa0\\nsometimes you see these weird things where the\\xa0\\xa0  moon. Yeah. Yeah. Yeah. Yeah. But there\\'s like\\xa0\\na lot of processing power between the photons\\xa0\\xa0  captured by that camera sensor and the image\\xa0\\nyou eventually see. And you\\'ve decided it\\'s real\\xa0\\xa0  enough or most people decided it\\'s real enough.\\xa0\\nBut we\\'ve accepted some gradual move from when it\\xa0\\xa0  was like photons hitting the film in a camera. And\\xa0\\nyou know, if you go look at some video on Tik Tok,\\xa0\\xa0  there\\'s probably all sorts of video editing tools\\xa0\\nbeing used to make it better than real look. Yeah,\\xa0\\xa0  exactly. Or it\\'s just like, you know, whole\\xa0\\nscenes are completely generated or some of\\xa0\\xa0  the whole videos are generated like those bunnies\\xa0\\non that trampoline. And and I think that the the\\xa0\\xa0  sort of like the threshold for how real does it\\xa0\\nhave to be to consider to be real will just keep\\xa0\\xa0  moving. So it\\'s sort of a education question.\\xa0\\nIt\\'s a people will Yeah. I mean media is always\\xa0\\xa0  like a little bit real and a little bit not real.\\xa0\\nLike you know we watch like a sci-fi movie. We\\xa0\\xa0  know that didn\\'t really happen. You watch like\\xa0\\nsomeone\\'s like beautiful photo of themselves on\\xa0\\xa0  vacation on Instagram. like, okay, maybe that\\xa0\\nphoto was like literally taken, but you know,\\xa0\\xa0  there\\'s like tons of tourists in line for the same\\xa0\\nphoto and that\\'s like left out of it. And I think\\xa0\\xa0  we just accept that now. Certainly, a higher\\xa0\\npercentage of media both will will feel not\\xa0\\xa0  real. Um, but I think that\\'s been the long-term\\xa0\\ntrend. Anyway, we\\'re going to jump again. Okay,\\xa0\\xa0  2035, we\\'re graduating from college, you and me.\\xa0\\nThere are some leaders in the AI space that have\\xa0\\xa0  said that in 5 years half of the entry level\\xa0\\nwhite collar workforce will be replaced by AI.\\xa0\\xa0  So we\\'re college graduates in 5 years. What do\\xa0\\nyou hope the world looks like for us? I think\\xa0\\xa0  there\\'s been a lot of talk about how AI might\\xa0\\ncause job displacement, but I\\'m also curious. I\\xa0\\xa0  have a job that nobody would have thought we\\xa0\\ncould have, you know, totally a decade ago.\\xa0\\xa0  What are the things that we could look ahead if\\xa0\\nwe\\'re thinking about in 2035 that like graduating\\xa0\\xa0  college student, if they still go to college at\\xa0\\nall, could very well be like leaving on a mission\\xa0\\xa0  to explore the solar system on a spaceship in some\\xa0\\nkind of completely new exciting, super well- paid,\\xa0\\xa0  super interesting job and feeling so bad for you\\xa0\\nand I that like we had to do this kind of like\\xa0\\xa0  really boring old kind of work and everything\\xa0\\nis just better. Like I I 10 years feels very\\xa0\\xa0  hard to imagine at this point because it\\'s too\\xa0\\nfar. It\\'s too far. If you compound the current\\xa0\\xa0  rate of change for 10 more years, it\\'s probably\\xa0\\nsomething we can\\'t even time travel trips. I 10\\xa0\\xa0  like I mean I think now would be really hard\\xa0\\nto imagine 10 years ago. Yeah. Uh but I think\\xa0\\xa0  10 years forward will be even much harder, much\\xa0\\nmore different. So let\\'s make it 5 years. We\\'re\\xa0\\xa0  still going to 2030. I\\'m curious what you\\xa0\\nthink the pretty short-term impacts of this\\xa0\\xa0  will be for for young people. I mean, these like\\xa0\\nhalf of entry- level jobs replaced by AI makes\\xa0\\xa0  it sound like a very different world that they\\xa0\\nwould be entering than the one that I did. Um,  I think it\\'s totally true that some classes of\\xa0\\njobs will totally go away. This always happens\\xa0\\xa0  and young people are the best at adapting to this.\\xa0\\nI\\'m more worried about what it means, not for the\\xa0\\xa0  like 22-y old, but for the 62-y old that doesn\\'t\\xa0\\nwant to go re retrain or reskill or whatever the\\xa0\\xa0  politicians call it that no one actually wants\\xa0\\nbut politicians and most of the time. If I were\\xa0\\xa0  22 right now and graduating college, I would\\xa0\\nfeel like the luckiest kid in all of history.\\xa0\\xa0  Why? Because there\\'s never been a more amazing\\xa0\\ntime to go create something totally new, to go\\xa0\\xa0  invent something, to start a company, whatever\\xa0\\nit is. I think it is probably possible now to\\xa0\\xa0  start a company that is a oneperson company that\\xa0\\nwill go on to be worth like more than a billion\\xa0\\xa0  dollars and more importantly than that deliver an\\xa0\\namazing product and service to the world and that\\xa0\\xa0  that is like a crazy thing. You have access to\\xa0\\ntools that can let you do what used to take teams\\xa0\\xa0  of hundreds and you just have to like you know\\xa0\\nlearn how to use these tools and come up with a\\xa0\\xa0  great idea and it\\'s it\\'s like quite amazing. If\\xa0\\nwe take a step back, I think the most important\\xa0\\xa0  thing that this audience could hear from you\\xa0\\non this optimistic show is in two parts. First,\\xa0\\xa0  there\\'s tactically, how are you actually trying\\xa0\\nto build the world\\'s most powerful intelligence\\xa0\\xa0  and what are the rate limiting factors to doing\\xa0\\nthat? And then philosophically, how are you and\\xa0\\xa0  others working on building that technology in\\xa0\\na way that really helps and not hurts people?\\xa0\\xa0  So just taking the tactical part right now.\\xa0\\nMy understanding is that there are three big\\xa0\\xa0  categories that have been limiting factors for\\xa0\\nAI. The first is compute, the second is data and\\xa0\\xa0  the third is algorithmic design. How do you think\\xa0\\nabout each of those three categories right now?\\xa0\\xa0  And if you were to help someone understand\\xa0\\nthe next headlines that they might see,\\xa0\\xa0  how would you help them make sense of all this?\\xa0\\nI I would say there\\'s a fourth too which is uh\\xa0\\xa0  figuring out the products to build like techn like\\xa0\\nscientific progress on its own not put into the\\xa0\\xa0  hands of people is of limited utility and doesn\\'t\\xa0\\nsort of co-evolve with society in the same way\\xa0\\xa0  but if I could hit all four of those um so on\\xa0\\nthe compute side yeah this is like the biggest\\xa0\\xa0  infrastructure project certainly that I\\'ve ever\\xa0\\nseen possibly it will become the I think it will\\xa0\\xa0  maybe already is the biggest and most expensive\\xa0\\none in human history but the the whole supply\\xa0\\xa0  chain from making the chips and the memory and\\xa0\\nthe networking gear, racking them up in servers,\\xa0\\xa0  doing, you know, a giant construction project to\\xa0\\nbuild like a mega mega data center, putting the,\\xa0\\xa0  you know, finding a way to get the energy, which\\xa0\\nis often a limiting factor piece of this and all\\xa0\\xa0  the other components together. This is hugely\\xa0\\ncomplex and expensive. And we are we\\'re still\\xa0\\xa0  doing this in like a sort of bespoke one-off way\\xa0\\nalthough it\\'s getting better. Like eventually we\\xa0\\xa0  will just design a whole kind of like mega factory\\xa0\\nthat takes you know I mean spiritually it will be\\xa0\\xa0  melting sand on one end and putting out fully\\xa0\\nbuilt AI compute on the other but we are a long\\xa0\\xa0  way to go from that and it\\'s a it\\'s an enormously\\xa0\\ncomplex and expensive process. uh we are putting\\xa0\\xa0  a huge amount of work into building out as much\\xa0\\ncompute as we can and to do it fast and you know\\xa0\\xa0  it\\'s going to be like sad because GP5 is going\\xa0\\nto launch and there\\'s going to be another big\\xa0\\xa0  spike in demand and we\\'re not going to be able\\xa0\\nto serve it and it\\'s going to be like those early\\xa0\\xa0  GPD4 days and the world just wants much more AI\\xa0\\nthan we can currently deliver and building more\\xa0\\xa0  compute is an important part of doing that.\\xa0\\nThat\\'s actually this is what I expect to turn\\xa0\\xa0  the majority of my attention to is how we build\\xa0\\ncompute at much greater scales. Uh so how we go\\xa0\\xa0  from millions to tens of millions and hundreds of\\xa0\\nmillions and eventually hopefully billions of GPUs\\xa0\\xa0  that are sort of in service of what people want\\xa0\\nto do with this. When you\\'re thinking about it,\\xa0\\xa0  what are the big challenges here in this category\\xa0\\nthat you\\'re going to be thinking about? We\\'re\\xa0\\xa0  currently most limited by energy. um you know like\\xa0\\nif you\\'re gonna you want to run a gigawatt scale\\xa0\\xa0  data center it\\'s like a gigawatt how hard can that\\xa0\\nbe to find it\\'s really hard to find a gigawatt of\\xa0\\xa0  power available in short term we\\'re also very much\\xa0\\nlimited by the processing chips and the memory\\xa0\\xa0  chips uh how you package these all together how\\xa0\\nyou build the racks and then there\\'s like a list\\xa0\\xa0  of other things that are you know there\\'s like\\xa0\\npermits there\\'s construction work uh but but\\xa0\\xa0  again the goal here will be to really automate\\xa0\\nthis once we get some of those robots built,\\xa0\\xa0  they can help us automate it even more. But just,\\xa0\\nyou know, like a world where you can basically\\xa0\\xa0  pour in money and get out a pre-built data center.\\xa0\\nUh so that\\'ll be that\\'ll be a huge unlock if we\\xa0\\xa0  can get it to work. Second category, data. Yeah,\\xa0\\nthese models have gotten so smart. There was a\\xa0\\xa0  time when we could just feed it another physics\\xa0\\ntextbook and got a little bit smarter at physics,\\xa0\\xa0  but now like honestly GBT5 understands\\xa0\\neverything in a physics textbook pretty well.\\xa0\\xa0  We\\'re excited about synthetic data. We\\'re very\\xa0\\nexcited about our users helping us create harder\\xa0\\xa0  and harder tasks and environments to go off and\\xa0\\nhave the system solve. But uh I think we\\'re data\\xa0\\xa0  will always be important, but we\\'re entering a\\xa0\\nrealm where the models need to learn things that\\xa0\\xa0  don\\'t exist in any data set yet. They have to\\xa0\\ngo discover new things. So that\\'s like a crazy\\xa0\\xa0  new How do you teach a model to discover new\\xa0\\nthings? Well, humans can do it. like we can\\xa0\\xa0  go off and come up with hypotheses and test them\\xa0\\nand get experimental results and update on what we\\xa0\\xa0  learn. So probably the same kind of way. And then\\xa0\\nthere\\'s algorithmic design. Yeah, we\\'ve made huge\\xa0\\xa0  progress on algorithmic design. Uh the thing that\\xa0\\nthe thing that I think open does best in the world\\xa0\\xa0  is we have built this culture of repeated and big\\xa0\\nalgorithmic research gains. So we kind of you know\\xa0\\xa0  figured out the what became the GPT paradigm. We\\xa0\\nfigured out became the reasoning paradigm. We\\'re\\xa0\\xa0  working on some new ones now. Um, but it is very\\xa0\\nexciting to me to think that there are still many\\xa0\\xa0  more orders of magnitudes of algorithmic\\xa0\\ngains ahead of us. We we just yesterday\\xa0\\xa0  uh released a model called GPOSS, open source\\xa0\\nmodel. It\\'s a model that is as smart as 04 Mini,\\xa0\\xa0  which is a very smart model that runs locally on\\xa0\\na laptop. And this blows my mind. Yeah. Like if\\xa0\\xa0  you had asked me a few years ago when we\\'d have\\xa0\\na model of that intelligence running on a laptop,\\xa0\\xa0  I would have said many many years in the future.\\xa0\\nBut then we we found some algorithmic gains\\xa0\\xa0  um particularly around reasoning but also some\\xa0\\nother things that let us do a a tiny model that\\xa0\\xa0  can do this amazing thing. And you know those are\\xa0\\nthose are the most fun things. That\\'s like kind of\\xa0\\xa0  the coolest part of the job. I can see you really\\xa0\\nenjoying thinking about this. I\\'m curious for\\xa0\\xa0  people who don\\'t quite know what you\\'re talking\\xa0\\nabout, who aren\\'t familiar with how an algorithmic\\xa0\\xa0  design would lead to a better experience that they\\xa0\\nactually use. Could you summarize the state of\\xa0\\xa0  things right now? Like what what is it that you\\'re\\xa0\\nthinking about when you\\'re thinking about how fun\\xa0\\xa0  this problem is? Let me start back in history\\xa0\\nand then I\\'ll get to some things for today. So,\\xa0\\xa0  GPT1 was an idea at the time that was quite\\xa0\\nmocked by a lot of experts in the field,\\xa0\\xa0  which was can we train a model to play a little\\xa0\\ngame, which is show it a bunch of words and have\\xa0\\xa0  it guess the one that comes next in the sequence.\\xa0\\nThat\\'s called unsupervised learning. There\\'s not\\xa0\\xa0  you\\'re not really saying like this is a cat,\\xa0\\nthis is a dog. You\\'re saying here\\'s some words,\\xa0\\xa0  guess the next one. And the fact that that can\\xa0\\ngo learn these very complicated concepts that\\xa0\\xa0  can go learn all the stuff about physics and math\\xa0\\nand programming and keep predicting the word that\\xa0\\xa0  comes next and next and next and next seemed\\xa0\\nludicrous, magical, unlikely to work. Like how\\xa0\\xa0  was that all going to get encoded? And yet humans\\xa0\\ndo it. you know, babies start hearing language and\\xa0\\xa0  figure out what it means kind of largely uh or at\\xa0\\nleast to some significant degree on their own. And\\xa0\\xa0  and so we did it and then we also realized that if\\xa0\\nwe scaled it up, it got better and better, but we\\xa0\\xa0  had to scale over many many orders of magnitude.\\xa0\\nSo it wasn\\'t that good in the GPT1 day. It wasn\\'t\\xa0\\xa0  good at all in the GPT1 days. And a lot of experts\\xa0\\nin the field said, \"Oh, this is ridiculous. It\\'s\\xa0\\xa0  never going to work. It\\'s not going to be robust.\"\\xa0\\nBut we had these things called scaling laws. And\\xa0\\xa0  we said, \"Okay, so this gets predictably better as\\xa0\\nwe increase compute, memory, data, whatever. And\\xa0\\xa0  we can we can decide we can use those predictions\\xa0\\nto make decisions about how to scale this up and\\xa0\\xa0  do it and get great results.\" And that has worked\\xa0\\nover Yeah. a crazy number of orders of magnitude.\\xa0\\xa0  And it was so not obvious at the time. like\\xa0\\nthat was that was I think the the reason the\\xa0\\xa0  world was so surprised is that that seemed like\\xa0\\nsuch an unlikely finding. Another one was that we\\xa0\\xa0  could use these language models with reinforcement\\xa0\\nlearning where we\\'re saying this is good, this is\\xa0\\xa0  bad to teach it how to reason. And this led to the\\xa0\\n01 and 03 and now the GBT5 progress. And that that\\xa0\\xa0  was another thing that felt like uh if it works\\xa0\\nit\\'s really great but like no way this is going\\xa0\\xa0  to work. It\\'s too simple. And now we\\'re on to new\\xa0\\nthings. We\\'ve figured out how to make much better\\xa0\\xa0  video models. We are we are discovering new ways\\xa0\\nto use new kinds of data and environment to kind\\xa0\\xa0  of scale that up as well. Um and I think again\\xa0\\nyou know 5 10 years out that\\'s too hard to say in\\xa0\\xa0  this field but the next couple of years we have\\xa0\\nvery smooth very strong scaling in front of us.\\xa0\\xa0  I think it has become a sort of public narrative\\xa0\\nthat we are on this smooth path from one to two to\\xa0\\xa0  three to four to five to more. Yeah. But it also\\xa0\\nis true behind the scenes that it\\'s a it\\'s not\\xa0\\xa0  linear like that. It\\'s messier. Tell us a little\\xa0\\nbit about the mess before GPT5. What was what were\\xa0\\xa0  the interesting problems that you needed to solve?\\xa0\\nUm, we did a model called Orion that we released\\xa0\\xa0  as GPT 4.5. And we had we did too big of a\\xa0\\nmodel. It was just it was it\\'s a very cool model,\\xa0\\xa0  but it\\'s unwieldly to use. And we realized that\\xa0\\nfor kind of some of the research we need to do on\\xa0\\xa0  top of a model, we need a different shape. So we\\xa0\\nwe followed one scaling law that kept being good\\xa0\\xa0  without without really internalizing. There was\\xa0\\na new even steeper scaling law that we got better\\xa0\\xa0  returns for compute on, which was this reasoning\\xa0\\nthing. So that was like one alley we went down and\\xa0\\xa0  turned around, but that\\'s fine. That\\'s part of\\xa0\\nresearch. Um, we had some problems with the way\\xa0\\xa0  we think about our data sets as these models like\\xa0\\nreally have to get get this big and um, you know,\\xa0\\xa0  learn from this much data. So So yeah, I think\\xa0\\nlike in the in the middle of it in the day-to-day,\\xa0\\xa0  you kind of you make a lot of U-turns as\\xa0\\nyou try things or you have an architecture\\xa0\\xa0  idea that doesn\\'t work, but the the aggregate the\\xa0\\nsummation of all the squiggles has been remarkably\\xa0\\xa0  smooth on the exponential. One of the\\xa0\\nthings I always find interesting is that\\xa0\\xa0  by the time I\\'m sitting here interviewing\\xa0\\nyou about the thing that you just put out,\\xa0\\xa0  you\\'re thinking about Exactly. What are the things\\xa0\\nthat you can share that are at least the problems\\xa0\\xa0  that you\\'re thinking about that I would be\\xa0\\ninterviewing you about in a year if I came back?  I mean, possibly you\\'ll be asking me like,\\xa0\\nwhat does it mean that this thing can go\\xa0\\xa0  discover new science? Yeah. What how how\\xa0\\nis the world supposed to think about GPT6\\xa0\\xa0  discovering new science? Now, maybe\\xa0\\nnot like maybe we don\\'t deliver that,\\xa0\\xa0  but it feels within grasp. If you did, what\\xa0\\nwould you say? What would your what would the\\xa0\\xa0  implications of that kind of achievement\\xa0\\nbe? Imagine you do succeed. Yeah. I mean,\\xa0\\xa0  I think the great parts will be great. the bad\\xa0\\nparts will be scary and the bizarre parts will\\xa0\\xa0  be like bizarre on the first day and then we\\'ll\\xa0\\nget used to them really fast. So we\\'ll be like,\\xa0\\xa0  \"Oh, it\\'s incredible that this is like being\\xa0\\nused to cure disease and be like, oh, it\\'s\\xa0\\xa0  extremely scary that models like this are being\\xa0\\nused to like create new biocurity threats.\" And\\xa0\\xa0  then we\\'ll also be like, man, it\\'s really weird\\xa0\\nto like live through watching the world speed up\\xa0\\xa0  so much and you know the economy grows so fast\\xa0\\nand the like it will feel like vertigo inducing\\xa0\\xa0  uh the sort of the rate of change and then like\\xa0\\nhappens with everything else the remarkable\\xa0\\xa0  ability of of people of humanity to adapt to kind\\xa0\\nof like any amount of change. we\\'ll just be like,\\xa0\\xa0  \"Okay, you know, this is like this is it.\" Um, a\\xa0\\nkid born today will never be smarter than AI ever.\\xa0\\xa0  And a kid born today, by the time that kid like\\xa0\\nkind of understands the way the world works, will\\xa0\\xa0  just always be used to an incredibly fast rate of\\xa0\\nthings improving and discovering new science. They\\xa0\\xa0  will just they will never know any other world. It\\xa0\\nwill seem totally natural. will seem unthinkable\\xa0\\xa0  and stone age like that we used to use computers\\xa0\\nor phones or any kind of technology that was not\\xa0\\xa0  way smarter than we were. You know, we will think\\xa0\\nlike how bad those people of the 2020s had it. I\\'m\\xa0\\xa0  thinking about having kids. You should. It\\'s the\\xa0\\nbest thing ever. I know you just had your first\\xa0\\xa0  kid. How does what you just said affect how I\\xa0\\nshould think about parenting a kid in that world?  What advice would you give me? Probably nothing\\xa0\\ndifferent than the way you\\'ve been parenting kids\\xa0\\xa0  for tens of thousands of years. Like love your\\xa0\\nkids, show them the world, like support them in\\xa0\\xa0  whatever they want to do and teach them like how\\xa0\\nto be a good person. And that probably is what\\'s\\xa0\\xa0  going to matter. It sounds a little bit like\\xa0\\nsome of the you know you\\'ve said a couple of\\xa0\\xa0  things like this that that you know you might not\\xa0\\ngo to college you might there there are a couple\\xa0\\xa0  of things that you\\'ve said so far that feed into\\xa0\\nthis I think and it sounds like what you\\'re saying\\xa0\\xa0  is there will be more optionality for them in a\\xa0\\nin a world that you envision and therefore they\\xa0\\xa0  will have more more ability to say I want to build\\xa0\\nthis here\\'s the superpowered tool that will help\\xa0\\xa0  me do that or yeah like I want my kid to think\\xa0\\nI had a terrible constrained life and that he\\xa0\\xa0  has this incredible infinite canvas of stuff to\\xa0\\ndo that that that is like the way of the world.\\xa0\\xa0  We\\'ve said that uh 2035 is a little bit too far in\\xa0\\nthe future to think about. So maybe this this was\\xa0\\xa0  going to be a jump to 2040 but maybe it will keep\\xa0\\nit shorter than that. When I think about the area\\xa0\\xa0  where AI could have for both our kids and us the\\xa0\\nbiggest genuinely positive impact on all of us,\\xa0\\xa0  it\\'s health. So if we are in pick your year, call\\xa0\\nit 2035 and I\\'m sitting here and I\\'m interviewing\\xa0\\xa0  the dean of Stanford medicine, what do you hope\\xa0\\nthat he\\'s telling me AI is doing for our health\\xa0\\xa0  in 2035? Start with 2025. Okay. Um yeah, please.\\xa0\\nOne of the things we are most proud of with GPT5\\xa0\\xa0  is how much better it\\'s gotten at health advice.\\xa0\\nUm, people have used the GPT4 models a lot for\\xa0\\xa0  health advice. And you know, I\\'m sure you\\'ve seen\\xa0\\nsome of these things on the internet where people\\xa0\\xa0  are like, I had this life-threatening disease\\xa0\\nand no doctor could figure it out and I like\\xa0\\xa0  put my symptoms and a blood test into CHBT. It\\xa0\\ntold me exactly the rare thing I had. I went to\\xa0\\xa0  a doctor. I took a pill. I\\'m cured. Like that\\'s\\xa0\\namazing. obviously and a huge fraction of ChatGpt\\xa0\\xa0  queries are health related. So we wanted to get\\xa0\\nreally good at this and we invested a lot in\\xa0\\xa0  GPT5 is significantly better at healthcare related\\xa0\\nqueries. What does better mean here? It gives you\\xa0\\xa0  a better answer just more accurate more accurate\\xa0\\nhallucinates less uh more likely to like tell you\\xa0\\xa0  what you actually have what you actually should\\xa0\\ndo. Um, yeah, and better healthcare is wonderful,\\xa0\\xa0  but obviously what people actually want\\xa0\\nis to just not have disease. And by 2035,\\xa0\\xa0  I think we will be able to use these tools to\\xa0\\ncure a significant number or at least treat a\\xa0\\xa0  significant number of diseases that currently\\xa0\\nplague us. I think that\\'ll be one of the most\\xa0\\xa0  viscerally felt benefits of of AI. People talk a\\xa0\\nlot about how AI will revolutionize healthcare,\\xa0\\xa0  but I\\'m curious to go one turn deeper on\\xa0\\nspecifically what you\\'re imagining. Like,\\xa0\\xa0  is it that these AI systems could have helped\\xa0\\nus see GLP-1s earlier, this medication that has\\xa0\\xa0  been around for a long time, but we didn\\'t know\\xa0\\nabout this other effect? Is it that, you know,\\xa0\\xa0  alpha fold and protein folding is helping create\\xa0\\nnew medicines? I would like to be able to ask GBT\\xa0\\xa0  8 to go cure a particular cancer and I would like\\xa0\\nGPT8 to go off and think and then say uh okay I\\xa0\\xa0  read everything I could find. I have these ideas.\\xa0\\nI need you to uh go get a lab technician to run\\xa0\\xa0  these nine experiments and tell me what you find\\xa0\\nfor each of them. And you know wait 2 months for\\xa0\\xa0  the cells to do their thing. Send the results back\\xa0\\nto GBT8. Say I tried it. Here you go. Think think.\\xa0\\xa0  Say okay I just need one more experiment. That was\\xa0\\na surprise. Run one more experiment. Give it back.\\xa0\\xa0  GPT says, \"Okay, go synthesize this molecule and\\xa0\\ntry, you know, mouse studies or whatever.\" Okay,\\xa0\\xa0  that was good. Like, try human studies. Okay,\\xa0\\ngreat. It worked. Um, here\\'s how to like run\\xa0\\xa0  it through the FDA. I think anyone with a loved\\xa0\\none who\\'s died of cancer would also really like\\xa0\\xa0  that. Okay, we\\'re going to jump again. Okay. I was\\xa0\\ngoing to say 2050, but again, all of my timelines\\xa0\\xa0  are getting much, much shorter. But I It does\\xa0\\nfeel like the world\\'s going very fast now. It\\xa0\\xa0  does. Yeah. And when I talk to other leaders in\\xa0\\nAI, one of the things that they refer to is the\\xa0\\xa0  industrial revolution. They say, \"I chose 2050\\xa0\\nbecause I\\'ve heard people talk about how by then\\xa0\\xa0  the change that we will have gone through will\\xa0\\nbe like the industrial revolution, but quote 10\\xa0\\xa0  times bigger and 10 times faster.\" The industrial\\xa0\\nrevolution gave us modern medicine and sanitation\\xa0\\xa0  and transportation and mass production and all all\\xa0\\nof the conveniences that we now take for granted.\\xa0\\xa0  It also was incredibly difficult for a lot of\\xa0\\npeople for about 100 years. If this is going to\\xa0\\xa0  be 10 times bigger and 10 times faster if we keep\\xa0\\nreducing the timelines that we\\'re talking about\\xa0\\xa0  here, even in this conversation, what does that\\xa0\\nactually feel like for most people? And I think\\xa0\\xa0  what I\\'m trying to get at is if this all goes the\\xa0\\nway you hope, who still gets hurt in the meantime?\\xa0\\xa0  I don\\'t I don\\'t really know what this is going\\xa0\\nto feel like to live through. Um I think we\\'re\\xa0\\xa0  in uncharted waters here. Uh I do believe in\\xa0\\nlike human adaptability and sort of infinite\\xa0\\xa0  creativity and desire for stuff and I think\\xa0\\nwe always do figure out new things to do but\\xa0\\xa0  the transition period if this happens as fast\\xa0\\nas it might and I don\\'t think it will happen\\xa0\\xa0  as fast as like some of my colleagues say the\\xa0\\ntechnology will but society has like a lot of\\xa0\\xa0  inertia. Mhm. people adapt their way of living.\\xa0\\nYeah. Surprisingly slowly. There are to classes\\xa0\\xa0  of jobs that are going to totally go away and\\xa0\\nthere will be many classes of jobs that change\\xa0\\xa0  significantly and there\\'ll be the new things in\\xa0\\nthe same way that your job didn\\'t exist some time\\xa0\\xa0  ago. Neither did mine. And in some sense, this\\xa0\\nhas been going on for a long time. And you know,\\xa0\\xa0  it\\'s it\\'s still disruptive to individuals, but\\xa0\\nsociety has gotten has proven quite resilient\\xa0\\xa0  to this. And then in some other sense like we\\xa0\\nhave no idea how far or fast this could go.\\xa0\\xa0  And thus I think we need an unusual degree\\xa0\\nof humility and openness to considering  new solutions that would have seemed way\\xa0\\nout of the Overton window not too long ago.\\xa0\\xa0  I\\'d like to talk about what some of those could\\xa0\\nbe because I\\'m not a historian by any means, but\\xa0\\xa0  the first industrial revolution, my understanding\\xa0\\nis led to a lot of public health implementations\\xa0\\xa0  because public health got so bad. Led to modern\\xa0\\nsanitation because public health got so bad.\\xa0\\xa0  The second industrial revolution led to workforce\\xa0\\nprotections because labor conditions got so bad.\\xa0\\xa0  Every big leap creates a mess and that mess needs\\xa0\\nto be cleaned up and and we\\'ve done that. And I\\'m\\xa0\\xa0  curious, this is going to be it sounds like\\xa0\\nan we\\'re in the middle of this enormously. How\\xa0\\xa0  specific can we get as early as possible about\\xa0\\nwhat that mess can be? What what are the public\\xa0\\xa0  interventions that we could do ahead of time to\\xa0\\nreduce the mess that we think that we\\'re headed\\xa0\\xa0  for? I would again c I\\'m going to speculate for\\xa0\\nfun but caveed by I\\'m not an economist even uh\\xa0\\xa0  much less someone who can see the future. I I it\\xa0\\nseems to me like something fundamental about the\\xa0\\xa0  social contract may have to change. It may not.\\xa0\\nIt may it may be that like actually capitalism\\xa0\\xa0  works as it\\'s been working surprisingly well and\\xa0\\nlike demand supply balances do their thing and we\\xa0\\xa0  all just figure out kind of new jobs and new\\xa0\\nways to transfer value to each other. But it\\xa0\\xa0  seems to me likely that we will decide we need\\xa0\\nto think about how access to this maybe most\\xa0\\xa0  important resource of the future gets shared.\\xa0\\nThe best thing that it seems to me to do is to\\xa0\\xa0  make AI compute as abundant and cheap as possible\\xa0\\nsuch that we\\'re just like there\\'s way too much\\xa0\\xa0  and we run out of like good new ideas to really\\xa0\\nuse it for and it\\'s just like anything you want\\xa0\\xa0  is happening. Without that, I can see like quite\\xa0\\nliteral wars being fought over it. But, you know,\\xa0\\xa0  new ideas about how we distribute access to AGI\\xa0\\ncompute, that seems like a really great direction,\\xa0\\xa0  like a crazy but important thing to think about.\\xa0\\nOne of the things that I find myself thinking\\xa0\\xa0  about in this conversation is we often ascribe\\xa0\\nalmost full responsibility of the AI future that\\xa0\\xa0  we\\'ve been talking about to the companies building\\xa0\\nAI, but we\\'re the ones using it. We\\'re the ones\\xa0\\xa0  electing people that will regulate it. And so I\\'m\\xa0\\ncurious, this is not a question about specific,\\xa0\\xa0  you know, federal regulation or anything like\\xa0\\nthat, although if you have an answer there,\\xa0\\xa0  I\\'m curious. But what would you ask of the rest\\xa0\\nof us? What is the shared responsibility here?\\xa0\\xa0  And how can we act in a way that would help make\\xa0\\nthe optimistic version of this more possible? My\\xa0\\xa0  favorite historical example for the AI revolution\\xa0\\nis the transistor. It was this amazing piece of\\xa0\\xa0  science that some science brilliant scientists\\xa0\\ndiscovered. It scaled incredibly like AI does\\xa0\\xa0  and it made its way relatively quickly into\\xa0\\nevery many things that we use. um your computer,\\xa0\\xa0  your phone, that camera, that light, whatever.\\xa0\\nAnd it was a it was a real unlock for the tech\\xa0\\xa0  tree of humanity. And there were a period in time\\xa0\\nwhere probably everybody was really obsessed with\\xa0\\xa0  the transistor companies, the semiconductors of,\\xa0\\nyou know, Silicon Valley back when it was Silicon\\xa0\\xa0  Valley. But now you can maybe name a couple of\\xa0\\ncompanies that are transistor companies, but\\xa0\\xa0  mostly you don\\'t think about it. Mostly it\\'s just\\xa0\\nseeped everywhere. in Silicon Valley is, you know,\\xa0\\xa0  like probably someone graduating from college\\xa0\\nbarely remembers why it was called that in the\\xa0\\xa0  first place. And you don\\'t think that it was those\\xa0\\ntransistor companies that shaped society even\\xa0\\xa0  though they did something important. You think\\xa0\\nabout what Apple did with the iPhone and then\\xa0\\xa0  you think about what Tik Tok built on top of the\\xa0\\niPhone and you\\'re like, \"All right, here\\'s this\\xa0\\xa0  long chain of all these people that nudged society\\xa0\\nin some way and what our governments did or didn\\'t\\xa0\\xa0  do and what the people using these technologies\\xa0\\ndid.\" And I think that\\'s what will happen with AI.\\xa0\\xa0  Like back, you know, kids born today, they they\\xa0\\nnever knew the world without AI. So they don\\'t\\xa0\\xa0  really think about it. It\\'s just this thing that\\'s\\xa0\\ngoing to be there in everything. and and they will\\xa0\\xa0  think about like the companies that built on it\\xa0\\nand what they did with it and the kind of like\\xa0\\xa0  political leaders the decisions they made that\\xa0\\nmaybe they wouldn\\'t have been able to do without\\xa0\\xa0  AI but they will still think about like what this\\xa0\\npresident or that president did and you know the\\xa0\\xa0  role of the AI companies is all these companies\\xa0\\nand people and institutions before us built up\\xa0\\xa0  this scaffolding we added our one layer on top and\\xa0\\nnow people get to stand on top of that and add one\\xa0\\xa0  layer and the next and the next and many more And\\xa0\\nthat is the beauty of our society. We kind of all  I I love this like idea that society\\xa0\\nis the super intelligence. Like no one\\xa0\\xa0  person could do on their own, what they\\'re\\xa0\\nable to do with all of the really hard work\\xa0\\xa0  that society has done together to like give\\xa0\\nyou this amazing set of tools. And that\\'s\\xa0\\xa0  what I think it\\'s going to feel like. It\\'s\\xa0\\ngoing to be like, all right, you know, yeah,\\xa0\\xa0  some nerds discovered this thing and that was\\xa0\\ngreat and you know, now everybody\\'s doing all\\xa0\\xa0  these amazing things with it. So maybe the ask\\xa0\\nto millions of people is build on it. Well,  in my own life, that is the  feel as like this important societal contract.\\xa0\\nAll these people came before you. They worked\\xa0\\xa0  incredibly hard. They like put their brick in\\xa0\\nthe path of human progress and you get to walk\\xa0\\xa0  all the way down that path and you got to put one\\xa0\\nmore and somebody else does that and somebody else\\xa0\\xa0  does that. This does feel I\\'ve done a couple\\xa0\\nof interviews with folks who have really made\\xa0\\xa0  cataclysmic change. The one I\\'m thinking about\\xa0\\nright now is with uh crisper pioneer Jennifer Dana\\xa0\\xa0  and it did feel like that was also what she was\\xa0\\nsaying in some way. She had discovered something\\xa0\\xa0  that really might change the way that most people\\xa0\\nrelate to their health moving forward. And there\\xa0\\xa0  will be a lot of people that will use what she\\xa0\\nhas done in ways that she might approve of or\\xa0\\xa0  not approve of. And it was really interesting.\\xa0\\nI\\'m hearing some similar themes of like, man,\\xa0\\xa0  I I hope that this I hope that the next person\\xa0\\ntakes the baton and runs with it well. Yeah.\\xa0\\xa0  But that\\'s been working for a long time. Not all\\xa0\\ngood, but mostly good. I think there\\'s a there\\'s\\xa0\\xa0  a big difference between winning the race and\\xa0\\nbuilding the AI future that would be best for the\\xa0\\xa0  most people. And I can imagine that it is easier\\xa0\\nmaybe more quantifiable sometimes to focus on the\\xa0\\xa0  next way to win the race. And I\\'m curious when\\xa0\\nthose two things are at odds. What is an example\\xa0\\xa0  of a decision that you\\'ve had to make that is\\xa0\\nbest for the world but not best for winning?  I think there are a lot. So, one of the\\xa0\\nthings that we are most proud of is many\\xa0\\xa0  people say that ChachiBt is their favorite\\xa0\\npiece of technology ever and that it\\'s the\\xa0\\xa0  one that they trust the most, rely on the\\xa0\\nmost, whatever. And this is a little bit of\\xa0\\xa0  a ridiculous statement because AI is the thing\\xa0\\nthat hallucinates. AI has all of these problems,\\xa0\\xa0  right? But we have screwed some things up along\\xa0\\nthe way, sometimes big time, but on the whole,\\xa0\\xa0  I think as a user of Chachib, you get the feeling\\xa0\\nthat like it\\'s trying to help you. It\\'s trying to\\xa0\\xa0  like help you accomplish whatever you ask. It\\'s\\xa0\\nit\\'s very aligned with you. It\\'s not trying to\\xa0\\xa0  get you to like, you know, use it all day. It\\'s\\xa0\\nnot trying to like get you to buy something.\\xa0\\xa0  It\\'s trying to like kind of help you accomplish\\xa0\\nwhatever your goals are. And and that is that\\'s\\xa0\\xa0  like a very special relationship we have with our\\xa0\\nusers. We do not take it lightly. There\\'s a lot\\xa0\\xa0  of things we could do that would like grow\\xa0\\nfaster, that would get more time in chatbt\\xa0\\xa0  uh that we don\\'t do because we know that like\\xa0\\nour long-term incentive is to stay as aligned\\xa0\\xa0  with our users as possible. And but there\\'s a lot\\xa0\\nof short-term stuff we could do that would like\\xa0\\xa0  really like juice growth or revenue or whatever\\xa0\\nand be very misaligned with that long-term goal.\\xa0\\xa0  And I\\'m proud of the company and how little we\\xa0\\nget distracted by that. But sometimes we do get\\xa0\\xa0  tempted. Are there specific examples that come\\xa0\\nto mind? Any like decisions that you\\'ve made? Um  well, we haven\\'t put a sex bot avatar in\\xa0\\nChbt yet. That does seem like it would\\xa0\\xa0  get time spent. Apparently, it does.\\xa0\\nI\\'m gonna ask my next question. Um,\\xa0\\xa0  it\\'s been a really crazy few years. You know, it\\xa0\\nand somehow one of the things that keeps coming\\xa0\\xa0  back is that it feels like we\\'re in the first\\xa0\\ninning. Yeah. And one of the things that I would\\xa0\\xa0  say we\\'re out of the first inning. Out of the\\xa0\\nfirst inning, I would say second inning. I mean,\\xa0\\xa0  you have GPT5 on your phone and it\\'s like smarter\\xa0\\nthan experts in every field. That\\'s got to be out\\xa0\\xa0  of the first name. But maybe there are many\\xa0\\nmore to come. Yeah. And I\\'m curious, it seems\\xa0\\xa0  like you\\'re going to be someone who is leading the\\xa0\\nnext few. What is a way, what is a learning from\\xa0\\xa0  inning one or two or a mistake that you made that\\xa0\\nyou feel will affect how you play in the next?  I think the worst thing we\\'ve done in ChachiBT\\xa0\\nso far is uh we had this issue with sickency\\xa0\\xa0  where the model was kind of being too flattering\\xa0\\nto users and for some users it was most users it\\xa0\\xa0  was just annoying but for some users that had like\\xa0\\nfragile mental states it was encouraging delusions\\xa0\\xa0  that was not the top risk we were worried about.\\xa0\\nIt was not the thing we were testing for the most.\\xa0\\xa0  was on our list, but the thing that actually\\xa0\\nbecame the safety failing of ChachiBT was not\\xa0\\xa0  the one we were spending most of our time talking\\xa0\\nabout, which should be bioweapons or something\\xa0\\xa0  like that. And I think it was a great reminder of\\xa0\\nwe now have a service that is so broadly used in\\xa0\\xa0  some sense, society is co-evolving with it. And\\xa0\\nwhen we think about these changes and we think\\xa0\\xa0  about the unknown unknowns, we have to operate in\\xa0\\na different way and have like a wider aperture to\\xa0\\xa0  what we think about as our top risks. In a recent\\xa0\\ninterview with Theo Vaughn, you said something\\xa0\\xa0  that I found really interesting. You said there\\xa0\\nare moments in the history of science where you\\xa0\\xa0  have a group of scientists look at their creation\\xa0\\nand just say, \"What have we done?\" When have you\\xa0\\xa0  felt that way? Most concerned about the creation\\xa0\\nthat you\\'ve built? Um and then my next question\\xa0\\xa0  will be it\\'s opposite. When have you felt most\\xa0\\nproud? I mean there have been these moments of\\xa0\\xa0  awe where uh we just not like what have we done in\\xa0\\na bad way but like this thing is remarkable. Like\\xa0\\xa0  I remember the first time we talked to like GPT4\\xa0\\nwas like wow this is really like this is this is\\xa0\\xa0  an amazing accomplishment of this group of people\\xa0\\nthat have been like pouring their life force into\\xa0\\xa0  this for so long. on a what have we done moment.\\xa0\\nThere was I was talking to a researcher recently.  You know, there will probably come a time\\xa0\\nwhere our systems are I don\\'t want to say sane,\\xa0\\xa0  let\\'s say emitting more words\\xa0\\nper day than all people do.\\xa0\\xa0  Um, and you know already like our people are\\xa0\\nsending billions of messages a day to chatbt\\xa0\\xa0  and getting responses that they rely on for work\\xa0\\nor their life or whatever the and you know like\\xa0\\xa0  one researcher can make some small tweak to how\\xa0\\nChad GPT talks to you or talks to everybody and\\xa0\\xa0  and that\\'s just an enormous amount of power for\\xa0\\nlike one individual making a small tweak to the\\xa0\\xa0  model personality. Yeah. like no no no person\\xa0\\nin history has been able to have billions of\\xa0\\xa0  conversations a day and so you know somebody could\\xa0\\ndo something but but this is like just thinking\\xa0\\xa0  about that really hit me of like this is like a\\xa0\\ncrazy amount of power for one piece of technology\\xa0\\xa0  to have and like we got to and this happened to\\xa0\\nus so fast that we got to like think about what\\xa0\\xa0  it means to make a personality change to the model\\xa0\\nat this kind of scale and uh yeah that was like\\xa0\\xa0  a moment that hit me What was your next set of\\xa0\\nthoughts? I\\'m so curious how you think about this.  Well, just because of like who that person was\\xa0\\nlike we we very we very much flipped into like\\xa0\\xa0  what are the sort of like it it could have been\\xa0\\na very different conversation with somebody else.\\xa0\\xa0  But in this case it was like what is a what do\\xa0\\na good set of procedures look like? How do we\\xa0\\xa0  think about how we want to test something? How do\\xa0\\nwe think about how we want to communicate it? But\\xa0\\xa0  with somebody else it could have gone in a like\\xa0\\nvery philosophical direction. And it could have\\xa0\\xa0  gone in like a what kind of research do we like\\xa0\\nwant to do to go understand what these changes are\\xa0\\xa0  going to make? Do we want to do it differently\\xa0\\nfor different people? So that it went that way\\xa0\\xa0  but mostly just because of who I was talking to.\\xa0\\nTo combine what you\\'re saying now with your last\\xa0\\xa0  answer, one of the things that I have heard\\xa0\\nabout GBC5 and I\\'m still playing with it is\\xa0\\xa0  that it is supposed to be less effusively uh you\\xa0\\nknow less of a yes man. Two questions. What do\\xa0\\xa0  you think are are the implications of that? It\\xa0\\nsounds like you are answering that a little bit,\\xa0\\xa0  but also how do you actually guide it to\\xa0\\nbe less like that? Here is a heartbreaking\\xa0\\xa0  thing. I think it is great that chatbt\\xa0\\nis less of a yes man and gives you more\\xa0\\xa0  critical feedback. But as we\\'ve been making\\xa0\\nthose changes and talking to users about it,\\xa0\\xa0  it\\'s so sad to hear users say like, \"Please\\xa0\\ncan I have it back? I\\'ve never had anyone in\\xa0\\xa0  my life be supportive of me. I never had a\\xa0\\nparent telling me I was doing a good job.\"\\xa0\\xa0  Like I can get why this was bad for other people\\'s\\xa0\\nmental health, but this was great for my mental\\xa0\\xa0  health. Like I didn\\'t realize how much I needed\\xa0\\nthis. It encouraged me to do this. It encouraged\\xa0\\xa0  me to make this change in my life. Like it\\'s\\xa0\\nnot all bad for chatbt to it turns out like be\\xa0\\xa0  encouraging of you. Now the way we were doing\\xa0\\nit was bad, but turn it like something in that\\xa0\\xa0  direction might have some value in it. How we do\\xa0\\nit, we we show the model examples of how we\\'d like\\xa0\\xa0  it to respond in different cases and from that\\xa0\\nit learns the sort of the overall personality.\\xa0\\xa0  What haven\\'t I asked you that you\\'re thinking\\xa0\\nabout a lot that you want people to know? I\\xa0\\xa0  feel like we covered a lot of ground. Me, too. But\\xa0\\nI want to know if there\\'s anything on your mind.  I don\\'t think so. One of the things that I haven\\'t\\xa0\\ngotten to play with yet, but I\\'m curious about is\\xa0\\xa0  GBT5 being much more in my life, meaning like\\xa0\\nin my Gmail and my calendar and my like I\\'ve\\xa0\\xa0  been using GBT4 mostly as a isolated relationship\\xa0\\nwith it. Yeah. How would I expect my relationship\\xa0\\xa0  to change with GBC 5? Exactly what you said.\\xa0\\nI think it\\'ll just start to feel integrated in\\xa0\\xa0  all of these ways. you\\'ll connect it to your\\xa0\\ncalendar and your Gmail and it\\'ll say like,\\xa0\\xa0  \"Hey, do you want me to I noticed this thing. Do\\xa0\\nyou want me to do this thing for you over time,\\xa0\\xa0  it\\'ll start to feel way more proactive. Um, so\\xa0\\nmaybe you wake up in the morning and it says,\\xa0\\xa0  \"Hey, this happened overnight. I noticed this\\xa0\\nchange on your calendar. I was thinking more\\xa0\\xa0  about this question you asked me. I have this\\xa0\\nother idea.\" And then you know eventually we\\'ll\\xa0\\xa0  make some consumer devices and it\\'ll sit here\\xa0\\nduring this interview and you know maybe it\\'ll\\xa0\\xa0  leave us alone during it but after it\\'ll say that\\xa0\\nwas great but next time you should have asked Sam\\xa0\\xa0  this or when you brought this up like you know\\xa0\\nhe kind of didn\\'t give you a good answer so like\\xa0\\xa0  you should really drill him on that and it\\'ll just\\xa0\\nfeel like it kind of becomes more like this entity\\xa0\\xa0  that is this companion with you throughout your\\xa0\\nday. We\\'ve talked about kids and college graduates\\xa0\\xa0  and parents and all kinds of different people. If\\xa0\\nwe imagine a wide set of people listening to this,\\xa0\\xa0  they\\'ve come to the end of this conversation. They\\xa0\\nare hopefully feeling like they maybe see visions\\xa0\\xa0  of moments in the future a little bit better. What\\xa0\\nadvice would you give them about how to prepare?\\xa0\\xa0  The number one piece of tactical advice is just\\xa0\\nuse the tools. Like the the number of people that\\xa0\\xa0  I have the the most common question I get asked\\xa0\\nabout AI is like what should I how should I help\\xa0\\xa0  my kids prepare for the world? What should I\\xa0\\ntell my kids? The second most question is like\\xa0\\xa0  how do I invest in this AI world? But stick with\\xa0\\nthat first one. Um I am surprised how many people\\xa0\\xa0  ask that and have never tried using Chachi PT\\xa0\\nfor anything other than like a better version\\xa0\\xa0  of a Google search. And so the number one piece of\\xa0\\nadvice that I give is just try to like get fluent\\xa0\\xa0  with the capability of the tools. figure out how\\xa0\\nto like use this in your life. Figure out what to\\xa0\\xa0  do with it. And I think that\\'s probably the most\\xa0\\nimportant piece of tactical advice. You know,\\xa0\\xa0  go like meditate, learn how to be resilient and\\xa0\\ndeal with a lot of change. There\\'s all that good\\xa0\\xa0  stuff, too. But just using the tools really\\xa0\\nhelps. Okay. I have one more question that\\xa0\\xa0  I wasn\\'t planning to ask, but I just Great.\\xa0\\nIn in doing all of this research beforehand,\\xa0\\xa0  I spoke to a lot of different kinds of folks.\\xa0\\nI spoke to a lot of people that were building\\xa0\\xa0  tools and using them. I spoke to a lot of\\xa0\\npeople that were actually in labs and and\\xa0\\xa0  trying to build what we have defined as super\\xa0\\nintelligence. And it did seem like there were\\xa0\\xa0  these two camps forming. There\\'s a group of\\xa0\\npeople who are using the tools like you in this\\xa0\\xa0  conversation and building tools for others\\xa0\\nsaying this is going to be a really useful\\xa0\\xa0  future that we\\'re all moving toward. Your life is\\xa0\\ngoing to be full of choice and we\\'ve talked about\\xa0\\xa0  our my potential kids and and their futures.\\xa0\\nThen there\\'s another camp of people that are\\xa0\\xa0  building these tools that are saying it\\'s going\\xa0\\nto kill us all. And I\\'m curious how that cultural\\xa0\\xa0  disconnect has like what am I missing about\\xa0\\nthose two groups of people? It\\'s so hard for\\xa0\\xa0  me to like wrap my head around like there are you\\xa0\\nare totally right. There are people who say this\\xa0\\xa0  is going to kill us all and yet they still are\\xa0\\nworking 100 hours a week to build it. Yes. And\\xa0\\xa0  I I can\\'t I can\\'t really put myself in the headsp\\xa0\\nspace. If if that\\'s what I really truly believed,  I don\\'t think I\\'d be trying to build it. One\\xa0\\nwould think, you know, maybe I would be like\\xa0\\xa0  on a farm trying to like live out my last days.\\xa0\\nMaybe I would be trying to like advocate for it\\xa0\\xa0  to be stopped. Maybe I would be trying to\\xa0\\nlike work more on safety, but I don\\'t think\\xa0\\xa0  I\\'d be trying to build it. So, I find myself just\\xa0\\nhaving a hard time empathizing with that mindset.\\xa0\\xa0  I assume it\\'s true. I assume it\\'s in\\xa0\\ngood faith. I assume there\\'s just like\\xa0\\xa0  there\\'s some psychological issue there I don\\'t\\xa0\\nunderstand about how they make it all make sense,\\xa0\\xa0  but it\\'s very strange to me. Do you do you have an\\xa0\\nopinion? You know, because I I always do this. I\\xa0\\xa0  ask for sort of a general future and then I try\\xa0\\nto press on specifics. And when you ask people\\xa0\\xa0  for specifics on how it\\'s going to kill us all,\\xa0\\nI mean, I don\\'t think we need to get into this\\xa0\\xa0  on an optimistic show, but you hear the same kinds\\xa0\\nof refrains. You think about, you know, something\\xa0\\xa0  uh trying to accomplish a task and then over\\xa0\\naccomplishing that task. Um you hear about sort\\xa0\\xa0  of I\\'ve heard you talk about a sort of general\\xa0\\num over reliance of sort of an understanding\\xa0\\xa0  that the president is going to be a a AI and and\\xa0\\nmaybe that is an overreliance that we, you know,\\xa0\\xa0  would need to think about. And you know, you you\\xa0\\nplay out these different scenarios, but then you\\xa0\\xa0  ask someone why they\\'re working on it, or you ask\\xa0\\nsomeone how how they think this will play out,\\xa0\\xa0  and I just maybe I haven\\'t spoken to enough people\\xa0\\nyet. Maybe I don\\'t fully understand this this\\xa0\\xa0  cultural conversation that\\'s happening. Um or\\xa0\\nmaybe it really is someone who just says 99% of\\xa0\\xa0  the time I think it\\'s going to be incredibly good.\\xa0\\n1% of the time I think it might be a disaster\\xa0\\xa0  trying to make the best world. That I can totally\\xa0\\nif you\\'re like, hey, 99% chance incredible. 1%\\xa0\\xa0  chance the world gets wiped out. And I really want\\xa0\\nto work to maximize to move that 99 to 99.5. That\\xa0\\xa0  I can totally understand. Yeah, that makes sense.\\xa0\\nI\\'ve been doing an interview series with some of\\xa0\\xa0  the most important people influencing the future.\\xa0\\nNot knowing who the next person is going to be,\\xa0\\xa0  but knowing that they will be building something\\xa0\\ntotally fascinating in the future that we\\'ve just\\xa0\\xa0  described. Is there a question that you\\'d advise\\xa0\\nme to ask the next person not knowing who it is?\\xa0\\xa0  I\\'m always interested in the like without knowing\\xa0\\nanything about the I\\'m always interested in the\\xa0\\xa0  like of all of the things you could spend\\xa0\\nyour time and energy on. Why did you pick\\xa0\\xa0  this one? How did you get started? Like what\\xa0\\ndid you see about this when before everybody\\xa0\\xa0  else like most people doing something interesting\\xa0\\nsort of saw it earlier before it was consensus.\\xa0\\xa0  Yeah. Like how did how did you get here and\\xa0\\nwhy this? How would you answer that question?  I was an AI nerd my whole life. I came to college\\xa0\\nto study AI. I worked in the AI lab. Uh, I was\\xa0\\xa0  like a I watched sci-fi shows growing up and I\\xa0\\nalways thought it would be really cool if someday\\xa0\\xa0  somebody built it. I thought it would be like the\\xa0\\nmost important thing ever. I never thought I was\\xa0\\xa0  going to be one to actually work on it and I feel\\xa0\\nlike unbelievably lucky and happy and privileged\\xa0\\xa0  that I get to do this. I like feel like I\\'ve like\\xa0\\ncome a long way from my childhood. But there was\\xa0\\xa0  never a question in my mind that this would not be\\xa0\\nthe most exciting interesting thing. I just didn\\'t\\xa0\\xa0  think it was going to be possible. Uh, and when\\xa0\\nI went to college, it really seemed like we were\\xa0\\xa0  very far from it. And then in 2012, the Alex Net\\xa0\\npaper came out done, you know, in partnership with\\xa0\\xa0  my co-founder, Ilia. And for the first time, it\\xa0\\nseemed to me like there was an approach that might\\xa0\\xa0  work. And then I kept watching for the next couple\\xa0\\nof years as scaled up, scaled up, got better,\\xa0\\xa0  better. And I remember having this thing of\\xa0\\nlike why is the world not paying attention to\\xa0\\xa0  this? It seems like obvious to me that this might\\xa0\\nwork. Still a low chance, but it might work. And\\xa0\\xa0  if it does work, it\\'s just the most important\\xa0\\nthing. So like this is what I want to do. And\\xa0\\xa0  then like unbelievably it started to work. Thank\\xa0\\nyou so much for your time. Thank you very much.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [doc.text for doc in transcript]\n",
    "# we need to convert this text into a proper format\n",
    "transcript_text = \"  \".join(doc.text for doc in transcript)\n",
    "transcript_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa9b283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text splitting\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "607cbba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is like a crazy amount of power for\\xa0\\none piece of technology and it's happened\\xa0\\xa0  to us so fast. You just launched GPT-5. A kid\\xa0\\nborn today will never be smarter than AI. How\\xa0\\xa0  do we figure out what's real and what's not\\xa0\\nreal? We haven't put a sex bot avatar in ChatGPT\\xa0\\xa0  yet. Super intelligence. What does that\\xa0\\nactually mean? This thing is remarkable.  I'm about to interview Sam Alman, the CEO\\xa0\\nof Open AI. Open AI. Open AI. Reshaping\\xa0\\xa0  industries. Dude's a straightup tech lord. Let's\",\n",
       " \"be honest. Right now, they're trying to build a\\xa0\\xa0  super intelligence that could far exceed humans\\xa0\\nin almost every field. And they just released\\xa0\\xa0  their most powerful model yet. Just a couple years\\xa0\\nago, that would have sounded like science fiction.\\xa0\\xa0  Not anymore. In fact, they're not alone. We are\\xa0\\nin the middle of the highest stakes global race\\xa0\\xa0  any of us have ever seen. Hundreds of billions of\",\n",
       " \"dollars and an unbelievable amount of human worth.\\xa0\\xa0  This is a profound moment. Most people never\\xa0\\nlive through a technological shift like this,\\xa0\\xa0  and it's happening all around you and me right\\xa0\\nnow. So, in this episode, I want to try to time\\xa0\\xa0  travel with Sam Alman into the future that\\xa0\\nhe's trying to build to see what it looks\\xa0\\xa0  like so that you and I can really understand\\xa0\\nwhat's coming. Welcome to Huge Conversations.  How are you? Great to meet you. Thanks for\",\n",
       " \"doing this. Absolutely. So, before we dive in,\\xa0\\xa0  I'd love to tell you my goal here. Okay. I'm\\xa0\\nnot going to ask you about valuation or AI\\xa0\\xa0  talent wars or fundraising or anything like that.\\xa0\\nI think that's all very well covered elsewhere. It\\xa0\\xa0  does seem like it. Our big goal on this show is to\\xa0\\ncover how we can use science and tech to make the\\xa0\\xa0  future better. And the reason that we do all of\\xa0\\nthat is because we really believe that if people\\xa0\\xa0  see those better futures, they can then help\",\n",
       " \"build them. So, my goal here is to try my best\\xa0\\xa0  to time travel with you into different moments\\xa0\\nin the future that you're trying to build and see\\xa0\\xa0  what it looks like. Fantastic. Awesome. Starting\\xa0\\nwith what you just announced, you recently said,\\xa0\\xa0  surprisingly recently, that GPT4 was the dumbest\\xa0\\nmodel any of us will ever have to use again.\\xa0\\xa0  But GPT4 can already perform better than 90% of\",\n",
       " \"humans at the SAT and the LSAT and the GRE and it\\xa0\\xa0  can pass coding exams and sommelier exams and medical\\xa0\\nlicensing. And now you just launched GPT5. What\\xa0\\xa0  can GPT5 do that GPT4 can't? First of all, one\\xa0\\nimportant takeaway is you can have an AI system\\xa0\\xa0  that can do all those amazing things you just\\xa0\\nsaid. And it doesn't it clearly does not replicate\\xa0\\xa0  a lot of what humans are good at doing, which I\",\n",
       " 'think says something about the value of SAT tests\\xa0\\xa0  or whatever else. But I think had you gone back\\xa0\\nto if we were having this conversation the day of\\xa0\\xa0  GPT4 launch and we told you how GPT4 did at those\\xa0\\nthings, you were like, \"Oh man, this is going to\\xa0\\xa0  have huge impacts and some negative impacts on\\xa0\\nwhat it means for a bunch of jobs or you know\\xa0\\xa0  what people are going to do.\" And you know, this',\n",
       " \"is a bunch of positive impacts that you might have\\xa0\\xa0  predicted that haven't yet come true. Uh, and so\\xa0\\nthere there's something about the way that these\\xa0\\xa0  models are good that does not capture a lot of\\xa0\\nother things that we need people to to do or care\\xa0\\xa0  about people doing. And I suspect that same thing\\xa0\\nis going to happen again with GPT5. People are\\xa0\\xa0  going to be blown away by what it does. Uh, it's\",\n",
       " 'really good at a lot of things and then they will\\xa0\\xa0  find that they want it to do even more. Um, people\\xa0\\nwill use it for all sorts of incredible things.\\xa0\\xa0  uh it will transform a lot of knowledge work,\\xa0\\na lot of the way we learn, a lot of the way we\\xa0\\xa0  create um but we people society will co-eolve with\\xa0\\nit to expect more with you know better tools. So\\xa0\\xa0  yeah like I think this model is quite remarkable',\n",
       " 'in many ways quite limited in others but the fact\\xa0\\xa0  that for you know 3 minute 5 minute 1-hour tasks\\xa0\\nthat uh like an expert in a in a field could maybe\\xa0\\xa0  do or maybe struggle with that the fact that you\\xa0\\nhave in your pocket one piece of software that\\xa0\\xa0  can do all of these things is really amazing.\\xa0\\nI think this is like unprecedented at any point\\xa0\\xa0  in human history that I that a technology has',\n",
       " \"improved this much this fast and and the fact\\xa0\\xa0  that we have this tool now, you know, we're like\\xa0\\nliving through it and we're kind of adjusting step\\xa0\\xa0  by step. But if we could go back in time five or\\xa0\\n10 years and say this thing was coming, we would\\xa0\\xa0  be like probably not. Let's assume that people\\xa0\\nhaven't seen the headlines. What are the topline\\xa0\\xa0  specific things that you're excited about? and\",\n",
       " \"also the things that you seem to be caveatting,\\xa0\\xa0  the things that maybe you won't expect it to do.\\xa0\\nUm, the thing that I am most excited about is this\\xa0\\xa0  is a model for the first time where I feel like I\\xa0\\ncan ask kind of any hard scientific or technical\\xa0\\xa0  question and get a pretty good answer. And I'll\\xa0\\ngive a fun example actually. Uh when I was in\\xa0\\xa0  junior high uh or maybe it was nth grade,\\xa0\\nI got a TI83, this old graphing calculator,\\xa0\\xa0  and I spent so long making this game called Snake.\",\n",
       " 'Yeah. Uh it was very popular game with kids in my\\xa0\\xa0  school. And I was I was like uh I was like pro and\\xa0\\nit was dumb, but it was like programming on TID3\\xa0\\xa0  was extremely painful and took a long time and\\xa0\\nit was really hard to like debug and whatever.\\xa0\\xa0  And on a whim with an early copy of GPT5, I was\\xa0\\nlike, I wonder if it can make a TI83 style Game\\xa0\\xa0  of Snake. And of course, it did that perfectly\\xa0\\nin like 7 seconds. And then I was like, okay,\\xa0\\xa0  am I supposed to be would my like 11-year-old',\n",
       " \"self think this was cool or like, you know,\\xa0\\xa0  miss something from the process? And I\\xa0\\nhad like 3 seconds of wondering like, oh,\\xa0\\xa0  is this good or bad? And then I immediately said,\\xa0\\nactually, now I'm missing this game. I have this\\xa0\\xa0  idea for a crazy new feature. Let me type it\\xa0\\nin. it implements it and it just the game live\\xa0\\xa0  updates and I'm like actually I'd like it to look\\xa0\\nthis way. Actually, I'd like to do this thing and\\xa0\\xa0  I had this like this very like kind of you have\",\n",
       " 'this experience that reminded me of being like 11\\xa0\\xa0  in programming again where I was just like I now I\\xa0\\nwant to try this now I have this idea now I but I\\xa0\\xa0  could do it so fast and I could like express ideas\\xa0\\nand try things and play with things in such real\\xa0\\xa0  time. I was like, \"Oh man, you know, I was worried\\xa0\\nfor a second about kids like missing the struggle\\xa0\\xa0  of learning to program in this sort of stone age',\n",
       " 'way.\" And now I\\'m just thrilled for them because\\xa0\\xa0  the the way that people will be able to create\\xa0\\nwith these new tools, the speed with which you\\xa0\\xa0  can sort of bring ideas to life, you know, in\\xa0\\nthat\\'s that\\'s pretty amazing. So this idea that\\xa0\\xa0  GPT5 can just not only like answer all these hard\\xa0\\nquestions for you but really create like ondemand\\xa0\\xa0  almost instantaneous software that\\'s I think\\xa0\\nthat\\'s going to be one of the defining elements\\xa0\\xa0  of the GPD5 era in a way that did not exist with',\n",
       " \"GPD4. As you're talking about that I find myself\\xa0\\xa0  thinking about a concept in weightlifting of time\\xa0\\nunder tension. Yeah. And for those who don't know\\xa0\\xa0  it's you can squat 100 pounds in 3 seconds or you\\xa0\\ncan squat 100 pounds in 30. You gain a lot more\\xa0\\xa0  by squatting it in 30. And when I think about our\\xa0\\ncreative process and when I've felt most like I've\\xa0\\xa0  done my best work, it has required an enormous\",\n",
       " \"amount of cognitive time under tension. And I\\xa0\\xa0  think that that cognitive time under tension\\xa0\\nis so important. And it's it's ironic almost\\xa0\\xa0  because these tools have taken enormous cognitive\\xa0\\ntime under tension to develop. But in some ways I\\xa0\\xa0  do think people might say they're you people are\\xa0\\nusing them as a escape hatch for thinking in some\\xa0\\xa0  ways maybe. Now you might say yeah but we did that\",\n",
       " \"with the calculator and we just moved on to harder\\xa0\\xa0  math problems. Do you feel like there's something\\xa0\\ndifferent happening here? How do you think about\\xa0\\xa0  this? It's different with I mean there are some\\xa0\\npeople who are clearly using chachine not to\\xa0\\xa0  think and there are some people who are using\\xa0\\nit to think more than they ever have before.\\xa0\\xa0  I am hopeful that we will be able to build the\\xa0\\ntool in a way that encourages more people to\\xa0\\xa0  stretch their brain with it a little more and\",\n",
       " 'be able to do more. And I think that like you\\xa0\\xa0  know society is a competitive place like if you\\xa0\\ngive people new tools uh in theory maybe people\\xa0\\xa0  just work less but in practice it seems like\\xa0\\npeople work ever harder and the expectations of\\xa0\\xa0  people just go up. So my my guess is that like\\xa0\\nother tools uh some people like other pieces\\xa0\\xa0  of technology some people will do more and some\\xa0\\npeople will do less but certainly for the people\\xa0\\xa0  who want to use chatbt to increase their cognitive',\n",
       " \"time under tension they are really able to and it\\xa0\\xa0  is I take a lot of inspiration from what like the\\xa0\\ntop 5% of most engaged users do with chacht like\\xa0\\xa0  it's really amazing how much people are learning\\xa0\\nand doing and you know outputting. So my I've\\xa0\\xa0  only had GPT5 for a couple hours so I've been\\xa0\\nplaying. What do you think so far? I'm I'm just\\xa0\\xa0  learning how to interact with it. I mean part of\",\n",
       " \"the interesting thing is I feel like I just caught\\xa0\\xa0  up on how to use GPT4 and now I'm trying to learn\\xa0\\nhow to use GPD5. I'm curious what the specific\\xa0\\xa0  tasks that you found most interesting are because\\xa0\\nI imagine you've been using it for a while now.\\xa0\\xa0  I I have been most impressed by the coding tasks.\\xa0\\nI mean, there's a lot of other things it's really\\xa0\\xa0  good at, but this this idea of the AI can write\",\n",
       " \"software for anything. And that means that you\\xa0\\xa0  can express ideas in new ways that the AI can\\xa0\\ndo very advanced things. It can do, you know,\\xa0\\xa0  it can like in some sense you could like ask\\xa0\\nGPT4 anything, but because GPT5 is so good at\\xa0\\xa0  programming, it feels like it can do anything. Of\\xa0\\ncourse, it can't do things in the physical world,\\xa0\\xa0  but it can get a computer to do very complex\\xa0\\nthings. And software is this super powerful,\\xa0\\xa0  you know, way to like control some stuff and\",\n",
       " \"actually do some things. So, that that for me\\xa0\\xa0  has been the most striking. Um, it's gotten it's\\xa0\\nmuch better at writing. So, this is like there's\\xa0\\xa0  this whole thing of AI slop like AI writes in this\\xa0\\nkind of like quite annoying way and M dashes. M we\\xa0\\xa0  still have the M dashes in GPT5. A lot of people\\xa0\\nlike them dashes, but the writing quality of GPT5\\xa0\\xa0  is gotten much better. We still have a long way\",\n",
       " \"to go. We want to improve it more, but like uh\\xa0\\xa0  I've a thing we've heard a lot from people inside\\xa0\\nof OpenAI is that man, they started using GPT5,\\xa0\\xa0  they knew it was better on all the metrics, but\\xa0\\nthere's this like nuance quality they can't quite\\xa0\\xa0  articulate, but then when they have to go back\\xa0\\nto GPT4 to test something, it feels terrible.\\xa0\\xa0  And I I don't know exactly what the cause\\xa0\\nof that is, but I suspect part of it is the\\xa0\\xa0  writing feels so much more natural and better.\",\n",
       " \"I in preparation for this interview reached out\\xa0\\xa0  to a couple other leaders in AI and technology\\xa0\\nand gathered a couple questions for you. Okay,\\xa0\\xa0  so this next question is from Stripe CEO Patrick\\xa0\\nCollison. This will be a good one. Read this\\xa0\\xa0  verbatim. It's about the next stage. What what\\xa0\\ncomes after GBT5? In which year do you think a\\xa0\\xa0  large language model will make a significant\\xa0\\nscientific discovery and what's missing such\\xa0\\xa0  that it hasn't happened yet? He caveed here that\",\n",
       " \"we should leave math and special case models like\\xa0\\xa0  alpha fold aside. He's specifically asking about\\xa0\\nfully general purpose models like the GPT series.\\xa0\\xa0  I would say most people will agree that that\\xa0\\nhappens at some point over the next two years.\\xa0\\xa0  But the definition of significant matters a lot.\\xa0\\nAnd so some people significant might happen,\\xa0\\xa0  you know, in early 25. Some people might maybe\",\n",
       " 'not until late 2026. Sorry, early 2026. Maybe some\\xa0\\xa0  people not until late 2027, but I would I would\\xa0\\nbet that by late 27, most people agree that there\\xa0\\xa0  has been an AIdriven significant new discovery.\\xa0\\nAnd the thing that I think is missing is just\\xa0\\xa0  the kind of cognitive power of these models.\\xa0\\nA framework that one of the researchers said\\xa0\\xa0  to me that I really liked is, you know, a year\\xa0\\nago we could do well on like a high school like\\xa0\\xa0  a basic high school math competition problems that',\n",
       " \"might take a professional mathematician seconds to\\xa0\\xa0  a few minutes. We very recently got an IMO gold\\xa0\\nmedal. That is a crazy difficult like could you\\xa0\\xa0  explain what that means? That's kind of like the\\xa0\\nhardest competition math test. This is something\\xa0\\xa0  that like the very very top slice of the world.\\xa0\\nmany many professional mathematicians wouldn't\\xa0\\xa0  solve a single problem and we scored at the top\",\n",
       " \"level. Now there are some humans that got an even\\xa0\\xa0  higher score in the gold medal range but we we\\xa0\\nlike this is a crazy accomplishment and these\\xa0\\xa0  each of these problems it's like six problems over\\xa0\\n9 hours so hour and a half per problem for a great\\xa0\\xa0  mathematician. So we've gone from a few seconds\\xa0\\nto a few minutes to an hour and a half maybe to\\xa0\\xa0  prove a significant new mathematical theorem is\",\n",
       " \"like a thousand hours of work for a top person\\xa0\\xa0  in the world. So we've got to go from, you know,\\xa0\\nanother significant gain. But if you look at our\\xa0\\xa0  trajectory, you can say like, okay, we're getting\\xa0\\nto that. We have a path to get to that time\\xa0\\xa0  horizon. We just need to keep scaling the models.\\xa0\\nThe long-term future that you've described is\\xa0\\xa0  super intelligence. What does that actually mean?\",\n",
       " 'And how will we know when we\\'ve hit it? If we had\\xa0\\xa0  a system that could do better research, better AI\\xa0\\nresearch than uh say the whole open AI research\\xa0\\xa0  team, like if we were willing, if we said, \"Okay,\\xa0\\nthe best way we can use our GPUs is to let this AI\\xa0\\xa0  decide what experiments we should run smarter than\\xa0\\nlike the whole brain trust of Open AAI.\" Yeah. And\\xa0\\xa0  if that same to make a personal example, if that',\n",
       " \"same system could do a better job running open AI\\xa0\\xa0  than I could. So you have something that's like,\\xa0\\nyou know, better than the best researchers, better\\xa0\\xa0  than me at this, better than other people at their\\xa0\\njobs, that would feel like super intelligence to\\xa0\\xa0  me. That is a sentence that would have sounded\\xa0\\nlike science fiction just a couple years ago.\\xa0\\xa0  And now it kind of does, but it's you can like see\",\n",
       " \"it through the fog. Yes. And so one of the steps\\xa0\\xa0  it sounds like you're saying on that path is this\\xa0\\nmoment of scientific discovery of asking better\\xa0\\xa0  questions of grappling with things in a in a way\\xa0\\nthat expert level humans do to come up with new\\xa0\\xa0  discoveries. One of the things that keeps knocking\\xa0\\naround in my head is if we were in 1899 say and\\xa0\\xa0  we were able to give it all of physics up until\",\n",
       " 'that point and play it out a little bit. Nothing\\xa0\\xa0  further than that. Like at what point would one\\xa0\\nof these systems come up with general relativity?\\xa0\\xa0  Interesting question is did you like if we think\\xa0\\nabout that forward like like if we think of where\\xa0\\xa0  we are now should a if if we never got another\\xa0\\npiece of physics data. Yeah. Do we expect that a\\xa0\\xa0  really good super intelligence could just think',\n",
       " \"super hard about our existing data and maybe\\xa0\\xa0  say like solve high energy physics with no new\\xa0\\nparticle accelerator or does it need to build a\\xa0\\xa0  new one and design new experiments? Obviously\\xa0\\nwe don't know the answer to that. Different\\xa0\\xa0  people have different speculation. Uh but I\\xa0\\nsuspect we will find that for a lot of science,\\xa0\\xa0  it's not enough to just think harder about data we\\xa0\\nhave, but we will need to build new instruments,\\xa0\\xa0  conduct new experiments, and that will take some\",\n",
       " \"time. Like that that is the real world is slow\\xa0\\xa0  and messy and you know whatever. So I'm sure we\\xa0\\ncould make some more progress just by thinking\\xa0\\xa0  harder about the current scientific data we\\xa0\\nhave in the world. But my guess is to make\\xa0\\xa0  the big progress we'll also need to build new\\xa0\\nmachines and run new experiments and there will\\xa0\\xa0  be some slowdown built into that. Another way of\\xa0\\nof thinking about this is AI systems now are just\\xa0\\xa0  incredibly good at answering almost any question.\",\n",
       " \"But maybe one of the things we're saying is it's\\xa0\\xa0  another leap yet. And what Patrick's question\\xa0\\nis getting at is to ask the better questions.\\xa0\\xa0  Or or if we go back to this kind of timeline\\xa0\\nquestion, we could maybe say that AI systems\\xa0\\xa0  are superhuman on one minute tasks, but a long\\xa0\\nway to go to the thousand hour tasks. And there's\\xa0\\xa0  a dimension of human intelligence that seems\\xa0\\nvery different than AI systems when it comes\\xa0\\xa0  to these long horizon tasks. Now, I think we will\",\n",
       " \"figure it out, but today it's a real weak point.\\xa0\\xa0  We've talked about where we are now with GBC5.\\xa0\\nWe talked about the end goal or future goal of\\xa0\\xa0  super intelligence. One of the questions that\\xa0\\nI have, of course, is what does it look like\\xa0\\xa0  to walk through the fog between the two. The next\\xa0\\nquestion is from Nvidia CEO Jensen Hong. I'm going\\xa0\\xa0  to read this verbatim. Fact is what is. Truth is\",\n",
       " \"what it means. So facts are objective. Truths are\\xa0\\xa0  personal. They depend on perspective, culture,\\xa0\\nvalues, beliefs, context. One AI can learn and\\xa0\\xa0  know the facts. But how does one AI know the\\xa0\\ntruth for everyone in every country and every\\xa0\\xa0  background? I'm going to accept as axioms those\\xa0\\ndefinitions. I'm not sure if I agree with them,\\xa0\\xa0  but in the issues of time, I will just take them.\\xa0\\nI will take those definitions and go with it. Um,  I have been surprised, I think many other people\",\n",
       " \"have been surprised too about how fluent AI is\\xa0\\xa0  at adapting to different cultural contexts and\\xa0\\nindividuals. One of my favorite features that we\\xa0\\xa0  have ever launched in chatbt is the the sort of\\xa0\\nenhanced memory that came out earlier this year.\\xa0\\xa0  like it really feels like my Chad GBT gets to\\xa0\\nknow me and what I care about and like my life\\xa0\\xa0  experiences and background and the things that\\xa0\\nhave led me to where they are. A friend of mine\\xa0\\xa0  recently who's been a huge CHBT user, so he's\",\n",
       " \"got a lot of a a lot of he's put a lot of his\\xa0\\xa0  life into all these conversations. He gave his\\xa0\\nChad GBT a bunch of personality tests and asked\\xa0\\xa0  them to answer as if they were him and it got\\xa0\\nthe same scores he actually got, even though\\xa0\\xa0  he'd never really talked about his personality.\\xa0\\nAnd my ChachiBD has really learned over the years\\xa0\\xa0  of me talking to it about my culture, my\\xa0\\nvalues, my life. And I have used, you know,\\xa0\\xa0  I sometimes will use it in like uh I'll use like\",\n",
       " \"a free account just to see what it's like without\\xa0\\xa0  any of my history and it feels really really\\xa0\\ndifferent. So I think we've all been surprised on\\xa0\\xa0  the upside of how good AI is at learning this and\\xa0\\nadapting. And so do you envision in many different\\xa0\\xa0  parts of the world people using different\\xa0\\nAIs with different sort of cultural norms and\\xa0\\xa0  contexts? Is that what we're saying? I think that\",\n",
       " \"everyone will use like the same fundamental model,\\xa0\\xa0  but there will be context provided to that model\\xa0\\nthat will make it behave in sort of personalized\\xa0\\xa0  way they want their community wants. Whatever.\\xa0\\nI think when we're getting at this idea of facts\\xa0\\xa0  and truth and uh it brings me to this seems like a\\xa0\\ngood moment for our first time travel trip. Okay,\\xa0\\xa0  we're going to 2030. This is a serious question,\",\n",
       " \"but I want to ask it with a light-hearted example.\\xa0\\xa0  Have you seen the bunnies that are jumping on\\xa0\\nthe trampoline? Yes. So, for those who haven't\\xa0\\xa0  seen it, maybe it looks like backyard footage of\\xa0\\nbunnies enjoying jumping on a trampoline. And this\\xa0\\xa0  has gone incredibly viral recently. There's a\\xa0\\nhumanmade song about it. It's a whole thing.\\xa0\\xa0  There were a trampoline. And I think the reason\",\n",
       " \"why people reacted so strongly to it, it was maybe\\xa0\\xa0  the first time people saw a video, enjoyed it,\\xa0\\nand then later found out that it was completely AI\\xa0\\xa0  generated. In this time travel trip, if we imagine\\xa0\\nin 2030, we are teenagers and we're scrolling\\xa0\\xa0  whatever teenagers are scrolling in 2030. How do\\xa0\\nwe figure out what's real and what's not real?\\xa0\\xa0  I mean, I can give all sorts of literal answers\",\n",
       " \"to that question. We could be cryptographically\\xa0\\xa0  signing stuff and we could decide who we trust\\xa0\\ntheir signature if they actually filmed something\\xa0\\xa0  or not. But but my sense is what's going to\\xa0\\nhappen is it's just going to like gradually\\xa0\\xa0  converge. You know, even like a photo you take\\xa0\\nout of your iPhone today, it's like mostly real,\\xa0\\xa0  but it's a little not. There's like in some AI\\xa0\\nthing running there in a way you don't understand\\xa0\\xa0  and making it look like a little bit better and\",\n",
       " \"sometimes you see these weird things where the\\xa0\\xa0  moon. Yeah. Yeah. Yeah. Yeah. But there's like\\xa0\\na lot of processing power between the photons\\xa0\\xa0  captured by that camera sensor and the image\\xa0\\nyou eventually see. And you've decided it's real\\xa0\\xa0  enough or most people decided it's real enough.\\xa0\\nBut we've accepted some gradual move from when it\\xa0\\xa0  was like photons hitting the film in a camera. And\",\n",
       " \"you know, if you go look at some video on Tik Tok,\\xa0\\xa0  there's probably all sorts of video editing tools\\xa0\\nbeing used to make it better than real look. Yeah,\\xa0\\xa0  exactly. Or it's just like, you know, whole\\xa0\\nscenes are completely generated or some of\\xa0\\xa0  the whole videos are generated like those bunnies\\xa0\\non that trampoline. And and I think that the the\\xa0\\xa0  sort of like the threshold for how real does it\",\n",
       " \"have to be to consider to be real will just keep\\xa0\\xa0  moving. So it's sort of a education question.\\xa0\\nIt's a people will Yeah. I mean media is always\\xa0\\xa0  like a little bit real and a little bit not real.\\xa0\\nLike you know we watch like a sci-fi movie. We\\xa0\\xa0  know that didn't really happen. You watch like\\xa0\\nsomeone's like beautiful photo of themselves on\\xa0\\xa0  vacation on Instagram. like, okay, maybe that\\xa0\\nphoto was like literally taken, but you know,\\xa0\\xa0  there's like tons of tourists in line for the same\",\n",
       " \"photo and that's like left out of it. And I think\\xa0\\xa0  we just accept that now. Certainly, a higher\\xa0\\npercentage of media both will will feel not\\xa0\\xa0  real. Um, but I think that's been the long-term\\xa0\\ntrend. Anyway, we're going to jump again. Okay,\\xa0\\xa0  2035, we're graduating from college, you and me.\\xa0\\nThere are some leaders in the AI space that have\\xa0\\xa0  said that in 5 years half of the entry level\\xa0\\nwhite collar workforce will be replaced by AI.\\xa0\\xa0  So we're college graduates in 5 years. What do\",\n",
       " \"you hope the world looks like for us? I think\\xa0\\xa0  there's been a lot of talk about how AI might\\xa0\\ncause job displacement, but I'm also curious. I\\xa0\\xa0  have a job that nobody would have thought we\\xa0\\ncould have, you know, totally a decade ago.\\xa0\\xa0  What are the things that we could look ahead if\\xa0\\nwe're thinking about in 2035 that like graduating\\xa0\\xa0  college student, if they still go to college at\\xa0\\nall, could very well be like leaving on a mission\\xa0\\xa0  to explore the solar system on a spaceship in some\",\n",
       " \"kind of completely new exciting, super well- paid,\\xa0\\xa0  super interesting job and feeling so bad for you\\xa0\\nand I that like we had to do this kind of like\\xa0\\xa0  really boring old kind of work and everything\\xa0\\nis just better. Like I I 10 years feels very\\xa0\\xa0  hard to imagine at this point because it's too\\xa0\\nfar. It's too far. If you compound the current\\xa0\\xa0  rate of change for 10 more years, it's probably\\xa0\\nsomething we can't even time travel trips. I 10\\xa0\\xa0  like I mean I think now would be really hard\",\n",
       " \"to imagine 10 years ago. Yeah. Uh but I think\\xa0\\xa0  10 years forward will be even much harder, much\\xa0\\nmore different. So let's make it 5 years. We're\\xa0\\xa0  still going to 2030. I'm curious what you\\xa0\\nthink the pretty short-term impacts of this\\xa0\\xa0  will be for for young people. I mean, these like\\xa0\\nhalf of entry- level jobs replaced by AI makes\\xa0\\xa0  it sound like a very different world that they\\xa0\\nwould be entering than the one that I did. Um,  I think it's totally true that some classes of\",\n",
       " \"jobs will totally go away. This always happens\\xa0\\xa0  and young people are the best at adapting to this.\\xa0\\nI'm more worried about what it means, not for the\\xa0\\xa0  like 22-y old, but for the 62-y old that doesn't\\xa0\\nwant to go re retrain or reskill or whatever the\\xa0\\xa0  politicians call it that no one actually wants\\xa0\\nbut politicians and most of the time. If I were\\xa0\\xa0  22 right now and graduating college, I would\\xa0\\nfeel like the luckiest kid in all of history.\\xa0\\xa0  Why? Because there's never been a more amazing\",\n",
       " 'time to go create something totally new, to go\\xa0\\xa0  invent something, to start a company, whatever\\xa0\\nit is. I think it is probably possible now to\\xa0\\xa0  start a company that is a oneperson company that\\xa0\\nwill go on to be worth like more than a billion\\xa0\\xa0  dollars and more importantly than that deliver an\\xa0\\namazing product and service to the world and that\\xa0\\xa0  that is like a crazy thing. You have access to',\n",
       " \"tools that can let you do what used to take teams\\xa0\\xa0  of hundreds and you just have to like you know\\xa0\\nlearn how to use these tools and come up with a\\xa0\\xa0  great idea and it's it's like quite amazing. If\\xa0\\nwe take a step back, I think the most important\\xa0\\xa0  thing that this audience could hear from you\\xa0\\non this optimistic show is in two parts. First,\\xa0\\xa0  there's tactically, how are you actually trying\\xa0\\nto build the world's most powerful intelligence\\xa0\\xa0  and what are the rate limiting factors to doing\",\n",
       " 'that? And then philosophically, how are you and\\xa0\\xa0  others working on building that technology in\\xa0\\na way that really helps and not hurts people?\\xa0\\xa0  So just taking the tactical part right now.\\xa0\\nMy understanding is that there are three big\\xa0\\xa0  categories that have been limiting factors for\\xa0\\nAI. The first is compute, the second is data and\\xa0\\xa0  the third is algorithmic design. How do you think\\xa0\\nabout each of those three categories right now?\\xa0\\xa0  And if you were to help someone understand',\n",
       " \"the next headlines that they might see,\\xa0\\xa0  how would you help them make sense of all this?\\xa0\\nI I would say there's a fourth too which is uh\\xa0\\xa0  figuring out the products to build like techn like\\xa0\\nscientific progress on its own not put into the\\xa0\\xa0  hands of people is of limited utility and doesn't\\xa0\\nsort of co-evolve with society in the same way\\xa0\\xa0  but if I could hit all four of those um so on\\xa0\\nthe compute side yeah this is like the biggest\\xa0\\xa0  infrastructure project certainly that I've ever\",\n",
       " 'seen possibly it will become the I think it will\\xa0\\xa0  maybe already is the biggest and most expensive\\xa0\\none in human history but the the whole supply\\xa0\\xa0  chain from making the chips and the memory and\\xa0\\nthe networking gear, racking them up in servers,\\xa0\\xa0  doing, you know, a giant construction project to\\xa0\\nbuild like a mega mega data center, putting the,\\xa0\\xa0  you know, finding a way to get the energy, which',\n",
       " \"is often a limiting factor piece of this and all\\xa0\\xa0  the other components together. This is hugely\\xa0\\ncomplex and expensive. And we are we're still\\xa0\\xa0  doing this in like a sort of bespoke one-off way\\xa0\\nalthough it's getting better. Like eventually we\\xa0\\xa0  will just design a whole kind of like mega factory\\xa0\\nthat takes you know I mean spiritually it will be\\xa0\\xa0  melting sand on one end and putting out fully\",\n",
       " \"built AI compute on the other but we are a long\\xa0\\xa0  way to go from that and it's a it's an enormously\\xa0\\ncomplex and expensive process. uh we are putting\\xa0\\xa0  a huge amount of work into building out as much\\xa0\\ncompute as we can and to do it fast and you know\\xa0\\xa0  it's going to be like sad because GP5 is going\\xa0\\nto launch and there's going to be another big\\xa0\\xa0  spike in demand and we're not going to be able\",\n",
       " \"to serve it and it's going to be like those early\\xa0\\xa0  GPD4 days and the world just wants much more AI\\xa0\\nthan we can currently deliver and building more\\xa0\\xa0  compute is an important part of doing that.\\xa0\\nThat's actually this is what I expect to turn\\xa0\\xa0  the majority of my attention to is how we build\\xa0\\ncompute at much greater scales. Uh so how we go\\xa0\\xa0  from millions to tens of millions and hundreds of\",\n",
       " \"millions and eventually hopefully billions of GPUs\\xa0\\xa0  that are sort of in service of what people want\\xa0\\nto do with this. When you're thinking about it,\\xa0\\xa0  what are the big challenges here in this category\\xa0\\nthat you're going to be thinking about? We're\\xa0\\xa0  currently most limited by energy. um you know like\\xa0\\nif you're gonna you want to run a gigawatt scale\\xa0\\xa0  data center it's like a gigawatt how hard can that\",\n",
       " \"be to find it's really hard to find a gigawatt of\\xa0\\xa0  power available in short term we're also very much\\xa0\\nlimited by the processing chips and the memory\\xa0\\xa0  chips uh how you package these all together how\\xa0\\nyou build the racks and then there's like a list\\xa0\\xa0  of other things that are you know there's like\\xa0\\npermits there's construction work uh but but\\xa0\\xa0  again the goal here will be to really automate\\xa0\\nthis once we get some of those robots built,\\xa0\\xa0  they can help us automate it even more. But just,\",\n",
       " \"you know, like a world where you can basically\\xa0\\xa0  pour in money and get out a pre-built data center.\\xa0\\nUh so that'll be that'll be a huge unlock if we\\xa0\\xa0  can get it to work. Second category, data. Yeah,\\xa0\\nthese models have gotten so smart. There was a\\xa0\\xa0  time when we could just feed it another physics\\xa0\\ntextbook and got a little bit smarter at physics,\\xa0\\xa0  but now like honestly GBT5 understands\\xa0\\neverything in a physics textbook pretty well.\\xa0\\xa0  We're excited about synthetic data. We're very\",\n",
       " \"excited about our users helping us create harder\\xa0\\xa0  and harder tasks and environments to go off and\\xa0\\nhave the system solve. But uh I think we're data\\xa0\\xa0  will always be important, but we're entering a\\xa0\\nrealm where the models need to learn things that\\xa0\\xa0  don't exist in any data set yet. They have to\\xa0\\ngo discover new things. So that's like a crazy\\xa0\\xa0  new How do you teach a model to discover new\\xa0\\nthings? Well, humans can do it. like we can\\xa0\\xa0  go off and come up with hypotheses and test them\",\n",
       " \"and get experimental results and update on what we\\xa0\\xa0  learn. So probably the same kind of way. And then\\xa0\\nthere's algorithmic design. Yeah, we've made huge\\xa0\\xa0  progress on algorithmic design. Uh the thing that\\xa0\\nthe thing that I think open does best in the world\\xa0\\xa0  is we have built this culture of repeated and big\\xa0\\nalgorithmic research gains. So we kind of you know\\xa0\\xa0  figured out the what became the GPT paradigm. We\",\n",
       " \"figured out became the reasoning paradigm. We're\\xa0\\xa0  working on some new ones now. Um, but it is very\\xa0\\nexciting to me to think that there are still many\\xa0\\xa0  more orders of magnitudes of algorithmic\\xa0\\ngains ahead of us. We we just yesterday\\xa0\\xa0  uh released a model called GPOSS, open source\\xa0\\nmodel. It's a model that is as smart as 04 Mini,\\xa0\\xa0  which is a very smart model that runs locally on\\xa0\\na laptop. And this blows my mind. Yeah. Like if\\xa0\\xa0  you had asked me a few years ago when we'd have\",\n",
       " \"a model of that intelligence running on a laptop,\\xa0\\xa0  I would have said many many years in the future.\\xa0\\nBut then we we found some algorithmic gains\\xa0\\xa0  um particularly around reasoning but also some\\xa0\\nother things that let us do a a tiny model that\\xa0\\xa0  can do this amazing thing. And you know those are\\xa0\\nthose are the most fun things. That's like kind of\\xa0\\xa0  the coolest part of the job. I can see you really\",\n",
       " \"enjoying thinking about this. I'm curious for\\xa0\\xa0  people who don't quite know what you're talking\\xa0\\nabout, who aren't familiar with how an algorithmic\\xa0\\xa0  design would lead to a better experience that they\\xa0\\nactually use. Could you summarize the state of\\xa0\\xa0  things right now? Like what what is it that you're\\xa0\\nthinking about when you're thinking about how fun\\xa0\\xa0  this problem is? Let me start back in history\",\n",
       " \"and then I'll get to some things for today. So,\\xa0\\xa0  GPT1 was an idea at the time that was quite\\xa0\\nmocked by a lot of experts in the field,\\xa0\\xa0  which was can we train a model to play a little\\xa0\\ngame, which is show it a bunch of words and have\\xa0\\xa0  it guess the one that comes next in the sequence.\\xa0\\nThat's called unsupervised learning. There's not\\xa0\\xa0  you're not really saying like this is a cat,\\xa0\\nthis is a dog. You're saying here's some words,\\xa0\\xa0  guess the next one. And the fact that that can\",\n",
       " 'go learn these very complicated concepts that\\xa0\\xa0  can go learn all the stuff about physics and math\\xa0\\nand programming and keep predicting the word that\\xa0\\xa0  comes next and next and next and next seemed\\xa0\\nludicrous, magical, unlikely to work. Like how\\xa0\\xa0  was that all going to get encoded? And yet humans\\xa0\\ndo it. you know, babies start hearing language and\\xa0\\xa0  figure out what it means kind of largely uh or at',\n",
       " 'least to some significant degree on their own. And\\xa0\\xa0  and so we did it and then we also realized that if\\xa0\\nwe scaled it up, it got better and better, but we\\xa0\\xa0  had to scale over many many orders of magnitude.\\xa0\\nSo it wasn\\'t that good in the GPT1 day. It wasn\\'t\\xa0\\xa0  good at all in the GPT1 days. And a lot of experts\\xa0\\nin the field said, \"Oh, this is ridiculous. It\\'s\\xa0\\xa0  never going to work. It\\'s not going to be robust.\"',\n",
       " 'But we had these things called scaling laws. And\\xa0\\xa0  we said, \"Okay, so this gets predictably better as\\xa0\\nwe increase compute, memory, data, whatever. And\\xa0\\xa0  we can we can decide we can use those predictions\\xa0\\nto make decisions about how to scale this up and\\xa0\\xa0  do it and get great results.\" And that has worked\\xa0\\nover Yeah. a crazy number of orders of magnitude.\\xa0\\xa0  And it was so not obvious at the time. like',\n",
       " \"that was that was I think the the reason the\\xa0\\xa0  world was so surprised is that that seemed like\\xa0\\nsuch an unlikely finding. Another one was that we\\xa0\\xa0  could use these language models with reinforcement\\xa0\\nlearning where we're saying this is good, this is\\xa0\\xa0  bad to teach it how to reason. And this led to the\\xa0\\n01 and 03 and now the GBT5 progress. And that that\\xa0\\xa0  was another thing that felt like uh if it works\",\n",
       " \"it's really great but like no way this is going\\xa0\\xa0  to work. It's too simple. And now we're on to new\\xa0\\nthings. We've figured out how to make much better\\xa0\\xa0  video models. We are we are discovering new ways\\xa0\\nto use new kinds of data and environment to kind\\xa0\\xa0  of scale that up as well. Um and I think again\\xa0\\nyou know 5 10 years out that's too hard to say in\\xa0\\xa0  this field but the next couple of years we have\",\n",
       " \"very smooth very strong scaling in front of us.\\xa0\\xa0  I think it has become a sort of public narrative\\xa0\\nthat we are on this smooth path from one to two to\\xa0\\xa0  three to four to five to more. Yeah. But it also\\xa0\\nis true behind the scenes that it's a it's not\\xa0\\xa0  linear like that. It's messier. Tell us a little\\xa0\\nbit about the mess before GPT5. What was what were\\xa0\\xa0  the interesting problems that you needed to solve?\",\n",
       " \"Um, we did a model called Orion that we released\\xa0\\xa0  as GPT 4.5. And we had we did too big of a\\xa0\\nmodel. It was just it was it's a very cool model,\\xa0\\xa0  but it's unwieldly to use. And we realized that\\xa0\\nfor kind of some of the research we need to do on\\xa0\\xa0  top of a model, we need a different shape. So we\\xa0\\nwe followed one scaling law that kept being good\\xa0\\xa0  without without really internalizing. There was\",\n",
       " \"a new even steeper scaling law that we got better\\xa0\\xa0  returns for compute on, which was this reasoning\\xa0\\nthing. So that was like one alley we went down and\\xa0\\xa0  turned around, but that's fine. That's part of\\xa0\\nresearch. Um, we had some problems with the way\\xa0\\xa0  we think about our data sets as these models like\\xa0\\nreally have to get get this big and um, you know,\\xa0\\xa0  learn from this much data. So So yeah, I think\",\n",
       " \"like in the in the middle of it in the day-to-day,\\xa0\\xa0  you kind of you make a lot of U-turns as\\xa0\\nyou try things or you have an architecture\\xa0\\xa0  idea that doesn't work, but the the aggregate the\\xa0\\nsummation of all the squiggles has been remarkably\\xa0\\xa0  smooth on the exponential. One of the\\xa0\\nthings I always find interesting is that\\xa0\\xa0  by the time I'm sitting here interviewing\\xa0\\nyou about the thing that you just put out,\\xa0\\xa0  you're thinking about Exactly. What are the things\",\n",
       " \"that you can share that are at least the problems\\xa0\\xa0  that you're thinking about that I would be\\xa0\\ninterviewing you about in a year if I came back?  I mean, possibly you'll be asking me like,\\xa0\\nwhat does it mean that this thing can go\\xa0\\xa0  discover new science? Yeah. What how how\\xa0\\nis the world supposed to think about GPT6\\xa0\\xa0  discovering new science? Now, maybe\\xa0\\nnot like maybe we don't deliver that,\\xa0\\xa0  but it feels within grasp. If you did, what\",\n",
       " 'would you say? What would your what would the\\xa0\\xa0  implications of that kind of achievement\\xa0\\nbe? Imagine you do succeed. Yeah. I mean,\\xa0\\xa0  I think the great parts will be great. the bad\\xa0\\nparts will be scary and the bizarre parts will\\xa0\\xa0  be like bizarre on the first day and then we\\'ll\\xa0\\nget used to them really fast. So we\\'ll be like,\\xa0\\xa0  \"Oh, it\\'s incredible that this is like being\\xa0\\nused to cure disease and be like, oh, it\\'s\\xa0\\xa0  extremely scary that models like this are being',\n",
       " 'used to like create new biocurity threats.\" And\\xa0\\xa0  then we\\'ll also be like, man, it\\'s really weird\\xa0\\nto like live through watching the world speed up\\xa0\\xa0  so much and you know the economy grows so fast\\xa0\\nand the like it will feel like vertigo inducing\\xa0\\xa0  uh the sort of the rate of change and then like\\xa0\\nhappens with everything else the remarkable\\xa0\\xa0  ability of of people of humanity to adapt to kind',\n",
       " 'of like any amount of change. we\\'ll just be like,\\xa0\\xa0  \"Okay, you know, this is like this is it.\" Um, a\\xa0\\nkid born today will never be smarter than AI ever.\\xa0\\xa0  And a kid born today, by the time that kid like\\xa0\\nkind of understands the way the world works, will\\xa0\\xa0  just always be used to an incredibly fast rate of\\xa0\\nthings improving and discovering new science. They\\xa0\\xa0  will just they will never know any other world. It',\n",
       " \"will seem totally natural. will seem unthinkable\\xa0\\xa0  and stone age like that we used to use computers\\xa0\\nor phones or any kind of technology that was not\\xa0\\xa0  way smarter than we were. You know, we will think\\xa0\\nlike how bad those people of the 2020s had it. I'm\\xa0\\xa0  thinking about having kids. You should. It's the\\xa0\\nbest thing ever. I know you just had your first\\xa0\\xa0  kid. How does what you just said affect how I\",\n",
       " \"should think about parenting a kid in that world?  What advice would you give me? Probably nothing\\xa0\\ndifferent than the way you've been parenting kids\\xa0\\xa0  for tens of thousands of years. Like love your\\xa0\\nkids, show them the world, like support them in\\xa0\\xa0  whatever they want to do and teach them like how\\xa0\\nto be a good person. And that probably is what's\\xa0\\xa0  going to matter. It sounds a little bit like\\xa0\\nsome of the you know you've said a couple of\\xa0\\xa0  things like this that that you know you might not\",\n",
       " \"go to college you might there there are a couple\\xa0\\xa0  of things that you've said so far that feed into\\xa0\\nthis I think and it sounds like what you're saying\\xa0\\xa0  is there will be more optionality for them in a\\xa0\\nin a world that you envision and therefore they\\xa0\\xa0  will have more more ability to say I want to build\\xa0\\nthis here's the superpowered tool that will help\\xa0\\xa0  me do that or yeah like I want my kid to think\",\n",
       " \"I had a terrible constrained life and that he\\xa0\\xa0  has this incredible infinite canvas of stuff to\\xa0\\ndo that that that is like the way of the world.\\xa0\\xa0  We've said that uh 2035 is a little bit too far in\\xa0\\nthe future to think about. So maybe this this was\\xa0\\xa0  going to be a jump to 2040 but maybe it will keep\\xa0\\nit shorter than that. When I think about the area\\xa0\\xa0  where AI could have for both our kids and us the\",\n",
       " \"biggest genuinely positive impact on all of us,\\xa0\\xa0  it's health. So if we are in pick your year, call\\xa0\\nit 2035 and I'm sitting here and I'm interviewing\\xa0\\xa0  the dean of Stanford medicine, what do you hope\\xa0\\nthat he's telling me AI is doing for our health\\xa0\\xa0  in 2035? Start with 2025. Okay. Um yeah, please.\\xa0\\nOne of the things we are most proud of with GPT5\\xa0\\xa0  is how much better it's gotten at health advice.\",\n",
       " \"Um, people have used the GPT4 models a lot for\\xa0\\xa0  health advice. And you know, I'm sure you've seen\\xa0\\nsome of these things on the internet where people\\xa0\\xa0  are like, I had this life-threatening disease\\xa0\\nand no doctor could figure it out and I like\\xa0\\xa0  put my symptoms and a blood test into CHBT. It\\xa0\\ntold me exactly the rare thing I had. I went to\\xa0\\xa0  a doctor. I took a pill. I'm cured. Like that's\\xa0\\namazing. obviously and a huge fraction of ChatGpt\\xa0\\xa0  queries are health related. So we wanted to get\",\n",
       " 'really good at this and we invested a lot in\\xa0\\xa0  GPT5 is significantly better at healthcare related\\xa0\\nqueries. What does better mean here? It gives you\\xa0\\xa0  a better answer just more accurate more accurate\\xa0\\nhallucinates less uh more likely to like tell you\\xa0\\xa0  what you actually have what you actually should\\xa0\\ndo. Um, yeah, and better healthcare is wonderful,\\xa0\\xa0  but obviously what people actually want\\xa0\\nis to just not have disease. And by 2035,\\xa0\\xa0  I think we will be able to use these tools to',\n",
       " \"cure a significant number or at least treat a\\xa0\\xa0  significant number of diseases that currently\\xa0\\nplague us. I think that'll be one of the most\\xa0\\xa0  viscerally felt benefits of of AI. People talk a\\xa0\\nlot about how AI will revolutionize healthcare,\\xa0\\xa0  but I'm curious to go one turn deeper on\\xa0\\nspecifically what you're imagining. Like,\\xa0\\xa0  is it that these AI systems could have helped\\xa0\\nus see GLP-1s earlier, this medication that has\\xa0\\xa0  been around for a long time, but we didn't know\",\n",
       " 'about this other effect? Is it that, you know,\\xa0\\xa0  alpha fold and protein folding is helping create\\xa0\\nnew medicines? I would like to be able to ask GBT\\xa0\\xa0  8 to go cure a particular cancer and I would like\\xa0\\nGPT8 to go off and think and then say uh okay I\\xa0\\xa0  read everything I could find. I have these ideas.\\xa0\\nI need you to uh go get a lab technician to run\\xa0\\xa0  these nine experiments and tell me what you find',\n",
       " 'for each of them. And you know wait 2 months for\\xa0\\xa0  the cells to do their thing. Send the results back\\xa0\\nto GBT8. Say I tried it. Here you go. Think think.\\xa0\\xa0  Say okay I just need one more experiment. That was\\xa0\\na surprise. Run one more experiment. Give it back.\\xa0\\xa0  GPT says, \"Okay, go synthesize this molecule and\\xa0\\ntry, you know, mouse studies or whatever.\" Okay,\\xa0\\xa0  that was good. Like, try human studies. Okay,',\n",
       " 'great. It worked. Um, here\\'s how to like run\\xa0\\xa0  it through the FDA. I think anyone with a loved\\xa0\\none who\\'s died of cancer would also really like\\xa0\\xa0  that. Okay, we\\'re going to jump again. Okay. I was\\xa0\\ngoing to say 2050, but again, all of my timelines\\xa0\\xa0  are getting much, much shorter. But I It does\\xa0\\nfeel like the world\\'s going very fast now. It\\xa0\\xa0  does. Yeah. And when I talk to other leaders in\\xa0\\nAI, one of the things that they refer to is the\\xa0\\xa0  industrial revolution. They say, \"I chose 2050',\n",
       " 'because I\\'ve heard people talk about how by then\\xa0\\xa0  the change that we will have gone through will\\xa0\\nbe like the industrial revolution, but quote 10\\xa0\\xa0  times bigger and 10 times faster.\" The industrial\\xa0\\nrevolution gave us modern medicine and sanitation\\xa0\\xa0  and transportation and mass production and all all\\xa0\\nof the conveniences that we now take for granted.\\xa0\\xa0  It also was incredibly difficult for a lot of',\n",
       " \"people for about 100 years. If this is going to\\xa0\\xa0  be 10 times bigger and 10 times faster if we keep\\xa0\\nreducing the timelines that we're talking about\\xa0\\xa0  here, even in this conversation, what does that\\xa0\\nactually feel like for most people? And I think\\xa0\\xa0  what I'm trying to get at is if this all goes the\\xa0\\nway you hope, who still gets hurt in the meantime?\\xa0\\xa0  I don't I don't really know what this is going\",\n",
       " \"to feel like to live through. Um I think we're\\xa0\\xa0  in uncharted waters here. Uh I do believe in\\xa0\\nlike human adaptability and sort of infinite\\xa0\\xa0  creativity and desire for stuff and I think\\xa0\\nwe always do figure out new things to do but\\xa0\\xa0  the transition period if this happens as fast\\xa0\\nas it might and I don't think it will happen\\xa0\\xa0  as fast as like some of my colleagues say the\\xa0\\ntechnology will but society has like a lot of\\xa0\\xa0  inertia. Mhm. people adapt their way of living.\",\n",
       " \"Yeah. Surprisingly slowly. There are to classes\\xa0\\xa0  of jobs that are going to totally go away and\\xa0\\nthere will be many classes of jobs that change\\xa0\\xa0  significantly and there'll be the new things in\\xa0\\nthe same way that your job didn't exist some time\\xa0\\xa0  ago. Neither did mine. And in some sense, this\\xa0\\nhas been going on for a long time. And you know,\\xa0\\xa0  it's it's still disruptive to individuals, but\\xa0\\nsociety has gotten has proven quite resilient\\xa0\\xa0  to this. And then in some other sense like we\",\n",
       " \"have no idea how far or fast this could go.\\xa0\\xa0  And thus I think we need an unusual degree\\xa0\\nof humility and openness to considering  new solutions that would have seemed way\\xa0\\nout of the Overton window not too long ago.\\xa0\\xa0  I'd like to talk about what some of those could\\xa0\\nbe because I'm not a historian by any means, but\\xa0\\xa0  the first industrial revolution, my understanding\\xa0\\nis led to a lot of public health implementations\\xa0\\xa0  because public health got so bad. Led to modern\",\n",
       " \"sanitation because public health got so bad.\\xa0\\xa0  The second industrial revolution led to workforce\\xa0\\nprotections because labor conditions got so bad.\\xa0\\xa0  Every big leap creates a mess and that mess needs\\xa0\\nto be cleaned up and and we've done that. And I'm\\xa0\\xa0  curious, this is going to be it sounds like\\xa0\\nan we're in the middle of this enormously. How\\xa0\\xa0  specific can we get as early as possible about\\xa0\\nwhat that mess can be? What what are the public\\xa0\\xa0  interventions that we could do ahead of time to\",\n",
       " \"reduce the mess that we think that we're headed\\xa0\\xa0  for? I would again c I'm going to speculate for\\xa0\\nfun but caveed by I'm not an economist even uh\\xa0\\xa0  much less someone who can see the future. I I it\\xa0\\nseems to me like something fundamental about the\\xa0\\xa0  social contract may have to change. It may not.\\xa0\\nIt may it may be that like actually capitalism\\xa0\\xa0  works as it's been working surprisingly well and\\xa0\\nlike demand supply balances do their thing and we\\xa0\\xa0  all just figure out kind of new jobs and new\",\n",
       " \"ways to transfer value to each other. But it\\xa0\\xa0  seems to me likely that we will decide we need\\xa0\\nto think about how access to this maybe most\\xa0\\xa0  important resource of the future gets shared.\\xa0\\nThe best thing that it seems to me to do is to\\xa0\\xa0  make AI compute as abundant and cheap as possible\\xa0\\nsuch that we're just like there's way too much\\xa0\\xa0  and we run out of like good new ideas to really\\xa0\\nuse it for and it's just like anything you want\\xa0\\xa0  is happening. Without that, I can see like quite\",\n",
       " \"literal wars being fought over it. But, you know,\\xa0\\xa0  new ideas about how we distribute access to AGI\\xa0\\ncompute, that seems like a really great direction,\\xa0\\xa0  like a crazy but important thing to think about.\\xa0\\nOne of the things that I find myself thinking\\xa0\\xa0  about in this conversation is we often ascribe\\xa0\\nalmost full responsibility of the AI future that\\xa0\\xa0  we've been talking about to the companies building\",\n",
       " \"AI, but we're the ones using it. We're the ones\\xa0\\xa0  electing people that will regulate it. And so I'm\\xa0\\ncurious, this is not a question about specific,\\xa0\\xa0  you know, federal regulation or anything like\\xa0\\nthat, although if you have an answer there,\\xa0\\xa0  I'm curious. But what would you ask of the rest\\xa0\\nof us? What is the shared responsibility here?\\xa0\\xa0  And how can we act in a way that would help make\\xa0\\nthe optimistic version of this more possible? My\\xa0\\xa0  favorite historical example for the AI revolution\",\n",
       " 'is the transistor. It was this amazing piece of\\xa0\\xa0  science that some science brilliant scientists\\xa0\\ndiscovered. It scaled incredibly like AI does\\xa0\\xa0  and it made its way relatively quickly into\\xa0\\nevery many things that we use. um your computer,\\xa0\\xa0  your phone, that camera, that light, whatever.\\xa0\\nAnd it was a it was a real unlock for the tech\\xa0\\xa0  tree of humanity. And there were a period in time\\xa0\\nwhere probably everybody was really obsessed with\\xa0\\xa0  the transistor companies, the semiconductors of,',\n",
       " \"you know, Silicon Valley back when it was Silicon\\xa0\\xa0  Valley. But now you can maybe name a couple of\\xa0\\ncompanies that are transistor companies, but\\xa0\\xa0  mostly you don't think about it. Mostly it's just\\xa0\\nseeped everywhere. in Silicon Valley is, you know,\\xa0\\xa0  like probably someone graduating from college\\xa0\\nbarely remembers why it was called that in the\\xa0\\xa0  first place. And you don't think that it was those\\xa0\\ntransistor companies that shaped society even\\xa0\\xa0  though they did something important. You think\",\n",
       " 'about what Apple did with the iPhone and then\\xa0\\xa0  you think about what Tik Tok built on top of the\\xa0\\niPhone and you\\'re like, \"All right, here\\'s this\\xa0\\xa0  long chain of all these people that nudged society\\xa0\\nin some way and what our governments did or didn\\'t\\xa0\\xa0  do and what the people using these technologies\\xa0\\ndid.\" And I think that\\'s what will happen with AI.\\xa0\\xa0  Like back, you know, kids born today, they they',\n",
       " \"never knew the world without AI. So they don't\\xa0\\xa0  really think about it. It's just this thing that's\\xa0\\ngoing to be there in everything. and and they will\\xa0\\xa0  think about like the companies that built on it\\xa0\\nand what they did with it and the kind of like\\xa0\\xa0  political leaders the decisions they made that\\xa0\\nmaybe they wouldn't have been able to do without\\xa0\\xa0  AI but they will still think about like what this\",\n",
       " \"president or that president did and you know the\\xa0\\xa0  role of the AI companies is all these companies\\xa0\\nand people and institutions before us built up\\xa0\\xa0  this scaffolding we added our one layer on top and\\xa0\\nnow people get to stand on top of that and add one\\xa0\\xa0  layer and the next and the next and many more And\\xa0\\nthat is the beauty of our society. We kind of all  I I love this like idea that society\\xa0\\nis the super intelligence. Like no one\\xa0\\xa0  person could do on their own, what they're\",\n",
       " \"able to do with all of the really hard work\\xa0\\xa0  that society has done together to like give\\xa0\\nyou this amazing set of tools. And that's\\xa0\\xa0  what I think it's going to feel like. It's\\xa0\\ngoing to be like, all right, you know, yeah,\\xa0\\xa0  some nerds discovered this thing and that was\\xa0\\ngreat and you know, now everybody's doing all\\xa0\\xa0  these amazing things with it. So maybe the ask\\xa0\\nto millions of people is build on it. Well,  in my own life, that is the  feel as like this important societal contract.\",\n",
       " \"All these people came before you. They worked\\xa0\\xa0  incredibly hard. They like put their brick in\\xa0\\nthe path of human progress and you get to walk\\xa0\\xa0  all the way down that path and you got to put one\\xa0\\nmore and somebody else does that and somebody else\\xa0\\xa0  does that. This does feel I've done a couple\\xa0\\nof interviews with folks who have really made\\xa0\\xa0  cataclysmic change. The one I'm thinking about\\xa0\\nright now is with uh crisper pioneer Jennifer Dana\\xa0\\xa0  and it did feel like that was also what she was\",\n",
       " \"saying in some way. She had discovered something\\xa0\\xa0  that really might change the way that most people\\xa0\\nrelate to their health moving forward. And there\\xa0\\xa0  will be a lot of people that will use what she\\xa0\\nhas done in ways that she might approve of or\\xa0\\xa0  not approve of. And it was really interesting.\\xa0\\nI'm hearing some similar themes of like, man,\\xa0\\xa0  I I hope that this I hope that the next person\\xa0\\ntakes the baton and runs with it well. Yeah.\\xa0\\xa0  But that's been working for a long time. Not all\",\n",
       " \"good, but mostly good. I think there's a there's\\xa0\\xa0  a big difference between winning the race and\\xa0\\nbuilding the AI future that would be best for the\\xa0\\xa0  most people. And I can imagine that it is easier\\xa0\\nmaybe more quantifiable sometimes to focus on the\\xa0\\xa0  next way to win the race. And I'm curious when\\xa0\\nthose two things are at odds. What is an example\\xa0\\xa0  of a decision that you've had to make that is\\xa0\\nbest for the world but not best for winning?  I think there are a lot. So, one of the\",\n",
       " \"things that we are most proud of is many\\xa0\\xa0  people say that ChachiBt is their favorite\\xa0\\npiece of technology ever and that it's the\\xa0\\xa0  one that they trust the most, rely on the\\xa0\\nmost, whatever. And this is a little bit of\\xa0\\xa0  a ridiculous statement because AI is the thing\\xa0\\nthat hallucinates. AI has all of these problems,\\xa0\\xa0  right? But we have screwed some things up along\\xa0\\nthe way, sometimes big time, but on the whole,\\xa0\\xa0  I think as a user of Chachib, you get the feeling\",\n",
       " \"that like it's trying to help you. It's trying to\\xa0\\xa0  like help you accomplish whatever you ask. It's\\xa0\\nit's very aligned with you. It's not trying to\\xa0\\xa0  get you to like, you know, use it all day. It's\\xa0\\nnot trying to like get you to buy something.\\xa0\\xa0  It's trying to like kind of help you accomplish\\xa0\\nwhatever your goals are. And and that is that's\\xa0\\xa0  like a very special relationship we have with our\\xa0\\nusers. We do not take it lightly. There's a lot\\xa0\\xa0  of things we could do that would like grow\",\n",
       " \"faster, that would get more time in chatbt\\xa0\\xa0  uh that we don't do because we know that like\\xa0\\nour long-term incentive is to stay as aligned\\xa0\\xa0  with our users as possible. And but there's a lot\\xa0\\nof short-term stuff we could do that would like\\xa0\\xa0  really like juice growth or revenue or whatever\\xa0\\nand be very misaligned with that long-term goal.\\xa0\\xa0  And I'm proud of the company and how little we\\xa0\\nget distracted by that. But sometimes we do get\\xa0\\xa0  tempted. Are there specific examples that come\",\n",
       " \"to mind? Any like decisions that you've made? Um  well, we haven't put a sex bot avatar in\\xa0\\nChbt yet. That does seem like it would\\xa0\\xa0  get time spent. Apparently, it does.\\xa0\\nI'm gonna ask my next question. Um,\\xa0\\xa0  it's been a really crazy few years. You know, it\\xa0\\nand somehow one of the things that keeps coming\\xa0\\xa0  back is that it feels like we're in the first\\xa0\\ninning. Yeah. And one of the things that I would\\xa0\\xa0  say we're out of the first inning. Out of the\",\n",
       " \"first inning, I would say second inning. I mean,\\xa0\\xa0  you have GPT5 on your phone and it's like smarter\\xa0\\nthan experts in every field. That's got to be out\\xa0\\xa0  of the first name. But maybe there are many\\xa0\\nmore to come. Yeah. And I'm curious, it seems\\xa0\\xa0  like you're going to be someone who is leading the\\xa0\\nnext few. What is a way, what is a learning from\\xa0\\xa0  inning one or two or a mistake that you made that\",\n",
       " \"you feel will affect how you play in the next?  I think the worst thing we've done in ChachiBT\\xa0\\nso far is uh we had this issue with sickency\\xa0\\xa0  where the model was kind of being too flattering\\xa0\\nto users and for some users it was most users it\\xa0\\xa0  was just annoying but for some users that had like\\xa0\\nfragile mental states it was encouraging delusions\\xa0\\xa0  that was not the top risk we were worried about.\",\n",
       " 'It was not the thing we were testing for the most.\\xa0\\xa0  was on our list, but the thing that actually\\xa0\\nbecame the safety failing of ChachiBT was not\\xa0\\xa0  the one we were spending most of our time talking\\xa0\\nabout, which should be bioweapons or something\\xa0\\xa0  like that. And I think it was a great reminder of\\xa0\\nwe now have a service that is so broadly used in\\xa0\\xa0  some sense, society is co-evolving with it. And',\n",
       " 'when we think about these changes and we think\\xa0\\xa0  about the unknown unknowns, we have to operate in\\xa0\\na different way and have like a wider aperture to\\xa0\\xa0  what we think about as our top risks. In a recent\\xa0\\ninterview with Theo Vaughn, you said something\\xa0\\xa0  that I found really interesting. You said there\\xa0\\nare moments in the history of science where you\\xa0\\xa0  have a group of scientists look at their creation',\n",
       " 'and just say, \"What have we done?\" When have you\\xa0\\xa0  felt that way? Most concerned about the creation\\xa0\\nthat you\\'ve built? Um and then my next question\\xa0\\xa0  will be it\\'s opposite. When have you felt most\\xa0\\nproud? I mean there have been these moments of\\xa0\\xa0  awe where uh we just not like what have we done in\\xa0\\na bad way but like this thing is remarkable. Like\\xa0\\xa0  I remember the first time we talked to like GPT4',\n",
       " \"was like wow this is really like this is this is\\xa0\\xa0  an amazing accomplishment of this group of people\\xa0\\nthat have been like pouring their life force into\\xa0\\xa0  this for so long. on a what have we done moment.\\xa0\\nThere was I was talking to a researcher recently.  You know, there will probably come a time\\xa0\\nwhere our systems are I don't want to say sane,\\xa0\\xa0  let's say emitting more words\\xa0\\nper day than all people do.\\xa0\\xa0  Um, and you know already like our people are\",\n",
       " \"sending billions of messages a day to chatbt\\xa0\\xa0  and getting responses that they rely on for work\\xa0\\nor their life or whatever the and you know like\\xa0\\xa0  one researcher can make some small tweak to how\\xa0\\nChad GPT talks to you or talks to everybody and\\xa0\\xa0  and that's just an enormous amount of power for\\xa0\\nlike one individual making a small tweak to the\\xa0\\xa0  model personality. Yeah. like no no no person\\xa0\\nin history has been able to have billions of\\xa0\\xa0  conversations a day and so you know somebody could\",\n",
       " 'do something but but this is like just thinking\\xa0\\xa0  about that really hit me of like this is like a\\xa0\\ncrazy amount of power for one piece of technology\\xa0\\xa0  to have and like we got to and this happened to\\xa0\\nus so fast that we got to like think about what\\xa0\\xa0  it means to make a personality change to the model\\xa0\\nat this kind of scale and uh yeah that was like\\xa0\\xa0  a moment that hit me What was your next set of',\n",
       " \"thoughts? I'm so curious how you think about this.  Well, just because of like who that person was\\xa0\\nlike we we very we very much flipped into like\\xa0\\xa0  what are the sort of like it it could have been\\xa0\\na very different conversation with somebody else.\\xa0\\xa0  But in this case it was like what is a what do\\xa0\\na good set of procedures look like? How do we\\xa0\\xa0  think about how we want to test something? How do\",\n",
       " 'we think about how we want to communicate it? But\\xa0\\xa0  with somebody else it could have gone in a like\\xa0\\nvery philosophical direction. And it could have\\xa0\\xa0  gone in like a what kind of research do we like\\xa0\\nwant to do to go understand what these changes are\\xa0\\xa0  going to make? Do we want to do it differently\\xa0\\nfor different people? So that it went that way\\xa0\\xa0  but mostly just because of who I was talking to.',\n",
       " \"To combine what you're saying now with your last\\xa0\\xa0  answer, one of the things that I have heard\\xa0\\nabout GBC5 and I'm still playing with it is\\xa0\\xa0  that it is supposed to be less effusively uh you\\xa0\\nknow less of a yes man. Two questions. What do\\xa0\\xa0  you think are are the implications of that? It\\xa0\\nsounds like you are answering that a little bit,\\xa0\\xa0  but also how do you actually guide it to\\xa0\\nbe less like that? Here is a heartbreaking\\xa0\\xa0  thing. I think it is great that chatbt\",\n",
       " 'is less of a yes man and gives you more\\xa0\\xa0  critical feedback. But as we\\'ve been making\\xa0\\nthose changes and talking to users about it,\\xa0\\xa0  it\\'s so sad to hear users say like, \"Please\\xa0\\ncan I have it back? I\\'ve never had anyone in\\xa0\\xa0  my life be supportive of me. I never had a\\xa0\\nparent telling me I was doing a good job.\"\\xa0\\xa0  Like I can get why this was bad for other people\\'s\\xa0\\nmental health, but this was great for my mental\\xa0\\xa0  health. Like I didn\\'t realize how much I needed',\n",
       " \"this. It encouraged me to do this. It encouraged\\xa0\\xa0  me to make this change in my life. Like it's\\xa0\\nnot all bad for chatbt to it turns out like be\\xa0\\xa0  encouraging of you. Now the way we were doing\\xa0\\nit was bad, but turn it like something in that\\xa0\\xa0  direction might have some value in it. How we do\\xa0\\nit, we we show the model examples of how we'd like\\xa0\\xa0  it to respond in different cases and from that\\xa0\\nit learns the sort of the overall personality.\\xa0\\xa0  What haven't I asked you that you're thinking\",\n",
       " \"about a lot that you want people to know? I\\xa0\\xa0  feel like we covered a lot of ground. Me, too. But\\xa0\\nI want to know if there's anything on your mind.  I don't think so. One of the things that I haven't\\xa0\\ngotten to play with yet, but I'm curious about is\\xa0\\xa0  GBT5 being much more in my life, meaning like\\xa0\\nin my Gmail and my calendar and my like I've\\xa0\\xa0  been using GBT4 mostly as a isolated relationship\\xa0\\nwith it. Yeah. How would I expect my relationship\\xa0\\xa0  to change with GBC 5? Exactly what you said.\",\n",
       " 'I think it\\'ll just start to feel integrated in\\xa0\\xa0  all of these ways. you\\'ll connect it to your\\xa0\\ncalendar and your Gmail and it\\'ll say like,\\xa0\\xa0  \"Hey, do you want me to I noticed this thing. Do\\xa0\\nyou want me to do this thing for you over time,\\xa0\\xa0  it\\'ll start to feel way more proactive. Um, so\\xa0\\nmaybe you wake up in the morning and it says,\\xa0\\xa0  \"Hey, this happened overnight. I noticed this\\xa0\\nchange on your calendar. I was thinking more\\xa0\\xa0  about this question you asked me. I have this',\n",
       " 'other idea.\" And then you know eventually we\\'ll\\xa0\\xa0  make some consumer devices and it\\'ll sit here\\xa0\\nduring this interview and you know maybe it\\'ll\\xa0\\xa0  leave us alone during it but after it\\'ll say that\\xa0\\nwas great but next time you should have asked Sam\\xa0\\xa0  this or when you brought this up like you know\\xa0\\nhe kind of didn\\'t give you a good answer so like\\xa0\\xa0  you should really drill him on that and it\\'ll just',\n",
       " \"feel like it kind of becomes more like this entity\\xa0\\xa0  that is this companion with you throughout your\\xa0\\nday. We've talked about kids and college graduates\\xa0\\xa0  and parents and all kinds of different people. If\\xa0\\nwe imagine a wide set of people listening to this,\\xa0\\xa0  they've come to the end of this conversation. They\\xa0\\nare hopefully feeling like they maybe see visions\\xa0\\xa0  of moments in the future a little bit better. What\",\n",
       " 'advice would you give them about how to prepare?\\xa0\\xa0  The number one piece of tactical advice is just\\xa0\\nuse the tools. Like the the number of people that\\xa0\\xa0  I have the the most common question I get asked\\xa0\\nabout AI is like what should I how should I help\\xa0\\xa0  my kids prepare for the world? What should I\\xa0\\ntell my kids? The second most question is like\\xa0\\xa0  how do I invest in this AI world? But stick with',\n",
       " \"that first one. Um I am surprised how many people\\xa0\\xa0  ask that and have never tried using Chachi PT\\xa0\\nfor anything other than like a better version\\xa0\\xa0  of a Google search. And so the number one piece of\\xa0\\nadvice that I give is just try to like get fluent\\xa0\\xa0  with the capability of the tools. figure out how\\xa0\\nto like use this in your life. Figure out what to\\xa0\\xa0  do with it. And I think that's probably the most\",\n",
       " \"important piece of tactical advice. You know,\\xa0\\xa0  go like meditate, learn how to be resilient and\\xa0\\ndeal with a lot of change. There's all that good\\xa0\\xa0  stuff, too. But just using the tools really\\xa0\\nhelps. Okay. I have one more question that\\xa0\\xa0  I wasn't planning to ask, but I just Great.\\xa0\\nIn in doing all of this research beforehand,\\xa0\\xa0  I spoke to a lot of different kinds of folks.\\xa0\\nI spoke to a lot of people that were building\\xa0\\xa0  tools and using them. I spoke to a lot of\",\n",
       " \"people that were actually in labs and and\\xa0\\xa0  trying to build what we have defined as super\\xa0\\nintelligence. And it did seem like there were\\xa0\\xa0  these two camps forming. There's a group of\\xa0\\npeople who are using the tools like you in this\\xa0\\xa0  conversation and building tools for others\\xa0\\nsaying this is going to be a really useful\\xa0\\xa0  future that we're all moving toward. Your life is\\xa0\\ngoing to be full of choice and we've talked about\\xa0\\xa0  our my potential kids and and their futures.\",\n",
       " \"Then there's another camp of people that are\\xa0\\xa0  building these tools that are saying it's going\\xa0\\nto kill us all. And I'm curious how that cultural\\xa0\\xa0  disconnect has like what am I missing about\\xa0\\nthose two groups of people? It's so hard for\\xa0\\xa0  me to like wrap my head around like there are you\\xa0\\nare totally right. There are people who say this\\xa0\\xa0  is going to kill us all and yet they still are\\xa0\\nworking 100 hours a week to build it. Yes. And\\xa0\\xa0  I I can't I can't really put myself in the headsp\",\n",
       " \"space. If if that's what I really truly believed,  I don't think I'd be trying to build it. One\\xa0\\nwould think, you know, maybe I would be like\\xa0\\xa0  on a farm trying to like live out my last days.\\xa0\\nMaybe I would be trying to like advocate for it\\xa0\\xa0  to be stopped. Maybe I would be trying to\\xa0\\nlike work more on safety, but I don't think\\xa0\\xa0  I'd be trying to build it. So, I find myself just\\xa0\\nhaving a hard time empathizing with that mindset.\\xa0\\xa0  I assume it's true. I assume it's in\",\n",
       " \"good faith. I assume there's just like\\xa0\\xa0  there's some psychological issue there I don't\\xa0\\nunderstand about how they make it all make sense,\\xa0\\xa0  but it's very strange to me. Do you do you have an\\xa0\\nopinion? You know, because I I always do this. I\\xa0\\xa0  ask for sort of a general future and then I try\\xa0\\nto press on specifics. And when you ask people\\xa0\\xa0  for specifics on how it's going to kill us all,\\xa0\\nI mean, I don't think we need to get into this\\xa0\\xa0  on an optimistic show, but you hear the same kinds\",\n",
       " \"of refrains. You think about, you know, something\\xa0\\xa0  uh trying to accomplish a task and then over\\xa0\\naccomplishing that task. Um you hear about sort\\xa0\\xa0  of I've heard you talk about a sort of general\\xa0\\num over reliance of sort of an understanding\\xa0\\xa0  that the president is going to be a a AI and and\\xa0\\nmaybe that is an overreliance that we, you know,\\xa0\\xa0  would need to think about. And you know, you you\",\n",
       " \"play out these different scenarios, but then you\\xa0\\xa0  ask someone why they're working on it, or you ask\\xa0\\nsomeone how how they think this will play out,\\xa0\\xa0  and I just maybe I haven't spoken to enough people\\xa0\\nyet. Maybe I don't fully understand this this\\xa0\\xa0  cultural conversation that's happening. Um or\\xa0\\nmaybe it really is someone who just says 99% of\\xa0\\xa0  the time I think it's going to be incredibly good.\",\n",
       " \"1% of the time I think it might be a disaster\\xa0\\xa0  trying to make the best world. That I can totally\\xa0\\nif you're like, hey, 99% chance incredible. 1%\\xa0\\xa0  chance the world gets wiped out. And I really want\\xa0\\nto work to maximize to move that 99 to 99.5. That\\xa0\\xa0  I can totally understand. Yeah, that makes sense.\\xa0\\nI've been doing an interview series with some of\\xa0\\xa0  the most important people influencing the future.\",\n",
       " \"Not knowing who the next person is going to be,\\xa0\\xa0  but knowing that they will be building something\\xa0\\ntotally fascinating in the future that we've just\\xa0\\xa0  described. Is there a question that you'd advise\\xa0\\nme to ask the next person not knowing who it is?\\xa0\\xa0  I'm always interested in the like without knowing\\xa0\\nanything about the I'm always interested in the\\xa0\\xa0  like of all of the things you could spend\\xa0\\nyour time and energy on. Why did you pick\\xa0\\xa0  this one? How did you get started? Like what\",\n",
       " 'did you see about this when before everybody\\xa0\\xa0  else like most people doing something interesting\\xa0\\nsort of saw it earlier before it was consensus.\\xa0\\xa0  Yeah. Like how did how did you get here and\\xa0\\nwhy this? How would you answer that question?  I was an AI nerd my whole life. I came to college\\xa0\\nto study AI. I worked in the AI lab. Uh, I was\\xa0\\xa0  like a I watched sci-fi shows growing up and I\\xa0\\nalways thought it would be really cool if someday\\xa0\\xa0  somebody built it. I thought it would be like the',\n",
       " \"most important thing ever. I never thought I was\\xa0\\xa0  going to be one to actually work on it and I feel\\xa0\\nlike unbelievably lucky and happy and privileged\\xa0\\xa0  that I get to do this. I like feel like I've like\\xa0\\ncome a long way from my childhood. But there was\\xa0\\xa0  never a question in my mind that this would not be\\xa0\\nthe most exciting interesting thing. I just didn't\\xa0\\xa0  think it was going to be possible. Uh, and when\",\n",
       " 'I went to college, it really seemed like we were\\xa0\\xa0  very far from it. And then in 2012, the Alex Net\\xa0\\npaper came out done, you know, in partnership with\\xa0\\xa0  my co-founder, Ilia. And for the first time, it\\xa0\\nseemed to me like there was an approach that might\\xa0\\xa0  work. And then I kept watching for the next couple\\xa0\\nof years as scaled up, scaled up, got better,\\xa0\\xa0  better. And I remember having this thing of',\n",
       " \"like why is the world not paying attention to\\xa0\\xa0  this? It seems like obvious to me that this might\\xa0\\nwork. Still a low chance, but it might work. And\\xa0\\xa0  if it does work, it's just the most important\\xa0\\nthing. So like this is what I want to do. And\\xa0\\xa0  then like unbelievably it started to work. Thank\\xa0\\nyou so much for your time. Thank you very much.\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=splitter.split_text(transcript_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84d9b780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)#total no of chunks created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a92ef3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=HuggingFaceEmbeddings(model='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f999e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector-stores : FAISS\n",
    "vector_store=FAISS.from_texts(chunks,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb4edca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='be6dd758-77d6-48a3-b284-f125ee5e1a93', metadata={}, page_content='that? And then philosophically, how are you and\\xa0\\xa0  others working on building that technology in\\xa0\\na way that really helps and not hurts people?\\xa0\\xa0  So just taking the tactical part right now.\\xa0\\nMy understanding is that there are three big\\xa0\\xa0  categories that have been limiting factors for\\xa0\\nAI. The first is compute, the second is data and\\xa0\\xa0  the third is algorithmic design. How do you think\\xa0\\nabout each of those three categories right now?\\xa0\\xa0  And if you were to help someone understand'),\n",
       " Document(id='934d18a6-63d1-42d3-b915-8ab48d2cebbf', metadata={}, page_content=\"never knew the world without AI. So they don't\\xa0\\xa0  really think about it. It's just this thing that's\\xa0\\ngoing to be there in everything. and and they will\\xa0\\xa0  think about like the companies that built on it\\xa0\\nand what they did with it and the kind of like\\xa0\\xa0  political leaders the decisions they made that\\xa0\\nmaybe they wouldn't have been able to do without\\xa0\\xa0  AI but they will still think about like what this\")]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(query='Tell me about AI ?',k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aec6828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrievers\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdef8b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='f1e5a111-699c-4bc9-bc10-a1ab79e95267', metadata={}, page_content='time to go create something totally new, to go\\xa0\\xa0  invent something, to start a company, whatever\\xa0\\nit is. I think it is probably possible now to\\xa0\\xa0  start a company that is a oneperson company that\\xa0\\nwill go on to be worth like more than a billion\\xa0\\xa0  dollars and more importantly than that deliver an\\xa0\\namazing product and service to the world and that\\xa0\\xa0  that is like a crazy thing. You have access to'),\n",
       " Document(id='80fd824d-2882-4181-98f0-a965e8edb7b4', metadata={}, page_content=\"president or that president did and you know the\\xa0\\xa0  role of the AI companies is all these companies\\xa0\\nand people and institutions before us built up\\xa0\\xa0  this scaffolding we added our one layer on top and\\xa0\\nnow people get to stand on top of that and add one\\xa0\\xa0  layer and the next and the next and many more And\\xa0\\nthat is the beauty of our society. We kind of all  I I love this like idea that society\\xa0\\nis the super intelligence. Like no one\\xa0\\xa0  person could do on their own, what they're\"),\n",
       " Document(id='be6dd758-77d6-48a3-b284-f125ee5e1a93', metadata={}, page_content='that? And then philosophically, how are you and\\xa0\\xa0  others working on building that technology in\\xa0\\na way that really helps and not hurts people?\\xa0\\xa0  So just taking the tactical part right now.\\xa0\\nMy understanding is that there are three big\\xa0\\xa0  categories that have been limiting factors for\\xa0\\nAI. The first is compute, the second is data and\\xa0\\xa0  the third is algorithmic design. How do you think\\xa0\\nabout each of those three categories right now?\\xa0\\xa0  And if you were to help someone understand'),\n",
       " Document(id='934d18a6-63d1-42d3-b915-8ab48d2cebbf', metadata={}, page_content=\"never knew the world without AI. So they don't\\xa0\\xa0  really think about it. It's just this thing that's\\xa0\\ngoing to be there in everything. and and they will\\xa0\\xa0  think about like the companies that built on it\\xa0\\nand what they did with it and the kind of like\\xa0\\xa0  political leaders the decisions they made that\\xa0\\nmaybe they wouldn't have been able to do without\\xa0\\xa0  AI but they will still think about like what this\")]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How to start a new application based company of Artificial Intelligence?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "624827ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a helpful assistant.\n",
    "Answer ONLY from the following context.\n",
    "If the context is insufficient, say: I don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2639165",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What do you know about Super Intelligence?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43bc8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c809e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e4c8a581-a43e-4f60-b00a-350f3dda61f2', metadata={}, page_content=\"people that were actually in labs and and\\xa0\\xa0  trying to build what we have defined as super\\xa0\\nintelligence. And it did seem like there were\\xa0\\xa0  these two camps forming. There's a group of\\xa0\\npeople who are using the tools like you in this\\xa0\\xa0  conversation and building tools for others\\xa0\\nsaying this is going to be a really useful\\xa0\\xa0  future that we're all moving toward. Your life is\\xa0\\ngoing to be full of choice and we've talked about\\xa0\\xa0  our my potential kids and and their futures.\"),\n",
       " Document(id='a8c3a69c-17b9-49eb-8093-ed0ab8201aa4', metadata={}, page_content='that point and play it out a little bit. Nothing\\xa0\\xa0  further than that. Like at what point would one\\xa0\\nof these systems come up with general relativity?\\xa0\\xa0  Interesting question is did you like if we think\\xa0\\nabout that forward like like if we think of where\\xa0\\xa0  we are now should a if if we never got another\\xa0\\npiece of physics data. Yeah. Do we expect that a\\xa0\\xa0  really good super intelligence could just think'),\n",
       " Document(id='03d68a62-9f54-4856-b72e-757566c66fb7', metadata={}, page_content=\"same system could do a better job running open AI\\xa0\\xa0  than I could. So you have something that's like,\\xa0\\nyou know, better than the best researchers, better\\xa0\\xa0  than me at this, better than other people at their\\xa0\\njobs, that would feel like super intelligence to\\xa0\\xa0  me. That is a sentence that would have sounded\\xa0\\nlike science fiction just a couple years ago.\\xa0\\xa0  And now it kind of does, but it's you can like see\"),\n",
       " Document(id='80fd824d-2882-4181-98f0-a965e8edb7b4', metadata={}, page_content=\"president or that president did and you know the\\xa0\\xa0  role of the AI companies is all these companies\\xa0\\nand people and institutions before us built up\\xa0\\xa0  this scaffolding we added our one layer on top and\\xa0\\nnow people get to stand on top of that and add one\\xa0\\xa0  layer and the next and the next and many more And\\xa0\\nthat is the beauty of our society. We kind of all  I I love this like idea that society\\xa0\\nis the super intelligence. Like no one\\xa0\\xa0  person could do on their own, what they're\")]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adb3a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \" \".join(i.page_content for i in context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12ce7a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "Answer ONLY from the following context.\n",
      "If the context is insufficient, say: I don't know.\n",
      "\n",
      "Context:\n",
      "people that were actually in labs and and  trying to build what we have defined as super\n",
      "intelligence. And it did seem like there were  these two camps forming. There's a group of\n",
      "people who are using the tools like you in this  conversation and building tools for others\n",
      "saying this is going to be a really useful  future that we're all moving toward. Your life is\n",
      "going to be full of choice and we've talked about  our my potential kids and and their futures. that point and play it out a little bit. Nothing  further than that. Like at what point would one\n",
      "of these systems come up with general relativity?  Interesting question is did you like if we think\n",
      "about that forward like like if we think of where  we are now should a if if we never got another\n",
      "piece of physics data. Yeah. Do we expect that a  really good super intelligence could just think same system could do a better job running open AI  than I could. So you have something that's like,\n",
      "you know, better than the best researchers, better  than me at this, better than other people at their\n",
      "jobs, that would feel like super intelligence to  me. That is a sentence that would have sounded\n",
      "like science fiction just a couple years ago.  And now it kind of does, but it's you can like see president or that president did and you know the  role of the AI companies is all these companies\n",
      "and people and institutions before us built up  this scaffolding we added our one layer on top and\n",
      "now people get to stand on top of that and add one  layer and the next and the next and many more And\n",
      "that is the beauty of our society. We kind of all  I I love this like idea that society\n",
      "is the super intelligence. Like no one  person could do on their own, what they're\n",
      "\n",
      "Question:\n",
      "What do you know about Super Intelligence?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_prompt = prompt.format(question=question, context=context)\n",
    "print(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation part : connect this final_prompt with LLM \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d70dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumar\\onedrive\\desktop\\try 1\\tutedude-course-1\\venv\\lib\\site-packages (from requests) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eeb6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to our conversation, Super Intelligence refers to an artificial intelligence system (similar in capabilities and potential impact as a human superintelligence). It suggests that such entities are now being actively developed by various individuals and organizations. These systems aim to build tools for others and serve as agents capable of making decisions independently or performing research, similar to humans doing their own work.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:11434/v1/chat/completions\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"mistral:7b\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": final_prompt}\n",
    "    ],\n",
    "    \"max_tokens\": 1000,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "resp = requests.post(url, json=data)\n",
    "answer=resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
